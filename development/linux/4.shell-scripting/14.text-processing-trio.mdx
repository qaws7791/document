---
title: "14. 텍스트 처리 삼총사"
---

이전 Chapter 13까지 우리는 쉘 스크립트에 조건문, 반복문, 함수 등의 프로그래밍 요소를 더하여 논리적인 흐름을 제어하는 방법을 배웠습니다. 스크립트는 종종 로그 파일, 설정 파일, 명령어의 출력 결과 등 다양한 형태의 **텍스트 데이터**를 처리해야 하는 경우가 많습니다. 리눅스(및 유닉스) 환경에는 이러한 텍스트 데이터를 효과적으로 다루기 위한 강력하고 고전적인 명령줄 도구들이 있습니다.

이번 챕터에서는 그 중에서도 가장 유명하고 널리 사용되는 **텍스트 처리 삼총사**, 바로 **`grep`**, **`sed`**, **`awk`** 에 대해 자세히 알아봅니다.

* **`grep` (Global Regular Expression Print):** 텍스트 데이터에서 특정 **패턴(정규 표현식 포함)과 일치하는 행**을 찾아 출력합니다. (Chapter 4, 11에서 기본 사용법을 다루었지만, 여기서는 좀 더 심화된 활용법을 봅니다.)
* **`sed` (Stream EDitor):** 텍스트 스트림(파일 또는 파이프 입력)을 한 줄씩 읽어 들여 **편집(수정, 삭제, 추가 등)** 작업을 수행하고 결과를 출력하는 스트림 편집기입니다. 특히 **문자열 치환**에 강력합니다.
* **`awk`:** 입력 데이터를 한 줄씩 읽어 **필드(열) 단위로 분리**하고, 특정 **패턴에 따라 프로그래밍적인 동작(Action)** 을 수행하는 강력한 데이터 처리 언어입니다. 데이터 추출 및 보고서 생성에 탁월합니다. (이름은 개발자인 Alfred **A**ho, Peter **W**einberger, Brian **K**ernighan의 앞 글자를 딴 것입니다.)

이 세 도구를 잘 활용하면 복잡한 텍스트 조작 작업을 명령줄에서 매우 효율적으로 처리할 수 있으며, 특히 이 도구들의 핵심 능력인 **정규 표현식(Regular Expression)** 활용 능력이 중요합니다.


## 정규 표현식(Regular Expression) 복습 및 핵심 개념

정규 표현식(줄여서 Regex 또는 Regexp)은 텍스트 내에서 특정 **패턴**을 정의하고 찾아내기 위한 강력한 규칙의 집합입니다. `grep`, `sed`, `awk` 등 많은 리눅스 도구들이 정규 표현식을 지원합니다. Chapter 4, 11에서 잠시 언급했지만, 여기서 핵심 메타 문자들을 다시 한번 정리하고 넘어갑니다.

* **기본 정규 표현식 (BRE - Basic Regular Expressions):** `grep`, `sed` (기본) 등에서 사용
  * `.` : 임의의 **한 문자**와 일치 (줄바꿈 제외)
  * `*` : 바로 앞의 문자가 **0번 이상 반복**됨 (`a*` = a 없음, a, aa, aaa...)
  * `^` : 행의 **시작** 부분과 일치
  * `$` : 행의 **끝** 부분과 일치
  * `[]`: 대괄호 안의 **문자 중 하나**와 일치 (`[abc]`, `[0-9]`, `[a-zA-Z]`)
  * `\` : 뒤따르는 메타 문자의 **특수 의미를 제거** (리터럴 문자로 취급) (예: `\.` = 실제 점 문자)
  * `\{n,m\}`: 바로 앞의 패턴이 n번 이상 m번 이하 반복 (BRE에서는 `\` 필요)

* **확장 정규 표현식 (ERE - Extended Regular Expressions):** `grep -E`(또는 `egrep`), `sed -E`(또는 `-r`), `awk` 등에서 사용. BRE보다 더 많은 메타 문자를 `\` 없이 사용 가능.
  * `+` : 바로 앞의 패턴이 **1번 이상 반복**됨 (`a+` = a, aa, aaa...)
  * `?` : 바로 앞의 패턴이 **0번 또는 1번** 나타남 (`a?` = a 없음 또는 a)
  * `|` : **또는 (OR)** 연산자 (`cat|dog` = cat 또는 dog)
  * `()`: 패턴 **그룹화**

* **POSIX 문자 클래스:** `[[:...:]]` 형태로 사용 (BRE, ERE 모두 사용 가능)
  * `[[:alnum:]]`: 알파벳과 숫자 (`[a-zA-Z0-9]`)
  * `[[:alpha:]]`: 알파벳 (`[a-zA-Z]`)
  * `[[:digit:]]`: 숫자 (`[0-9]`)
  * `[[:lower:]]`: 소문자 (`[a-z]`)
  * `[[:upper:]]`: 대문자 (`[A-Z]`)
  * `[[:space:]]`: 공백 문자 (스페이스, 탭 등)
  * `[[:punct:]]`: 구두점 문자

정규 표현식은 매우 강력하지만 그만큼 복잡한 주제이기도 합니다. 여기서는 `grep`, `sed`, `awk` 예제에 필요한 수준으로만 다루고 넘어가겠습니다.


## 14.2 `grep` 고급 활용 (패턴 매칭의 달인) (Advanced `grep` Usage: Master of Pattern Matching)

`grep`은 단순히 특정 단어를 찾는 것을 넘어, 정규 표현식과 다양한 옵션을 활용하여 훨씬 정교한 패턴 매칭을 수행할 수 있습니다.

* **확장 정규 표현식 사용 (`-E` 또는 `egrep`):** `+`, `?`, `|`, `()` 등 ERE 메타 문자를 사용하려면 `-E` 옵션을 사용합니다. (`egrep` 명령어는 `grep -E`와 동일합니다.)

    ```bash
    # 'warning' 또는 'error' 문자열을 포함하는 행 검색 (대소문자 무시 -i)
    grep -Ei 'warning|error' application.log

    # IP 주소 패턴 (간단한 예시) 찾기
    grep -E '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' network.log
    # \b 는 단어 경계를 의미

    # 'apple' 이 1번 이상 나오는 행 검색
    grep -E 'apple+' fruits.txt
    ```

* **패턴 주변 행 함께 보기 (`-A`, `-B`, `-C`):** 검색된 행뿐만 아니라 그 주변의 문맥(Context)을 함께 보고 싶을 때 유용합니다.
  * `-A <숫자>`: 일치하는 행 **뒤(After)** 의 `<숫자>` 행을 함께 출력합니다.
  * `-B <숫자>`: 일치하는 행 **앞(Before)** 의 `<숫자>` 행을 함께 출력합니다.
  * `-C <숫자>`: 일치하는 행 **앞뒤(Context)** 로 각각 `<숫자>` 행을 함께 출력합니다. (`-A`와 `-B` 동시 적용)

    ```bash
    # 에러 메시지와 그 다음 2줄을 함께 보기
    grep -A 2 'ERROR' system.log
    ```

* **기타 유용한 옵션 복습 및 추가:**
  * `-c`: 일치하는 **행의 개수(Count)** 만 출력합니다.
  * `-l`: 일치하는 내용을 포함하는 **파일 이름(List)** 만 출력합니다.
  * `-v`: 패턴과 일치하지 **않는(Invert)** 행만 출력합니다.
  * `-r` 또는 `-R`: 디렉토리 내부를 **재귀적(Recursive)** 으로 검색합니다.
  * `-w`: 패턴이 **완전한 단어(Word)** 로 일치하는 경우만 찾습니다.
  * `-o`: 일치하는 행 전체가 아닌, **패턴과 일치하는 부분만(Only matched)** 잘라서 각 줄에 출력합니다.

        ```bash
        # 로그 파일에서 IP 주소 패턴만 추출하여 출력
        grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' access.log
        ```

  * `--color=auto`: 검색된 패턴을 **색상으로 강조**하여 보여줍니다. (많은 시스템에서 `grep` 앨리어스로 기본 설정되어 있습니다.)

`grep`은 특히 파이프라인(`|`)과 함께 다른 명령어의 출력을 필터링하는 데 매우 빈번하게 사용됩니다.


## 14.3 `sed` 활용 (스트림 편집기 - Stream Editor) (Using `sed`: The Stream Editor)

`sed`는 입력 스트림(파일 또는 파이프 입력)을 **한 줄씩 읽어** 특정 편집 명령을 적용한 후 결과를 표준 출력으로 내보내는 **비대화형(non-interactive) 스트림 편집기**입니다. 원본 파일을 직접 수정하지 않는 것이 기본 동작입니다 (단, `-i` 옵션 사용 시 예외).

* **기본 형식:** `sed '[주소]명령[옵션]' [입력 파일...]` 또는 `명령어 출력 | sed '[주소]명령[옵션]'`
  * `[주소]`: 명령을 적용할 행을 지정합니다 (선택 사항). 생략하면 모든 행에 적용됩니다. 주소는 행 번호, 정규 표현식(`/pattern/`), 또는 범위(`시작주소,끝주소`) 등으로 지정할 수 있습니다.
  * `명령`: 수행할 편집 작업 (예: `s`=치환, `d`=삭제, `p`=출력 등)
  * `[옵션]`: 명령의 동작을 수정합니다.


### 14.3.1 기본 치환 (`s/.../.../`) (Basic Substitution)

`sed`의 가장 대표적이고 강력한 기능은 **문자열 치환(substitute)** 입니다. `s` 명령어를 사용합니다.

* **형식:** `sed '[주소]s/찾을패턴/바꿀문자열/플래그'`
  * `s`: 치환 명령어
  * `찾을패턴`: 정규 표현식(BRE 기본)
  * `바꿀문자열`: 변경할 내용
  * `플래그` (선택 사항):
    * `g` (global): 행 전체에서 **모든** 일치 항목을 변경합니다. (없으면 각 행에서 첫 번째 일치 항목만 변경)
    * `i` (ignore case): 대소문자를 **무시**하고 검색합니다. (GNU `sed` 확장 기능)
    * `<숫자>`: 해당 행에서 `<숫자>`번째 일치 항목만 변경합니다.

* **구분자:** 일반적으로 슬래시(`/`)를 사용하지만, 패턴이나 바꿀 문자열에 슬래시가 포함될 경우 다른 문자(예: `|`, `#`, `:`)를 구분자로 사용할 수 있습니다.
    `sed 's|/old/path|/new/path|g'`

* **예시:**

    ```bash
    # text.txt 파일에서 각 줄의 첫 번째 "apple"을 "orange"로 변경하여 출력
    sed 's/apple/orange/' text.txt

    # text.txt 파일에서 각 줄의 모든 "apple"을 "orange"로 변경하여 출력
    sed 's/apple/orange/g' text.txt

    # config.xml 파일에서 모든 "/usr/share" 경로를 "/opt/share" 로 변경
    sed 's|/usr/share|/opt/share|g' config.xml

    # document.txt 에서 대소문자 구분 없이 모든 'Error' 를 'Warning' 으로 변경 (GNU sed)
    sed 's/Error/Warning/gi' document.txt

    # '&' 활용: 찾은 패턴 자체를 바꿀 문자열에서 참조 가능
    # "word" 라는 단어를 "(word)" 로 감싸기
    sed 's/word/(&)/g' notes.txt

    # 파이프와 함께 사용: ls -l 결과에서 사용자 이름 'alice' 를 'ALICE' 로 변경
    ls -l | sed 's/alice/ALICE/'
    ```

* **파일 직접 수정 (`-i` 옵션):** `-i` 옵션을 사용하면 결과를 화면에 출력하는 대신 **원본 파일을 직접 수정**합니다. **매우 주의해서 사용해야 하며, 실행 전에 원본 파일을 백업하는 것이 안전합니다!**

    ```bash
    # 원본 파일(config.ini)을 직접 수정 (GNU sed 방식)
    sed -i 's/enabled=true/enabled=false/g' config.ini

    # 원본 파일을 수정하면서 백업 파일(config.ini.bak) 생성 (GNU sed 방식)
    sed -i.bak 's/debug=1/debug=0/g' config.ini
    ```

    (macOS 등 BSD 기반 시스템의 `sed`는 `-i` 옵션 사용법이 약간 다를 수 있습니다. `-i ''` 처럼 빈 문자열을 제공해야 할 수 있습니다.)


### 14.3.2 특정 라인 출력, 삭제 등 (Printing, Deleting Specific Lines)

`sed`는 치환 외에도 특정 행을 삭제하거나 출력하는 등의 작업도 가능합니다.

* **`-n` 옵션:** 기본적으로 `sed`는 모든 행을 처리 후 출력하는데, `-n` 옵션을 사용하면 이 **자동 출력을 억제**합니다. 주로 특정 행만 골라서 출력하는 `p` 명령어와 함께 사용됩니다.
* **주소 지정:** 명령 앞에 주소를 지정하여 특정 행에만 명령을 적용할 수 있습니다.
  * `<숫자>`: 해당 줄 번호 (예: `3`)
  * `$` : 마지막 줄
  * `/정규표현식/`: 정규 표현식과 일치하는 행
  * `<시작주소>,<끝주소>`: 시작 주소부터 끝 주소까지의 범위 (주소는 숫자 또는 정규 표현식 가능)

* **주요 명령어:**
  * `p` (print): 현재 처리 중인 행을 **출력**합니다. (`-n` 옵션과 함께 사용해야 중복 출력을 막을 수 있음)
  * `d` (delete): 현재 처리 중인 행을 **삭제**합니다. (결과에서 해당 행이 제외됨)
  * `a <텍스트>` (append): 현재 행 **다음에** `<텍스트>`를 추가합니다.
  * `i <텍스트>` (insert): 현재 행 **앞에** `<텍스트>`를 추가합니다.

* **예시:**

    ```bash
    # data.txt 파일의 5번째 줄만 출력
    sed -n '5p' data.txt

    # data.txt 파일에서 10번째 줄부터 20번째 줄까지 삭제
    sed '10,20d' data.txt

    # log.txt 파일에서 "CRITICAL" 문자열을 포함하는 행만 출력
    sed -n '/CRITICAL/p' log.txt

    # config.file 에서 # 으로 시작하는 주석 라인 모두 삭제
    sed '/^#/d' config.file

    # file.txt 에서 빈 줄(내용 없는 줄) 모두 삭제
    sed '/^$/d' file.txt

    # 3번째 줄 다음에 "--- new section ---" 텍스트 추가
    sed '3a --- new section ---' data.txt
    ```


## 14.4 `awk` 활용 (데이터 추출 및 보고서 생성) (Using `awk`: Data Extraction and Report Generation)

`awk`는 텍스트 데이터를 처리하는 강력한 **프로그래밍 언어**입니다. 입력 데이터를 **한 줄씩 읽어들여**, 각 줄을 **필드(Field) 또는 열(Column)로 분리**하고, 특정 **패턴(Pattern)** 과 일치하는 줄에 대해 지정된 **액션(Action)** 을 수행하는 방식으로 작동합니다. 특히 공백이나 특정 구분자로 분리된 **정형화된 텍스트 데이터(예: 로그 파일, CSV 파일, 명령어 출력 결과)** 를 처리하고 원하는 정보를 추출하여 보고서 형태로 가공하는 데 매우 뛰어납니다.

* **기본 구조:** `awk '패턴 { 액션 }' [입력 파일...]` 또는 `명령어 출력 | awk '패턴 { 액션 }'`
  * **패턴 (Pattern):** 어떤 줄에 액션을 적용할지를 결정하는 조건입니다 (선택 사항).
    * 생략되면 **모든 줄**에 대해 액션을 수행합니다.
    * 정규 표현식 (`/regex/`)
    * 비교 연산 (`$1 == "ERROR"`, `$3 > 100`, `NF >= 5`)
    * `BEGIN`: 첫 번째 입력 줄을 처리하기 **전에** 실행되는 특수 패턴
    * `END`: 마지막 입력 줄 처리가 **끝난 후**에 실행되는 특수 패턴
  * **액션 (Action):** 패턴과 일치하는 줄에 대해 수행할 명령어들의 블록입니다 (`{}` 안에 작성).
    * 생략되면 기본 액션인 `print $0` (현재 줄 전체 출력)이 수행됩니다.
    * `print`: 필드나 문자열 등을 출력합니다. (콤마`,`로 구분하면 기본적으로 공백(OFS)으로 연결됨)
    * 변수 할당 및 계산, 문자열 함수, 제어문(`if`, `for`, `while`) 등 프로그래밍 언어 기능 사용 가능


### 14.4.1 필드 기반 처리 (Field-based Processing)

`awk`의 핵심 기능은 입력된 각 줄을 자동으로 **필드**로 분리하는 것입니다.

* **필드 분리:** 기본적으로 하나 이상의 **공백(space) 또는 탭(tab)** 을 필드 구분자(Field Separator)로 사용합니다.
* **필드 변수:** 분리된 필드는 특별한 변수를 통해 접근할 수 있습니다.
  * `$0`: 현재 처리 중인 **줄 전체**
  * `$1`: **첫 번째** 필드
  * `$2`: **두 번째** 필드, ...
  * `$NF`: **마지막 필드** (**N**umber of **F**ields 변수 `NF` 값을 이용)
* **내장 변수:** `awk`는 유용한 내장 변수들을 제공합니다.
  * `NF`: 현재 줄의 **총 필드 개수**
  * `NR`: 현재까지 처리한 총 **레코드(줄) 번호** (**N**umber of **R**ecords)
  * `FS`: **입력 필드 구분자** (기본값: 공백). `-F` 옵션이나 `BEGIN` 블록에서 변경 가능 (예: `awk -F':' ...` 는 콜론 `:` 을 구분자로 사용)
  * `OFS`: **출력 필드 구분자** (`print`에서 콤마로 여러 항목 출력 시 사용될 구분자, 기본값: 공백)
  * `ORS`: **출력 레코드 구분자** (`print` 실행 후 출력될 문자, 기본값: 줄바꿈 `\n`)

* **예시:**

    ```bash
    # /etc/passwd 파일 (콜론 구분)에서 사용자 이름(1번째 필드)과 기본 쉘(마지막 필드) 출력
    awk -F':' '{ print "User:", $1, " Shell:", $NF }' /etc/passwd

    # ls -l 결과에서 파일 이름(9번째 이후 필드들)만 출력 (필드 개수가 가변적일 때)
    # (주의: 파일 이름에 공백이 있으면 제대로 안 나올 수 있음)
    ls -l | awk '{ for(i=9; i<=NF; i++) printf "%s ", $i; printf "\n" }'

    # data.log 파일에서 3번째 필드 값이 1000 보다 큰 줄만 출력
    awk '$3 > 1000 { print $0 }' data.log # { print $0 } 은 생략 가능

    # access.log 파일에서 1번째(IP), 4번째(날짜/시간), 7번째(요청 URL) 필드 출력
    awk '{ print $1, $4, $7 }' access.log
    ```


### 14.4.2 패턴과 액션 (Patterns and Actions)

패턴을 이용하여 특정 줄에만 액션을 적용하거나, `BEGIN`/`END` 패턴을 사용하여 전처리/후처리 작업을 수행할 수 있습니다.

* **`BEGIN` 블록:** 첫 번째 입력 줄을 읽기 전에 **단 한 번** 실행됩니다. 주로 헤더 출력, 변수 초기화 등에 사용됩니다.

    ```awk
    # CSV 파일 헤더와 함께 1, 3번째 필드 출력
    awk 'BEGIN { FS=","; OFS="\t"; print "ID\tName" } NR > 1 { print $1, $3 }' data.csv
    # FS: 입력 필드 구분자를 콤마로 설정
    # OFS: 출력 필드 구분자를 탭으로 설정
    # NR > 1: 첫 번째 줄(헤더)은 제외하고 처리
    ```

* **`END` 블록:** 모든 입력 줄 처리가 끝난 후 **단 한 번** 실행됩니다. 주로 합계, 평균 등 최종 결과 출력에 사용됩니다.

    ```awk
    # numbers.txt 파일의 모든 숫자의 합계와 평균 계산
    awk 'BEGIN { sum=0; count=0 } { sum += $1; count++ } END { if (count > 0) print "Sum:", sum, "Average:", sum/count; else print "No data"; }' numbers.txt
    ```

* **정규 표현식 패턴:** `/regex/ { action }` 형식으로 사용합니다. 해당 정규 표현식과 일치하는 줄에 대해서만 액션을 수행합니다.

    ```awk
    # /var/log/messages 에서 "kernel" 이 포함된 행의 첫 번째 필드(시간)와 나머지 내용 출력
    awk '/kernel/ { print $1, $2, $3; for(i=4;i<=NF;i++) printf "%s ", $i; print "" }' /var/log/messages
    # 더 간단하게: awk '/kernel/ { print $0 }' /var/log/messages
    ```

* **관계식 패턴:** 필드 값 비교 등 관계식을 패턴으로 사용합니다.

    ```awk
    # score.txt 에서 3번째 필드(점수)가 90 이상인 학생(1번째 필드) 이름 출력
    awk '$3 >= 90 { print $1 }' score.txt
    ```

`awk`는 자체적으로 변수, 연산, 조건문(`if`), 반복문(`for`, `while`), 배열, 내장 함수(`length`, `substr`, `split`, `sprintf` 등)를 지원하는 **완전한 프로그래밍 언어**입니다. 간단한 필터링부터 복잡한 데이터 변환 및 보고서 생성까지 매우 다양한 작업이 가능합니다.


## 결론

이번 챕터에서는 리눅스 명령줄 환경에서 텍스트 데이터를 자유자재로 다룰 수 있게 해주는 강력한 삼총사, `grep`, `sed`, `awk` 에 대해 알아보았습니다.

* **`grep`** 은 정규 표현식을 활용하여 원하는 패턴을 가진 행을 **찾아내는** 데 특화되어 있습니다. 다양한 옵션을 통해 검색 방식을 제어하고 주변 문맥을 확인하는 등 고급 검색이 가능합니다.
* **`sed`** 는 스트림 편집기로서, 텍스트 스트림을 한 줄씩 읽어 **치환(`s`), 삭제(`d`), 출력(`p`)** 등 다양한 편집 작업을 수행합니다. 특히 문자열 치환 작업에 매우 강력합니다.
* **`awk`** 는 필드 기반 데이터 처리 언어로, 각 줄을 필드로 분리하고 **패턴에 따라 프로그래밍적인 액션**을 수행하여 데이터를 추출, 변환, 요약, 보고서 생성 등에 탁월한 능력을 보입니다.

이 세 도구는 각자의 강점을 가지고 있으며, 종종 **파이프라인(`|`)** 으로 함께 연결되어 사용될 때 더욱 강력한 시너지를 발휘합니다. 정규 표현식에 대한 이해는 이 도구들을 효과적으로 사용하는 데 핵심적인 역할을 합니다.

물론 `sed` 와 `awk` 는 이 챕터에서 소개한 내용보다 훨씬 더 많은 기능과 복잡한 프로그래밍 능력을 가지고 있습니다. 하지만 여기서 배운 기본적인 사용법만으로도 여러분의 쉘 스크립트 작성 능력과 명령줄 작업 효율성은 크게 향상될 것입니다. 로그 파일, 설정 파일, CSV 데이터 등 주변의 텍스트 데이터를 대상으로 직접 `grep`, `sed`, `awk` 명령어를 실행해보며 연습하는 것이 중요합니다.

다음 Chapter 15에서는 리눅스 시스템의 네트워크 설정 확인 및 변경 방법에 대해 알아보겠습니다.
