---
title: "19. 시스템 모니터링 및 최적화"
---

이전 Chapter 18에서는 리눅스 시스템의 보안을 강화하는 다양한 방법들을 살펴보았습니다. 안전한 시스템을 구축하는 것도 중요하지만, 그 시스템이 사용자의 요구사항에 맞게 원활하고 **효율적으로 작동**하도록 관리하는 것 또한 매우 중요합니다. 시스템이 느려지거나 응답하지 않는다면 아무리 안전해도 소용이 없겠죠.

이번 챕터에서는 시스템의 **성능 상태를 지속적으로 관찰(모니터링)** 하고, 잠재적인 **성능 병목 현상(Bottleneck)을 식별**하며, 필요한 경우 시스템 설정을 조정하여 **성능을 개선(최적화/튜닝)** 하는 기본적인 방법들을 알아봅니다.

* **모니터링 (Monitoring):** 시스템의 핵심 자원(CPU, 메모리, 디스크 I/O, 네트워크 I/O) 사용량과 시스템 동작 상태를 시간에 따라 관찰하고 기록하는 활동입니다.
* **최적화/튜닝 (Optimization/Tuning):** 모니터링을 통해 얻은 데이터를 분석하고 시스템의 부하 특성을 파악하여, 커널 파라미터나 서비스 설정을 조정함으로써 성능, 효율성, 안정성을 향상시키는 과정입니다.

시스템 모니터링과 최적화는 시스템의 갑작스러운 장애를 예방하고, 사용자에게 쾌적한 서비스 환경을 제공하며, 향후 필요한 자원을 예측(용량 계획)하는 데 필수적인 시스템 관리 활동입니다. 이 챕터에서는 리눅스의 표준 도구들을 사용하여 시스템의 건강 상태를 진단하고 개선하는 기초를 다룹니다.


## 19.1 시스템 성능 분석 (System Performance Analysis)

시스템 성능 문제를 해결하기 위한 첫걸음은 **병목 현상(Bottleneck)** 이 어디에서 발생하는지 정확히 파악하는 것입니다. 병목 현상이란 시스템 전체의 성능을 제한하는 특정 자원 또는 구성 요소를 의미합니다. 예를 들어, 아무리 빠른 CPU를 사용해도 디스크 읽기/쓰기가 느려서 작업이 지연된다면 디스크 I/O가 병목인 것입니다.

**주요 모니터링 대상 자원:**

1. **CPU:** 프로세스 연산 처리 속도와 직접 관련됩니다. CPU 사용률이 지속적으로 100%에 가깝다면 CPU가 병목일 수 있습니다.
2. **메모리 (RAM):** 프로그램과 데이터가 실행되고 저장되는 작업 공간입니다. 사용 가능한 메모리가 부족해지면 시스템은 디스크 공간(스왑 영역)을 메모리처럼 사용하게 되는데(스와핑), 이는 디스크 I/O를 유발하여 시스템 성능을 급격히 저하시킵니다.
3. **디스크 I/O (Input/Output):** 하드 디스크나 SSD에서 데이터를 읽고 쓰는 속도입니다. 디스크 읽기/쓰기 대기 시간이 길거나 사용률이 높다면 디스크 I/O 병목을 의심할 수 있습니다.
4. **네트워크 I/O:** 네트워크 인터페이스를 통해 데이터를 주고받는 속도입니다. 네트워크 대역폭이 부족하거나 지연 시간이 길면 네트워크 관련 작업 성능이 저하됩니다.

종종 한 자원의 병목이 다른 자원의 문제처럼 보일 수도 있습니다. 예를 들어 메모리가 부족하여 스와핑이 심하게 발생하면, 디스크 I/O 사용률이 높아지고 CPU 사용률(I/O 대기 시간 증가)에도 영향을 미칩니다. 따라서 여러 자원의 상태를 종합적으로 파악하는 것이 중요합니다.

**기준선(Baseline) 설정:** 평상시 시스템이 정상적으로 작동할 때의 자원 사용률과 성능 지표를 미리 측정하고 기록해두는 것이 좋습니다. 이를 통해 나중에 문제가 발생했을 때 정상 상태와 비교하여 이상 징후를 더 쉽게 파악할 수 있습니다.


## 19.2 리소스 모니터링 (Resource Monitoring)

리눅스는 시스템 자원 상태를 확인하기 위한 다양한 명령줄 도구들을 제공합니다. Chapter 8에서 배운 `top` 이나 `htop` 도 훌륭한 실시간 종합 모니터링 도구이지만, 특정 자원에 대한 더 상세한 정보를 얻기 위해 다음과 같은 전문 도구들을 사용할 수 있습니다. (일부 도구는 `sysstat` 등의 패키지를 별도로 설치해야 할 수 있습니다: `sudo apt install sysstat`, `sudo dnf install sysstat`)


### CPU 모니터링

* **`top` / `htop` (복습):** 실시간으로 전체 CPU 사용률, 개별 프로세스의 CPU 점유율, 그리고 **로드 에버리지(Load Average)** 를 보여줍니다.
  * **로드 에버리지:** 시스템의 부하 정도를 나타내는 지표로, 보통 1분, 5분, 15분 평균값이 표시됩니다. 실행 중이거나 실행 대기 중인 프로세스들의 평균 개수를 의미하며, **CPU 코어 수와 비교**하여 해석해야 합니다. 예를 들어 4코어 시스템에서 로드 에버리지가 꾸준히 4.0 이상이라면 CPU 부하가 높다고 볼 수 있습니다.
  * CPU 상태 (%): `%us`(사용자 프로세스), `%sy`(커널 프로세스), `%ni`(nice 값 변경 프로세스), `%id`(유휴 상태), `%wa`(I/O 대기), `%hi`(하드웨어 인터럽트), `%si`(소프트웨어 인터럽트) 등 CPU가 어떤 작업을 하느라 시간을 보내는지 세부적으로 보여줍니다. `%wa` 가 높으면 디스크 I/O 병목을 의심할 수 있습니다.
* **`uptime`:** 시스템이 얼마나 오랫동안 켜져 있었는지(uptime)와 함께 현재 로드 에버리지(1분, 5분, 15분)를 간결하게 보여줍니다.

    ```bash
    uptime
    # 03:55:01 up 2 days, 15:30,  1 user,  load average: 0.05, 0.10, 0.08
    ```

* **`mpstat` (Multiple Processor Statistics):** (`sysstat` 패키지 필요) 멀티코어 CPU 시스템에서 **각 코어별 사용률**을 상세하게 보여줍니다. CPU 부하가 특정 코어에 집중되는지 등을 확인할 때 유용합니다.

    ```bash
    # 1초 간격으로 모든 CPU 코어(-P ALL)의 통계 보기
    mpstat -P ALL 1
    ```


### 메모리 모니터링

* **`free -h`:** 시스템의 전체 메모리(RAM) 및 스왑(Swap) 공간의 **사용 현황**을 사람이 읽기 쉬운 단위(`-h`)로 보여줍니다.

    ```bash
    free -h
    #               total        used        free      shared  buff/cache   available
    # Mem:           7.7Gi       3.1Gi       1.2Gi       150Mi       3.4Gi       4.1Gi
    # Swap:          2.0Gi       512Mi       1.5Gi
    ```

  * **`total`**: 전체 메모리/스왑 크기
  * **`used`**: 사용 중인 크기
  * **`free`**: 순수하게 비어있는 메모리 크기
  * **`shared`**: 여러 프로세스가 공유하는 메모리 크기
  * **`buff/cache`**: 커널이 디스크 I/O 성능 향상을 위해 사용하는 버퍼 및 캐시 메모리 크기. 이 메모리는 필요 시 다른 프로세스가 사용할 수 있도록 회수될 수 있습니다.
  * **`available`**: **실제로 애플리케이션이 즉시 사용 가능한 메모리 크기**를 추정한 값 (`free` + 회수 가능한 `buff/cache`). `free` 값보다 시스템의 여유 메모리 상태를 더 정확하게 나타내는 경우가 많습니다.
* **`vmstat <간격> [횟수]` (Virtual Memory Statistics):** (`procps` 또는 `sysstat` 패키지) 지정된 간격으로 시스템의 프로세스, **메모리(특히 스와핑 `si`/`so`)**, 페이징, 블록 I/O, CPU 활동 등 다양한 통계 정보를 보여줍니다.

    ```bash
    # 1초 간격으로 계속 통계 보기 (Ctrl+C 로 중지)
    vmstat 1
    ```

  * `procs`: `r`(실행 대기 프로세스 수), `b`(Uninterruptible sleep 상태 프로세스 수)
  * `memory`: `swpd`(사용된 스왑 공간), `free`(여유 메모리), `buff`, `cache`
  * **`swap`**: `si`(Swap In - 디스크에서 메모리로 읽어온 양), `so`(Swap Out - 메모리에서 디스크로 내보낸 양). **`si`, `so` 값이 지속적으로 0보다 크다면 메모리가 부족하여 스와핑이 발생하고 있음을 의미하며, 이는 심각한 성능 저하의 원인**이 될 수 있습니다.
  * `io`: `bi`(블록 장치에서 읽은 블록 수), `bo`(블록 장치에 쓴 블록 수)
  * `system`: `in`(초당 인터럽트 수), `cs`(초당 컨텍스트 스위치 수)
  * `cpu`: `us`, `sy`, `id`, `wa`, `st` 등 CPU 사용률 (%)
* **`top` / `htop` (복습):** 전체 메모리/스왑 사용량과 함께, 개별 프로세스가 사용하는 메모리 양(`VIRT`:가상 메모리, `RES`:실제 물리 메모리, `SHR`:공유 메모리, `%MEM`:물리 메모리 점유율)을 확인할 수 있습니다.


### 디스크 I/O 모니터링

* **`iostat <간격> [횟수]` (Input/Output Statistics):** (`sysstat` 패키지 필요) CPU 사용률과 함께 **디스크(블록 장치)의 I/O 통계** 정보를 보여줍니다. 디스크 성능 병목을 진단하는 데 중요합니다.

    ```bash
    # 1초 간격으로 확장된(-x) 디스크(-d) 통계 보기
    iostat -dx 1
    ```

  * 주요 지표:
    * `r/s`, `w/s`: 초당 읽기/쓰기 요청 수
    * `rkB/s`, `wkB/s`: 초당 읽기/쓰기 KB 양 (처리량)
    * `await`: I/O 요청 평균 대기 시간 (밀리초). 이 값이 높으면 디스크 응답이 느리다는 의미.
    * `avgqu-sz`: 평균 I/O 큐 길이. 큐가 길다는 것은 요청이 밀려있다는 의미.
    * `%util`: 디스크 사용률 (%). 100%에 가까우면 디스크가 매우 바쁘다는 의미. (단, 100%라고 무조건 병목은 아닐 수 있음. `await` 값과 함께 봐야 함)
* **`iotop`:** (`iotop` 패키지 별도 설치 필요) `top` 명령어의 I/O 버전과 같습니다. **실시간으로 어떤 프로세스가 디스크 I/O를 많이 발생시키는지** 보여줍니다. 디스크 부하의 원인이 되는 프로세스를 찾을 때 매우 유용합니다. 루트 권한(`sudo iotop`)이 필요합니다.


### 네트워크 I/O 모니터링

* **`iftop`:** (별도 설치 필요) `top` 명령어의 네트워크 인터페이스 버전입니다. 특정 네트워크 인터페이스에서 **실시간으로 어떤 연결(Source/Destination IP 및 Port)이 네트워크 대역폭을 얼마나 사용하는지** 보여줍니다. 네트워크 트래픽의 원인을 파악할 때 유용합니다. 루트 권한(`sudo iftop -i <인터페이스명>`)이 필요합니다.
* **`nload`:** (별도 설치 필요) 특정 네트워크 인터페이스의 **수신(Incoming)/송신(Outgoing) 트래픽 양**을 실시간 그래프 형태로 간결하게 보여주는 도구입니다. (`nload <인터페이스명>`)
* **`sar` (System Activity Reporter):** (`sysstat` 패키지 필요) `sar`는 CPU, 메모리, I/O뿐만 아니라 네트워크 통계 정보도 수집하고 보고할 수 있는 강력한 도구입니다. 주기적으로 데이터를 수집하도록 설정하면 과거 시점의 네트워크 활동 분석도 가능합니다.
  * `sar -n DEV <간격> [횟수]`: **DEV**ice (네트워크 인터페이스) 통계를 지정된 간격으로 보여줍니다. `rxpck/s`(초당 수신 패킷), `txpck/s`(초당 송신 패킷), `rxkB/s`(초당 수신 KB), `txkB/s`(초당 송신 KB) 등의 정보를 확인할 수 있습니다.

        ```bash
        # 1초 간격으로 네트워크 인터페이스 통계 보기
        sar -n DEV 1
        ```

  * `-n` 옵션 뒤에 `TCP`, `ETCP`(TCP 오류), `UDP` 등 다른 키워드를 사용하여 특정 프로토콜 통계도 볼 수 있습니다.


## 19.3 시스템 튜닝 (System Tuning - Basic Concepts)

**튜닝(Tuning)** 이란 모니터링을 통해 얻은 정보와 시스템의 작업 부하(Workload) 특성을 분석하여, 시스템 설정값(파라미터)을 조정함으로써 성능을 개선하는 과정입니다.

* **반복적인 과정:** 튜닝은 한 번에 끝나는 것이 아니라 **모니터링 → 병목 식별 → 튜닝 적용 → 모니터링 → 개선 확인** 의 순환적인 과정을 거칩니다.
* **주의사항:**
  * **섣부른 튜닝은 금물:** 명확한 성능 문제나 병목 현상이 확인되지 않았는데 무턱대고 설정을 변경하는 것은 오히려 성능을 저하시키거나 시스템 불안정을 초래할 수 있습니다. "고장나지 않았으면 고치지 마라(If it ain't broke, don't fix it)"는 격언을 기억하세요.
  * **변경 전 이해 필수:** 변경하려는 설정값(파라미터)이 정확히 어떤 역할을 하고 어떤 영향을 미치는지 충분히 이해한 후에 변경해야 합니다.
  * **하나씩 변경하고 측정:** 여러 설정을 한꺼번에 변경하면 어떤 변경이 효과가 있었는지 알기 어렵습니다. 가능하면 하나씩 변경하고 성능 변화를 측정하는 것이 좋습니다.
  * **백업 및 기록:** 중요한 설정을 변경하기 전에는 반드시 기존 설정을 백업하고, 변경 내용을 기록해두어야 문제가 발생했을 때 원복하기 쉽습니다.
* **튜닝 대상:** 커널 파라미터, 파일 시스템 마운트 옵션, 개별 서비스(웹 서버, 데이터베이스 등)의 설정, 하드웨어 업그레이드 등 다양한 영역이 튜닝 대상이 될 수 있습니다.


## 19.4 커널 파라미터 최적화 (`sysctl`) (Kernel Parameter Optimization with `sysctl`)

리눅스 커널은 내부 동작 방식을 제어하는 수많은 **파라미터(Parameter)** 를 가지고 있습니다. 이 파라미터들은 네트워크 스택 작동 방식, 가상 메모리 관리 정책, 파일 시스템 처리 방식 등에 영향을 미칩니다. 대부분의 경우 기본값이 일반적인 환경에 적합하지만, 특정 작업 부하(예: 대규모 웹 서비스, 고성능 데이터베이스)에 맞춰 일부 파라미터를 조정하면 성능을 향상시킬 수 있습니다.

* **파라미터 확인 및 임시 변경:**
  * 커널 파라미터는 `/proc/sys/` 가상 파일 시스템을 통해 접근할 수 있습니다. (예: `cat /proc/sys/vm/swappiness`)
  * 루트 권한으로 `echo <값> > /proc/sys/경로/파라미터` 를 통해 임시 변경 가능합니다.
* **`sysctl` 명령어 (권장 방식):** 커널 파라미터를 확인하고 변경하는 표준 명령어입니다.
  * `sysctl -a`: 현재 설정된 **모든** 커널 파라미터와 값 목록을 보여줍니다. (매우 김)
  * `sysctl <파라미터.이름>`: 특정 파라미터의 값을 보여줍니다. (예: `sysctl vm.swappiness`, `sysctl net.ipv4.ip_local_port_range`)
  * `sudo sysctl <파라미터.이름>=<값>`: 파라미터 값을 **임시로 변경**합니다. (재부팅 시 사라짐)

        ```bash
        # 스와핑을 덜 하도록 swappiness 값을 10으로 임시 변경
        sudo sysctl vm.swappiness=10
        ```

* **영구적인 변경 (`/etc/sysctl.conf`, `/etc/sysctl.d/`):**
  * 재부팅 후에도 변경된 파라미터 값을 유지하려면, `/etc/sysctl.conf` 파일을 편집하거나 `/etc/sysctl.d/` 디렉토리 아래에 `.conf` 확장자를 가진 설정 파일을 새로 만들어 다음 형식으로 추가합니다.
        `<파라미터.이름> = <값>`
  * 예시 (`/etc/sysctl.conf` 또는 `/etc/sysctl.d/99-custom.conf`):

        ```
        # Decrease swappiness
        vm.swappiness = 10

        # Increase max connections
        net.core.somaxconn = 4096
        ```

  * **설정 적용:** 파일을 수정한 후, `sudo sysctl -p /etc/sysctl.conf` (지정 파일 로드) 또는 `sudo sysctl --system` (모든 설정 파일 로드) 명령을 실행하면 재부팅 없이 변경 사항을 적용할 수 있습니다.

* **주요 튜닝 파라미터 예시 (주의: 변경 전 반드시 영향 파악 필요!):**
  * `vm.swappiness`: 커널이 얼마나 적극적으로 메모리를 스왑 공간으로 내릴지 결정 (0 ~ 100). 낮을수록 덜 내림. RAM이 충분하다면 10 정도로 낮추는 것을 고려.
  * `net.ipv4.tcp_fin_timeout`: TCP 연결 종료 후 FIN-WAIT-2 상태 유지 시간 (초).
  * `net.core.somaxconn`: TCP 리스닝 소켓의 최대 연결 대기 큐 크기. 부하 높은 웹 서버 등에서 증가 고려.
  * `fs.file-max`: 시스템 전체에서 열 수 있는 최대 파일 핸들 수.
  * `kernel.shmmax`: 최대 공유 메모리 세그먼트 크기 (일부 데이터베이스 등에서 중요).

**!!! 경고: 커널 파라미터는 시스템 동작에 큰 영향을 미칩니다. 각 파라미터의 의미와 변경 시 발생할 수 있는 부작용을 정확히 이해하지 못한 상태에서 함부로 변경해서는 안 됩니다. 변경 전 반드시 관련 문서를 충분히 찾아보고, 테스트 환경에서 검증 후 적용해야 합니다 !!!**


## 19.5 서비스 최적화 (Service Optimization)

커널 파라미터 튜닝만으로는 부족한 경우가 많습니다. 실제 시스템 성능은 그 위에서 실행되는 **개별 서비스(애플리케이션)** 의 설정에 크게 좌우됩니다.

* 각 서비스(웹 서버, 데이터베이스 서버, 애플리케이션 서버 등)는 자체적인 **설정 파일**과 **튜닝 가능한 파라미터**들을 가지고 있습니다.
* **예시 (개념):**
  * **웹 서버 (Apache/Nginx):** 동시에 처리할 수 있는 클라이언트 요청 수(Worker 프로세스/스레드 수), Keep-Alive 설정, 캐싱 설정, Gzip 압축 활성화 등.
  * **데이터베이스 서버 (MySQL/PostgreSQL):** 메모리 버퍼/캐시 크기 설정(매우 중요!), 최대 동시 연결 수, 쿼리 캐시 설정, 테이블 인덱싱 전략 등.
  * **애플리케이션 자체:** 비효율적인 알고리즘 개선, 데이터베이스 쿼리 최적화, 불필요한 리소스 사용 줄이기 등 애플리케이션 코드 레벨의 최적화가 성능 향상에 가장 큰 영향을 미치는 경우가 많습니다.

각 서비스별 최적화는 해당 서비스의 공식 문서나 관련 커뮤니티 자료를 통해 학습해야 하는 전문 분야입니다.


## 결론

이번 챕터에서는 시스템 성능 문제 해결과 개선의 기초가 되는 **시스템 모니터링 및 최적화** 개념을 다루었습니다. 시스템 성능 분석의 기본 접근법과 주요 병목 지점(CPU, 메모리, 디스크 I/O, 네트워크 I/O)을 이해하고, 각 자원을 모니터링하기 위한 리눅스의 표준 도구들(`top`, `htop`, `uptime`, `mpstat`, `free`, `vmstat`, `iostat`, `iotop`, `iftop`, `nload`, `sar` 등)의 사용법을 익혔습니다.

또한, 시스템 튜닝의 기본적인 개념과 주의사항을 알아보고, 커널 파라미터를 `sysctl` 명령과 설정 파일을 통해 조정하는 방법을 배웠습니다. 마지막으로, 개별 서비스 자체의 설정 최적화와 애플리케이션 코드 최적화의 중요성에 대해서도 언급했습니다.

성능 모니터링과 최적화는 단발성 작업이 아니라, 시스템의 상태를 꾸준히 관찰하고 변화에 맞춰 지속적으로 개선해나가는 과정입니다. 특히 설정을 변경할 때는 항상 신중하게 접근하고, 변경의 영향을 충분히 검토하며, 가능하다면 테스트를 거치는 것이 중요합니다.

다음 Chapter 20에서는 현대적인 IT 인프라 운영에서 빼놓을 수 없는 **가상화(Virtualization)** 와 **컨테이너(Container)** 기술에 대해 알아보겠습니다.
