---
title:  프론트엔드에서의 데이터 지향 프로그래밍
---

## 1. 순수 함수와 불변 데이터 구조


> "데이터가 복잡한 게 아니다. 우리가 데이터를 다루는 방식이 복잡할 뿐이다. 불변성은 그 복잡성을 길들이는 가장 강력한 무기 중 하나다."

데이터 지향 프로그래밍(DOP)의 여정을 시작하는 첫걸음은 가장 근본적인 두 가지 원칙인 **순수 함수(Pure Functions)** 와 **불변 데이터 구조(Immutable Data Structures)** 를 이해하는 것입니다. 이 두 가지 개념은 '데이터와 로직의 분리'라는 핵심 사상을 구현하는 가장 강력하고 실용적인 도구입니다.

프론트엔드 애플리케이션은 본질적으로 '상태(State)'라는 데이터를 받아 'UI(View)'라는 또 다른 데이터(DOM 트리)로 변환하는 거대한 함수라고 볼 수 있습니다. 이 과정에서 예측 불가능한 변경, 복잡하게 얽힌 의존성, 추적하기 어려운 버그가 발생하며, 그 중심에는 거의 항상 '가변 상태(Mutable State)'와 '부수 효과(Side Effects)'가 있습니다.

본 장에서는 왜 순수 함수와 불변성이 현대 프론트엔드 아키텍처의 핵심 원칙으로 자리 잡았는지, 그리고 TypeScript를 사용해 이를 어떻게 효과적으로 구현할 수 있는지 깊이 있게 탐구합니다.

------


### 1.1. 순수 함수 (Pure Functions): 예측 가능한 로직


순수 함수는 함수형 프로그래밍의 핵심 개념으로, 다음 두 가지 조건을 만족하는 함수를 의미합니다.

1. **동일한 입력에 대해 항상 동일한 출력을 반환합니다.** (참조 투명성, Referential Transparency)
2. **어떠한 부수 효과(Side Effects)도 일으키지 않습니다.**


#### 1.1.1. 동일한 입력, 동일한 출력


함수의 출력값이 오직 입력 인자에만 의존한다는 의미입니다. 전역 변수, `Date.now()`, `Math.random()`, API 응답 등 외부의 어떤 값에도 영향을 받지 않습니다.

**[나쁜 예: 순수하지 않은 함수]**

```typescript
let globalTaxRate = 0.1;

// 👎 전역 변수에 의존하므로 순수하지 않다.
function calculatePriceWithTax(price: number): number {
  return price + price * globalTaxRate;
}

calculatePriceWithTax(100); // 110 (globalTaxRate가 0.1일 때)
globalTaxRate = 0.2; // 외부 상태 변경
calculatePriceWithTax(100); // 120 (동일한 입력 100에도 출력이 달라짐)

// 👎 외부 세계에 의존하므로 순수하지 않다.
function getGreeting(name: string): string {
  const hour = new Date().getHours(); // 실행 시점에 따라 값이 변한다.
  if (hour < 12) {
    return `Good morning, ${name}`;
  }
  return `Hello, ${name}`;
}
```

**[좋은 예: 순수 함수]**

```typescript
// 👍 모든 의존성을 '입력'으로 받는다.
function calculatePriceWithTaxPure(price: number, taxRate: number): number {
  return price + price * taxRate;
}

calculatePriceWithTaxPure(100, 0.1); // 언제나 110
calculatePriceWithTaxPure(100, 0.2); // 언제나 120

// 👍 의존성을 주입(DI)받는다.
function getGreetingPure(name: string, currentDate: Date): string {
  const hour = currentDate.getHours();
  if (hour < 12) {
    return `Good morning, ${name}`;
  }
  return `Hello, ${name}`;
}

getGreetingPure("Alice", new Date("2025-10-29T10:00:00")); // 언제나 'Good morning, Alice'
```


#### 1.1.2. 부수 효과 (Side Effects)의 부재


부수 효과는 함수가 자신의 스코프(범위)를 벗어나 외부의 상태를 변경하거나 상호작용하는 모든 행위를 의미합니다.

- 입력 인자(객체, 배열)를 직접 수정하는 행위
- 전역 변수를 수정하는 행위
- `console.log`, `alert` 등 콘솔이나 화면에 출력하는 행위
- API 요청, DB 접근 등 I/O 작업
- DOM을 직접 조작하는 행위

데이터 지향 프로그래밍에서 **가장 경계해야 할 부수 효과는 '입력 인자를 직접 수정하는 행위'** 입니다.

**[나쁜 예: 입력 인자를 수정하는(Mutating) 함수]**

```typescript
interface User {
  id: number;
  name: string;
  age: number;
  tags: string[];
}

// 👎 입력 객체 'user'와 그 내부의 배열 'tags'를 직접 수정한다. (최악!)
function addTag(user: User, newTag: string): void {
  user.tags.push(newTag); // 원본 데이터를 '파괴'
  user.age += 1; // 이것 역시 원본 수정
}

const alice: User = { id: 1, name: "Alice", age: 30, tags: ["dev"] };
console.log(alice); // { id: 1, name: "Alice", age: 30, tags: ["dev"] }

addTag(alice, "ts"); // 함수 실행

// 'alice'라는 원본 데이터가 예고 없이 변경되었다.
console.log(alice); // { id: 1, name: "Alice", age: 31, tags: ["dev", "ts"] }
```

이 코드는 `alice`라는 원본 데이터를 "파괴"했습니다. 프로그램의 다른 부분에서 `alice`의 30살 상태를 기대하고 있었다면, 이 코드는 심각한 버그를 유발합니다.

**[좋은 예: 새로운 데이터를 반환하는 순수 함수]**

```typescript
// 👍 입력 객체를 수정하지 않고, '새로운' 객체를 반환한다.
function addTagPure(user: User, newTag: string): User {
  // 1. 새로운 태그 배열 생성 (불변성)
  const newTags = [...user.tags, newTag];
  
  // 2. 새로운 사용자 객체 생성 (불변성)
  const newUser: User = {
    ...user, // 얕은 복사 (Shallow Copy)
    age: user.age + 1, // 값 수정
    tags: newTags,     // 새로운 배열 참조
  };
  
  return newUser;
}

const bob: User = { id: 2, name: "Bob", age: 25, tags: ["qa"] };
console.log(bob); // { id: 2, name: "Bob", age: 25, tags: ["qa"] }

const bobWithNewTag = addTagPure(bob, "automation"); // 함수 실행

// 'bob' 원본 데이터는 절대 변하지 않는다.
console.log(bob); // { id: 2, name: "Bob", age: 25, tags: ["qa"] }

// '새로운' 데이터가 생성되었다.
console.log(bobWithNewTag); // { id: 2, name: "Bob", age: 26, tags: ["qa", "automation"] }
```

`addTagPure` 함수는 이제 100번을 실행해도 `bob` 원본을 변경시키지 않으며, 항상 예측 가능한 새로운 `User` 객체를 반환합니다.

------


### 1.2. 불변 데이터 구조 (Immutable Data Structures): 신뢰할 수 있는 데이터


불변성(Immutability)은 **데이터가 생성된 후에는 절대 변경될 수 없다** 는 원칙입니다. 데이터를 "수정"해야 할 경우, 원본을 변경하는 대신 원본의 복사본을 만들고 그 복사본에 변경 사항을 적용한 **새로운 데이터** 를 만듭니다.


#### 1.2.1. 원시 값과 참조 값의 차이


JavaScript에서 `string`, `number`, `boolean`, `null`, `undefined`, `symbol`, `bigint`와 같은 **원시 값(Primitive Types)** 은 그 자체로 불변입니다.

```typescript
let a: string = "Hello";
let b = a; // 값이 복사됨
b = "World"; // 'b'에 새로운 값 'World'가 할당됨

console.log(a); // "Hello" (a는 절대 변하지 않음)
console.log(b); // "World"
```

문제는 항상 **참조 값(Reference Types)** , 즉 `객체(Object)`와 `배열(Array)`에서 발생합니다.

```typescript
let objA = { name: "Alice" };
let objB = objA; // '참조(주소)'가 복사됨

objB.name = "Bob"; // 'objB'를 수정했지만...

// 'objA'까지 함께 변경된다!
console.log(objA.name); // "Bob"
console.log(objA === objB); // true (두 변수는 같은 객체를 가리킴)
```

프론트엔드 상태의 99%는 객체와 배열로 이루어집니다. 이 "참조에 의한 동작" 특성이 바로 예측 불가능성의 근원입니다. 불변성은 이 문제를 정면으로 해결합니다.


#### 1.2.2. 불변성이 제공하는 핵심 이점


1. 예측 가능성 및 디버깅 용이성:

   데이터가 변하지 않기 때문에, 특정 시점의 데이터 스냅샷을 신뢰할 수 있습니다. "대체 이 데이터가 어디서 바뀐 거지?"라는 지옥 같은 디버깅에서 해방됩니다. 데이터의 변경은 오직 명시적인 '새 데이터 생성'을 통해서만 일어나므로, 변경 지점을 추적하기 쉽습니다.

2. 성능 최적화: 값비싼 비교 연산 회피:

   현대 프론트엔드 프레임워크(React, Vue 등)의 성능 최적화(Reconciliation)는 불변성을 전제로 합니다.

   두 개의 복잡한 중첩 객체나 거대한 배열이 "같은지" 비교하는 작업(`deepEqual`)은 매우 비쌉니다. 하지만 불변성이 보장된다면, 두 데이터가 같은지 비교하는 작업은 단순히 **참조(메모리 주소)가 같은지만 비교** 하면 됩니다 (`===`).

   TypeScript

   ```typescript
   // 불변성이 없다면, React는 상태가 변했는지 알기 위해
   // oldState의 모든 속성과 newState의 모든 속성을 재귀적으로 비교해야 함. (O(n))
   if (deepEqual(oldState, newState)) {
     // 리렌더링 안 함
   }
   
   // 불변성이 보장된다면,
   // 데이터가 변경되었다면 '반드시' 새로운 참조가 생성됨.
   // (O(1) 비교)
   if (oldState === newState) {
     // 참조가 같음 = 데이터가 변하지 않음 = 리렌더링 안 함
   }
   ```

   React의 `useMemo`, `useCallback`, `memo` HOC, Redux의 `useSelector` 등 모든 최적화 기법이 이 `===` 비교에 의존합니다.

3. 손쉬운 기능 구현 (시간 여행, Undo/Redo):

   데이터를 "수정"하는 대신 항상 "새로운 버전"을 생성하므로, 이전 상태들이 자동으로 보존됩니다. Redux DevTools의 '시간 여행 디버깅'이나 사용자의 '실행 취소(Undo)' 기능은 상태를 이전 버전의 스냅샷으로 그냥 "교체"하기만 하면 되므로 구현이 매우 간단해집니다.

------


### 1.3. TypeScript로 불변성 구현하기


JavaScript/TypeScript에서 불변성을 지키는 것은 "규칙"이므로 개발자의 노력이 필요합니다.


#### 1.3.1. TypeScript의 `readonly`와 `Readonly<T>`


TypeScript는 컴파일 시점에 불변성을 강제하는 `readonly` 키워드를 제공합니다.

```typescript
interface Point {
  readonly x: number;
  readonly y: number;
}

const p1: Point = { x: 10, y: 20 };
p1.x = 20; // 🛑 컴파일 오류: 'x' is a read-only property.

// 유틸리티 타입 Readonly<T>
type ReadonlyUser = Readonly<User>;

const readonlyAlice: ReadonlyUser = { id: 1, name: "Alice", age: 30, tags: ["dev"] };
readonlyAlice.age = 31; // 🛑 컴파일 오류
```

> 경고: readonly는 얕다(Shallow)!
>
> readonly는 객체의 1단계 속성만 막아줄 뿐, 중첩된 객체나 배열의 가변성까지 막아주지는 못합니다.

```typescript
const readonlyAlice: ReadonlyUser = { id: 1, name: "Alice", age: 30, tags: ["dev"] };

// readonlyAlice.tags = ["new"]; // 🛑 컴파일 오류 (tags 속성 자체를 교체하는 것은 막힘)

// 하지만...
readonlyAlice.tags.push("ts"); // ✅ 허용됨! 그리고 원본이 변경됨! (치명적)

console.log(readonlyAlice.tags); // ["dev", "ts"]
```


#### 1.3.2. 얕은 복사의 함정과 `as const`


`readonly`의 한계를 극복하고 더 강력한 불변성을 지향하기 위해 **`as const` (Const Assertions)** 를 사용할 수 있습니다.

```typescript
const config = {
  apiUrl: "/api/v1",
  timeout: 5000,
  features: {
    beta: false,
    logging: true
  }
} as const;

/*
'config'의 타입은 다음과 같이 추론됨:
{
  readonly apiUrl: "/api/v1";
  readonly timeout: 5000;
  readonly features: {
    readonly beta: false;
    readonly logging: true;
  };
}
*/

config.timeout = 3000; // 🛑 컴파일 오류
config.features.beta = true; // 🛑 컴파일 오류 (재귀적으로 readonly가 됨)
```

`as const`는 타입스크립트 레벨에서 매우 강력한 불변성을 제공합니다.


#### 1.3.3. JavaScript 문법을 활용한 불변 업데이트


가장 기본적인 방법은 전개 연산자(`...`)와 `map`, `filter` 같은 배열 메서드를 활용하는 것입니다.

**[배열 불변 업데이트]**

```typescript
const originalArray = [1, 2, 3, 4];
const itemToAdd = 5;
const indexToUpdate = 1;
const newItem = 99;
const indexToRemove = 2;

// 1. 항목 추가 (새 배열)
const added = [...originalArray, itemToAdd]; // [1, 2, 3, 4, 5]

// 2. 항목 수정 (새 배열)
const updated = originalArray.map((item, index) => 
  index === indexToUpdate ? newItem : item
); // [1, 99, 3, 4]

// 3. 항목 제거 (새 배열)
const removed = originalArray.filter((item, index) => 
  index !== indexToRemove
); // [1, 2, 4]

console.log(originalArray); // [1, 2, 3, 4] (원본은 안전)
```

**[객체 불변 업데이트]**

```typescript
const originalObject = {
  id: 1,
  name: "Alice",
  profile: {
    email: "alice@example.com",
    address: "Seoul"
  }
};

// 1. 속성 수정 (새 객체)
const updatedName = {
  ...originalObject,
  name: "Bob" // 'name' 속성만 덮어씀
};

// 2. 중첩 객체 속성 수정 (주의!)
const updatedEmail = {
  ...originalObject, // 1. 얕은 복사
  profile: {
    ...originalObject.profile, // 2. 중첩 객체도 얕은 복사
    email: "bob@example.com" // 3. 원하는 속성 덮어쓰기
  }
};

/*
originalObject === updatedName // false (참조가 다름)
originalObject.profile === updatedName.profile // true (profile 참조는 동일)
originalObject.profile === updatedEmail.profile // false (profile 참조가 다름)
*/
```

> 얕은 복사의 문제점:
>
> 위 예시처럼 중첩 구조가 깊어질수록 ... 연산자를 재귀적으로 사용해야 하며, 이는 코드를 장황하게 만들고 실수하기 쉽게 만듭니다. (예: profile 객체를 복사하는 것을 잊으면 originalObject의 profile이 변경됨)


#### 1.3.4. 실용적인 해결책: Immer.js


불변성을 지키기 위한 복잡한 스프레드 문법(`...`)은 번거롭습니다. `Immer.js`는 이 문제를 우아하게 해결합니다.

Immer는 **"불변성을 지키려 노력하지 말고, 그냥 데이터를 수정하세요. 나머지는 제가 알아서 할게요"** 라는 철학을 가집니다.

Immer는 '가상(Draft)' 상태를 제공하며, 개발자가 이 `draft`를 (마치 가변 데이터처럼) 편하게 수정하면, Immer가 그 변경 사항을 추적하여 원본 대신 안전하고 효율적인 **새로운 불변 객체** 를 생성해 줍니다.

```typescript
import { produce } from "immer";

const baseState: User = {
  id: 1,
  name: "Alice",
  age: 30,
  tags: ["dev"],
  profile: {
    email: "alice@example.com",
    address: "Seoul"
  }
};

// Immer의 produce 함수 사용
const nextState = produce(baseState, (draft) => {
  // 'draft'는 baseState의 프록시(Proxy) 객체
  
  // 1. 중첩 객체 속성 수정
  draft.profile.address = "Busan";
  
  // 2. 배열 수정
  draft.tags.push("react");
  
  // 3. 속성 수정
  draft.age += 1;
  
  // (return을 명시적으로 하지 않아도 됨)
});

// 1. 원본(baseState)은 절대 변경되지 않았습니다.
console.log(baseState.profile.address); // "Seoul"
console.log(baseState.tags);            // ["dev"]
console.log(baseState.age);             // 30

// 2. 변경 사항이 적용된 '새로운' 객체(nextState)가 생성되었습니다.
console.log(nextState.profile.address); // "Busan"
console.log(nextState.tags);            // ["dev", "react"]
console.log(nextState.age);             // 31

// 3. 변경되지 않은 부분은 참조를 재사용합니다 (구조적 공유)
console.log(baseState === nextState);             // false (객체는 다름)
console.log(baseState.profile === nextState.profile); // false (profile 객체는 다름)
console.log(baseState.name === nextState.name);   // "Alice" === "Alice"
```

Immer는 Redux Toolkit, Zustand 등 현대 상태 관리 라이브러리의 핵심 엔진으로 사용되며, 가독성과 불변성 유지라는 두 마리 토끼를 모두 잡게 해줍니다.

------


### 1.4. 프론트엔드 아키텍처에서의 적용


순수 함수와 불변성은 React, Redux, (그리고 데이터 지향 설계)의 심장입니다.


#### 1.4.1. React와 불변성


React의 상태 업데이트는 **반드시 불변성** 을 지켜야 합니다.

```typescript
function Counter() {
  const [count, setCount] = useState(0);

  // 'setCount(count + 1)'는 새로운 'number' 값을 전달 (원시 값은 불변)
  const handleClick = () => setCount(count + 1);
  
  // ...
}

function UserProfile() {
  const [user, setUser] = useState({ name: "Alice", age: 30 });

  const handleAgeUp = () => {
    // 👎 나쁜 예: 원본 상태 객체를 수정
    // user.age += 1;
    // setUser(user); // React는 'user' 참조가 같아서 변경을 감지 못함 (리렌더링 X)

    // 👍 좋은 예: 새로운 객체를 생성하여 전달
    setUser(currentUser => ({
      ...currentUser,
      age: currentUser.age + 1
    }));
  };
  
  // ...
}
```

React가 리렌더링을 결정하는 유일한 기준은 `oldState === newState`가 `false`일 때입니다. 불변성을 지키지 않으면 상태가 바뀌었음에도 React가 이를 인지하지 못해 UI가 갱신되지 않는 치명적인 버그가 발생합니다.


#### 1.4.2. Redux 리듀서 (Reducer)


Redux의 리듀서는 **반드시 순수 함수** 여야 합니다.

> 리듀서(Reducer) = (previousState, action) => newState

리듀서는 (이전 상태, 액션)이라는 **입력**을 받아, **새로운 상태** 라는 **출력**을 반환해야 합니다. 이 과정에서 절대 부수 효과(API 호출 등)가 있어서는 안 되며, `previousState`를 직접 수정해서도 안 됩니다.

```typescript
// Redux Toolkit과 Immer가 내장된 'createSlice' 예시

import { createSlice, PayloadAction } from '@reduxjs/toolkit';

interface CounterState {
  value: number;
}

const initialState: CounterState = { value: 0 };

const counterSlice = createSlice({
  name: 'counter',
  initialState,
  reducers: {
    // 'increment' 리듀서 함수
    increment: (state) => {
      // 🚨 주의: 이 코드는 Immer가 내부적으로 동작하기에 '안전'합니다.
      // Redux Toolkit은 'produce'를 내장하고 있어
      // 우리가 'draft' 상태를 수정하는 것처럼 코드를 짜도
      // 실제로는 불변성이 보장된 새로운 상태를 반환합니다.
      state.value += 1;
    },
    incrementByAmount: (state, action: PayloadAction<number>) => {
      state.value += action.payload;
    },
    // (이 리듀서들은 순수 함수로 취급됩니다)
  },
});

export const { increment, incrementByAmount } = counterSlice.actions;
export default counterSlice.reducer;
```

------


### 1.5. 결론: 데이터 지향의 견고한 토대


순수 함수는 우리의 로직(Logic)을 예측 가능하고 테스트하기 쉬운 독립적인 단위로 격리시킵니다.

불변 데이터 구조는 우리의 데이터(Data)를 신뢰할 수 있고 시간의 흐름에 따라 추적 가능하도록 보존합니다.

데이터 지향 프로그래밍은 결국 **데이터**와 **로직**을 명확히 분리하는 것에서 시작합니다.

- **데이터(Data):** 상태(State). 단순하고, 투명하며, **불변**해야 합니다.
- **로직(Logic):** 변환(Transformation). 이 데이터를 저 데이터로 바꾸는 **순수 함수** 의 집합이어야 합니다.

`UI = f(State)` 라는 유명한 공식에서, `State`는 **불변 데이터** 를 의미하며, `f`는 **순수 함수(또는 순수 컴포넌트)** 를 의미합니다.

이 견고한 토대 위에서, 우리는 '데이터 변환 파이프라인'을 설계하고, '부수 효과를 격리'하며, 복잡한 프론트엔드 애플리케이션을 단순하고 명료하게 구축할 준비를 마쳤습니다.

------

알겠습니다. 바로 이어서 제2장 '데이터 변환 파이프라인 설계' 집필을 시작하겠습니다.


## 2. 데이터 변환 파이프라인 설계


> "위대한 프론트엔드 아키텍처는 거대한 상태 기계가 아니다. 그것은 데이터가 한 형태에서 다른 형태로 흘러가는 잘 정돈된 파이프라인의 집합이다."

제1장에서 우리는 '순수 함수'와 '불변 데이터'라는 견고한 재료를 확보했습니다. 이제 이 재료들을 조립하여 실제 동작하는 시스템을 만들 차례입니다. 데이터 지향 프로그래밍에서 이 조립의 청사진이 바로 **데이터 변환 파이프라인(Data Transformation Pipeline)** 입니다.

프론트엔드 애플리케이션의 본질을 다시 생각해 봅시다.

1. 서버로부터 **Raw Data** (API 응답)가 도착합니다.
2. 이 데이터는 **Application State** (애플리케이션이 이해하는 형태, 예: 정규화된 상태)로 변환됩니다.
3. 이 상태는 다시 **Derived Data** (계산된 값, 예: 필터링/정렬된 목록)로 변환됩니다.
4. 최종적으로 이 데이터는 **View Model** (UI 렌더링에 필요한 데이터, 예: `props`)로 변환됩니다.
5. View Model은 **View**(DOM, HTML)로 렌더링됩니다.

이 모든 과정은 **데이터(Data)가 또 다른 데이터(Data)로 변환되는 과정의 연속** 입니다.

`Raw Data` → `f1` → `State` → `f2` → `Derived Data` → `f3` → `View Model` → `f4(React)` → `View`

여기서 `f1`, `f2`, `f3`가 바로 우리가 설계해야 할 '데이터 변환 파이프라인'이며, 이 함수들은 제1장에서 배운 **순수 함수** 여야 합니다.

본 장에서는 이 파이프라인을 어떻게 명확하고 효율적으로 설계하며, 왜 이것이 '데이터와 로직의 분리'의 핵심인지 깊이 있게 탐구합니다.

------


### 2.1. 파이프라인이란 무엇인가?


파이프라인은 단순히 함수를 연쇄적으로 연결하는(Function Chaining) 개념 그 이상입니다. 이는 **데이터 흐름의 방향성을 명확히 정의** 하는 아키텍처 패턴입니다.

- 데이터는 **단방향(Uni-directional)** 으로 흐릅니다. (예: Redux, Flux 패턴)
- 각 변환 단계(Stage)는 오직 이전 단계의 출력에만 의존합니다.
- 각 단계는 **순수 함수** 로 구성되어 독립적으로 테스트할 수 있습니다.
- 파이프라인 자체는 **선언적(Declarative)** 입니다. "무엇을" 할지 정의할 뿐, "언제" 실행할지(이벤트 핸들러, 훅)는 외부의 부수 효과 영역에서 결정합니다.

가장 단순한 파이프라인은 '함수 합성(Function Composition)'입니다.

```typescript
// B를 C로 변환하는 함수 g
const g = (b: B): C => { ... };

// A를 B로 변환하는 함수 f
const f = (a: A): B => { ... };

// A를 C로 변환하는 파이프라인 (f를 거친 후 g를 거침)
// 주의: 수학적 표기(g ∘ f)와 달리 코드 실행 순서는 보통 왼쪽에서 오른쪽임
const pipeline = (a: A): C => g(f(a));
```


#### 2.1.1. 파이프라인 설계의 이점


1. 명확한 관심사 분리 (SoC):

   데이터를 가져오는 로직(API), 데이터를 가공하는 로직(파이프라인), 데이터를 화면에 그리는 로직(컴포넌트)이 물리적으로 분리됩니다.

2. 테스트 용이성:

   각 변환 함수는 입/출력이 명확한 순수 함수이므로, Mock 데이터만 주입하면 완벽하게 단위 테스트가 가능합니다. UI나 네트워크 없이도 비즈니스 로직 전체를 검증할 수 있습니다.

3. 재사용성 및 조합성:

   f1, f2, f3... 같은 작은 변환 함수(빌딩 블록)들을 만들어두면, 이들을 다양한 순서로 조합하여 수많은 종류의 새로운 파이프라인을 즉시 만들 수 있습니다.

4. 디버깅 용이성:

   데이터 흐름이 f1 → f2 → f3로 고정되어 있으므로, 문제가 발생하면 각 단계 사이의 데이터 스냅샷만 확인하면 됩니다. f1의 출력은 정상인데 f2의 출력이 비정상이라면, 문제는 100% f2 함수 내부에 있습니다.

------


### 2.2. 파이프라인의 3단계: 입력, 변환, 출력


모든 데이터 파이프라인은 이 세 가지 명확한 단계를 가집니다.

1. **입력 (Input)** : 원천 데이터. (예: API 응답, 사용자 입력)
2. **변환 (Transformation)** : 하나 이상의 순수 함수로 구성된 로직.
3. **출력 (Output)** : 새로운 형태의 데이터. (예: 상태 객체, View Model)

프론트엔드에서 가장 중요한 파이프라인 중 하나는 **"API 응답을 애플리케이션 상태로 변환하는 파이프라인"** 입니다.


#### 2.2.1. 예시: 서버 데이터를 상태 데이터로 변환하기


서버는 보통 '서버 중심적인' 데이터 구조를 반환합니다.

```typescript
// 👎 입력 (Raw Data): 서버 API 응답
// 서버는 'User' 객체 안에 'posts'와 'comments'를 중첩(Nested)해서 줌
interface ApiPost {
  id: string;
  title: string;
  content: string;
  comments: ApiComment[]; // 중첩된 댓글
}

interface ApiComment {
  id: string;
  text: string;
  authorId: string;
}

interface ApiUser {
  userId: string;
  username: string;
  posts: ApiPost[]; // 중첩된 게시글
}
```

이 구조는 프론트엔드 상태로 관리하기에 최악입니다.

- 게시글(Post) 하나를 수정하려면 `user.posts[i]`를 찾아야 합니다.
- 댓글(Comment) 하나를 수정하려면 `user.posts[i].comments[j]`를 찾아야 합니다.
- 데이터가 중복됩니다 (만약 다른 API가 `ApiPost`만 따로 반환한다면?).

데이터 지향 설계에서는 이를 **정규화(Normalized)** 된 상태로 변환합니다. (자세한 내용은 3부 '데이터 정규화 전략'에서 다룹니다)

```typescript
// 👍 출력 (Application State): 정규화된 데이터
// 각 'Entity'를 ID 기반 맵(Map)으로 관리
interface Entities {
  users: Record<string, User>;
  posts: Record<string, Post>;
  comments: Record<string, Comment>;
}

// 상태는 '관계'를 ID로 저장
interface User {
  id: string;
  username: string;
  postIds: string[]; // 관계 (ID 참조)
}

interface Post {
  id: string;
  title: string;
  content: string;
  authorId: string;
  commentIds: string[]; // 관계 (ID 참조)
}

interface Comment {
  id: string;
  text: string;
  authorId: string;
  postId: string;
}
```


#### 2.2.2. 변환 파이프라인 구축


이제 `ApiUser`를 받아 저 `Entities` 구조로 변환하는 파이프라인(순수 함수)을 만듭니다.

```typescript
// 변환 파이프라인의 최종 출력 타입
interface NormalizedData {
  entities: Entities;
  result: { // 최상위 엔티티의 ID (이 경우 사용자 ID)
    user: string;
  };
}

// 💥 핵심: 데이터 변환 파이프라인
function normalizeUserData(apiUser: ApiUser): NormalizedData {
  // 초기 상태 (빈 껍데기)
  const normalized: NormalizedData = {
    entities: {
      users: {},
      posts: {},
      comments: {},
    },
    result: {
      user: apiUser.userId,
    },
  };

  // 파이프라인 1: Post와 Comment 처리
  apiUser.posts.forEach(apiPost => {
    // 1-1. Comment 정규화
    apiPost.comments.forEach(apiComment => {
      normalized.entities.comments[apiComment.id] = {
        id: apiComment.id,
        text: apiComment.text,
        authorId: apiComment.authorId,
        postId: apiPost.id, // 부모 Post ID 관계 설정
      };
    });

    // 1-2. Post 정규화
    normalized.entities.posts[apiPost.id] = {
      id: apiPost.id,
      title: apiPost.title,
      content: apiPost.content,
      authorId: apiUser.userId, // 부모 User ID 관계 설정
      commentIds: apiPost.comments.map(c => c.id), // Comment ID 목록
    };
  });

  // 파이프라인 2: User 처리
  normalized.entities.users[apiUser.userId] = {
    id: apiUser.userId,
    username: apiUser.username,
    postIds: apiUser.posts.map(p => p.id), // Post ID 목록
  };

  // 👍 불변하는 새로운 데이터를 반환
  return normalized;
}
```

`normalizeUserData` 함수는 **데이터(ApiUser)를 입력받아 데이터(NormalizedData)를 반환하는 완벽한 순수 함수** 입니다.

이 함수는 React에도, Redux에도, API 호출에도 전혀 의존하지 않습니다. 이 함수는 오직 '데이터 변환'이라는 자신의 책임에만 집중합니다. 이것이 '데이터와 로직의 분리'입니다.

------


### 2.3. 파이프라인 조합하기 (Piping)


파이프라인의 진정한 힘은 '조합(Composition)'에 있습니다. 위 `normalizeUserData` 함수는 거대하고 단일 책임 원칙(SRP)을 위배합니다. User, Post, Comment 처리가 모두 섞여 있습니다.

이것을 작은 파이프라인 조각(순수 함수)들로 분리해 봅시다.

```typescript
// 유틸리티: 두 Entities 객체를 병합하는 순수 함수
// (Immer를 사용하면 더 간단하지만, 기본에 충실하게 작성)
function mergeEntities(e1: Entities, e2: Entities): Entities {
  return {
    users: { ...e1.users, ...e2.users },
    posts: { ...e1.posts, ...e2.posts },
    comments: { ...e1.comments, ...e2.comments },
  };
}

// 파이프라인 조각 1: ApiComment[] -> Entities
function normalizeComments(apiComments: ApiComment[], postId: string): Entities {
  const comments: Record<string, Comment> = {};
  apiComments.forEach(apiComment => {
    comments[apiComment.id] = {
      id: apiComment.id,
      text: apiComment.text,
      authorId: apiComment.authorId,
      postId: postId,
    };
  });
  return { users: {}, posts: {}, comments };
}

// 파이프라인 조각 2: ApiPost -> Entities
// (이 함수는 내부적으로 normalizeComments 파이프라인을 사용)
function normalizePost(apiPost: ApiPost, authorId: string): Entities {
  // 1. 중첩된 댓글 파이프라인 실행
  const commentEntities = normalizeComments(apiPost.comments, apiPost.id);

  // 2. Post 엔티티 생성
  const post: Post = {
    id: apiPost.id,
    title: apiPost.title,
    content: apiPost.content,
    authorId: authorId,
    commentIds: apiPost.comments.map(c => c.id),
  };
  
  const postEntity = { [apiPost.id]: post };

  // 3. 댓글 엔티티와 게시글 엔티티 병합
  return mergeEntities(commentEntities, { users: {}, posts: postEntity, comments: {} });
}

// 파이프라인 조각 3: ApiUser -> NormalizedData
// (이 함수는 내부적으로 normalizePost 파이프라인을 사용)
function normalizeUser(apiUser: ApiUser): NormalizedData {
  let postEntities: Entities = { users: {}, posts: {}, comments: {} };

  // 1. 중첩된 게시글 파이프라인 실행 (forEach 대신 reduce 사용)
  postEntities = apiUser.posts.reduce(
    (accEntities, apiPost) => {
      const newEntities = normalizePost(apiPost, apiUser.userId);
      return mergeEntities(accEntities, newEntities);
    },
    postEntities // 초기값
  );

  // 2. User 엔티티 생성
  const user: User = {
    id: apiUser.userId,
    username: apiUser.username,
    postIds: apiUser.posts.map(p => p.id),
  };
  const userEntity = { [apiUser.userId]: user };
  
  // 3. 게시글/댓글 엔티티와 사용자 엔티티 병합
  const finalEntities = mergeEntities(postEntities, { users: userEntity, posts: {}, comments: {} });

  return {
    entities: finalEntities,
    result: { user: apiUser.userId },
  };
}
```

이제 `normalizeUser`라는 메인 파이프라인은 `normalizePost`를 호출하고, `normalizePost`는 `normalizeComments`를 호출합니다. 각 함수는 명확히 분리되었고, 독립적으로 테스트할 수 있으며, 재사용 가능합니다.

예를 들어, `ApiPost` 데이터만 따로 받는 API가 있다면, `normalizePost` 함수를 그대로 재사용하면 됩니다.


#### 2.3.1. `pipe` 유틸리티 사용하기


함수형 프로그래밍에서는 이 파이프라인 조합을 더 명시적으로 표현하기 위해 `pipe` 유틸리티 함수를 사용합니다.

```typescript
// pipe 유틸리티 함수 (간단한 버전)
type AnyFunction = (...args: any[]) => any;

function pipe<F extends AnyFunction[]>(...fns: F): 
  (initialValue: Parameters<F[0]>[0]) => ReturnType<F[F['length'] - 1]> {
  
  return (initialValue: Parameters<F[0]>[0]) =>
    fns.reduce((acc, fn) => fn(acc), initialValue);
}

// --- 파이프라인 정의 ---

// 단계 1: 입력(RawData)을 받음
function parseInput(input: string): { value: number } {
  const num = parseInt(input, 10);
  return { value: isNaN(num) ? 0 : num };
}

// 단계 2: 값에 10을 더함
function addTen(data: { value: number }): { value: number } {
  return { value: data.value + 10 };
}

// 단계 3: 값을 2배로 만듦
function doubleValue(data: { value: number }): { value: number } {
  return { value: data.value * 2 };
}

// 단계 4: 출력(ViewModel) 형태로 포맷팅
function formatOutput(data: { value: number }): string {
  return `최종 결과: ${data.value}`;
}

// 💥 데이터 변환 파이프라인 '선언'
const calculationPipeline = pipe(
  parseInput,   // string -> { value: number }
  addTen,       // { value: number } -> { value: number }
  doubleValue,  // { value: number } -> { value: number }
  formatOutput  // { value: number } -> string
);

// --- 파이프라인 '실행' (부수 효과가 발생하는 시점) ---
// (예: React 컴포넌트 내부)

const rawInput = "20";
const viewModel = calculationPipeline(rawInput); // "최종 결과: 60"

console.log(viewModel);
```

이 `calculationPipeline`은 **로직의 청사진** 입니다. 이 청사진은 React 컴포넌트에서도, Node.js 서버에서도, 테스트 코드에서도 동일하게 동작합니다.

------


### 2.4. 파이프라인과 부수 효과


데이터 지향 프로그래밍은 부수 효과(Side Effects)를 부정하지 않습니다. 오히려 **부수 효과를 파이프라인의 '외부'로 명확하게 격리** 할 것을 요구합니다. (다음 장에서 자세히 다룹니다)

- **데이터 변환 파이프라인 (순수 영역)** :
  - `normalizeUser(data)`
  - `filterVisibleTodos(state, filter)`
  - `calculateTotalPrice(cartItems)`
  - 이 함수들은 '무엇을' 할지(What)만 정의합니다.
- **부수 효과 실행자 (불순한 영역)** :
  - `useEffect`, `useQuery` (데이터 페칭)
  - Redux `thunk`, `saga` (비동기 로직)
  - `onClick`, `onSubmit` (이벤트 핸들러)
  - 이 함수들은 '언제' 파이프라인을 실행할지(When) 결정합니다.

**[나쁜 예: 파이프라인과 부수 효과의 결합]**

```typescript
// 👎 로직과 부수 효과가 섞여있다.
// 테스트하기 극도로 어렵다. (fetch, setState를 모두 mock해야 함)
function fetchAndNormalizeUser(userId: string, setState: Function) {
  fetch(`/api/users/${userId}`)
    .then(res => res.json())
    .then(apiUser => {
      // 1. 변환 로직 (파이프라인)
      const normalized = normalizeUser(apiUser); // (순수 함수 호출)
      
      // 2. 부수 효과 (상태 변경)
      setState(normalized); 
    })
    .catch(err => {
      // 3. 또 다른 부수 효과 (로깅)
      console.error(err); 
    });
}
```

**[좋은 예: 파이프라인과 부수 효과의 분리]**

```typescript
// 👍 1. 순수 데이터 변환 파이프라인 (로직)
// (위에서 정의한 normalizeUser 함수)
// 이 함수는 100% 테스트 가능


// 👍 2. 부수 효과 실행자 (React 컴포넌트)
// (React Query나 SWR 사용을 권장하지만, 기본 예시)
function useUser(userId: string) {
  const [normalizedData, setNormalizedData] = useState<NormalizedData | null>(null);
  const [error, setError] = useState<Error | null>(null);

  useEffect(() => {
    // '언제' 실행할지 결정
    if (!userId) return;

    // '어떻게' 부수 효과를 실행할지 결정
    fetch(`/api/users/${userId}`)
      .then(res => res.json())
      .then(apiUser => {
        // '어떤' 로직을 사용할지 결정
        // 💥 순수 파이프라인 호출 💥
        const normalized = normalizeUser(apiUser);
        
        // 상태 업데이트 (부수 효과)
        setNormalizedData(normalized);
      })
      .catch(err => {
        // 에러 상태 업데이트 (부수 효과)
        setError(err);
      });
  }, [userId]); // '언제' 다시 실행할지 결정

  return { data: normalizedData, error };
}
```

`useUser` 훅은 **오케스트레이터(Orchestrator)** 역할을 합니다. 데이터를 가져오고, `normalizeUser`라는 **순수 로직(파이프라인)** 을 호출한 뒤, 그 결과를 상태에 반영합니다.

로직(`normalizeUser`)은 이제 재사용 가능하며, `useUser` 훅은 `normalizeUser`의 내부 구현을 전혀 몰라도 됩니다. 이것이 데이터 지향 설계의 핵심입니다.

------


### 2.5. 결론: 흐름으로서의 로직


데이터 변환 파이프라인은 '데이터와 로직의 분리'를 구현하는 동적인 청사진입니다.

- 로직을 **작고, 순수하며, 조합 가능한 함수 조각** 들로 나눕니다.
- 이 함수 조각들을 `pipe`로 연결하여 **데이터가 흘러가는 명확한 경로** 를 정의합니다.
- 이 파이프라인은 애플리케이션의 핵심 비즈니스 로직 그 자체가 됩니다.
- 컴포넌트나 훅은 이 순수한 파이프라인을 가져와 '실행'만 시킬 뿐, 로직의 구체적인 내용에는 관여하지 않습니다.

파이프라인 설계를 통해 우리는 복잡한 비즈니스 요구사항을 '데이터가 A에서 B로, B에서 C로 변환되는 과정'이라는 단순하고 예측 가능한 흐름으로 치환할 수 있습니다.

이제 이 '순수한' 파이프라인 세상과 '더러운' 실제 세계(API, DOM, 사용자 입력)가 만나는 지점, 즉 '부수 효과'를 어떻게 격리하고 관리할지 알아볼 차례입니다.

------

네, 알겠습니다. 제1부의 마지막 장이자 데이터 지향 프로그래밍의 핵심 원칙을 완성하는 '부수 효과 격리'에 대해이어서 집필하겠습니다.

------


## 3. 비즈니스 로직에서 부수효과 격리하기


> "순수함(Purity)은 전염성이 없다. 하지만 불순함(Impurity)은 치명적인 전염병이다. 단 하나의 부수 효과가 당신의 함수 전체를, 나아가 시스템 전체를 오염시킬 수 있다. 우리의 임무는 방화벽을 세우는 것이다."

제1장과 제2장에서 우리는 순수 함수와 불변 데이터를 재료로 삼아 예측 가능하고 테스트하기 쉬운 '데이터 변환 파이프라인'을 구축했습니다. 우리는 `f(data) = newData`라는 완벽하게 격리된 '순수(Pure)의 세계'를 만들었습니다.

하지만 프론트엔드 애플리케이션은 이 순수의 세계에만 머무를 수 없습니다. 우리는 필연적으로 '불순(Impure)한 실제 세계'와 상호작용해야 합니다.

- 네트워크에 API를 요청해야 합니다. (`fetch`)
- 사용자 이벤트를 받아야 합니다. (`onClick`)
- 브라우저 저장소에 데이터를 써야 합니다. (`localStorage.setItem`)
- 타이머를 설정해야 합니다. (`setTimeout`)
- DOM에 무언가를 렌더링해야 합니다. (`setState`를 통한 React의 렌더링)

이 모든 행위가 바로 **부수 효과(Side Effects)** 입니다.

데이터 지향 프로그래밍은 부수 효과를 제거하려는 시도가 아닙니다. 그것은 불가능합니다. 대신, **부수 효과를 식별하고, 제어하며, 우리의 핵심 비즈니스 로직으로부터 명확하게 '격리'하는 것** 을 목표로 합니다.

본 장에서는 이 '격리'가 왜 중요한지, 그리고 TypeScript를 사용하여 어떻게 효과적으로 부수 효과라는 야수를 길들일 수 있는지 탐구합니다.

------


### 3.1. 부수 효과: 예측 불가능성의 근원


부수 효과는 함수가 자신의 스코프(범위)를 벗어나 외부 세계와 상호작용하거나 외부의 상태를 변경하는 모든 행위를 의미합니다.

제1장에서 언급했듯이, 가장 흔한 부수 효과는 다음과 같습니다.

- **네트워크 I/O** : `fetch`, `axios`를 사용한 API 호출
- **스토리지 I/O** : `localStorage.setItem`, `sessionStorage.getItem`, `IndexedDB` 접근
- **DOM 조작** : `document.getElementById` (React의 `setState`나 `render`도 궁극적으로는 DOM 조작이라는 부수 효과를 '스케줄링'합니다)
- **시간 의존** : `new Date()`, `Date.now()`, `setTimeout`
- **전역 상태 변경** : 전역 변수, `window` 객체 수정
- **로깅**: `console.log` (엄밀히 말해 외부 시스템(콘솔)과 상호작용)

이러한 부수 효과가 비즈니스 로직(데이터 변환 파이프라인)과 뒤섞였을 때, 끔찍한 문제들이 발생합니다.


#### 3.1.1. 테스트의 저주


가장 즉각적인 고통은 '테스트 불가능한 코드'의 탄생입니다.

**[나쁜 예: 로직과 부수 효과가 결합된 함수]**

```typescript
// 👎 로직(데이터 필터링)과 부수 효과(fetch)가 끔찍하게 섞여있다.
async function getActiveUsersAndNotify(): Promise<User[]> {
  try {
    // 1. 부수 효과 (네트워크)
    const response = await fetch('/api/users');
    const users: User[] = await response.json();

    // 2. 비즈니스 로직 (데이터 변환)
    const activeUsers = users.filter(user => user.status === 'active');
    
    // 3. 부수 효과 (로깅)
    console.log(`${activeUsers.length}명의 활성 사용자 발견`);
    
    // 4. 또 다른 부수 효과 (네트워크)
    if (activeUsers.length > 0) {
      await fetch('/api/notify', {
        method: 'POST',
        body: JSON.stringify({ message: `활성 사용자: ${activeUsers.length}명` }),
      });
    }

    // 5. 비즈니스 로직의 '결과' 반환
    return activeUsers;
    
  } catch (error) {
    // 6. 또 다른 부수 효과 (에러 로깅)
    console.error('사용자 데이터 처리 실패:', error);
    return []; // 7. 로직의 '대체' 결과 반환
  }
}
```

이 `getActiveUsersAndNotify` 함수를 어떻게 단위 테스트할 수 있을까요?

- `fetch` 함수를 모킹(Mocking)해야 합니다.
- `fetch`가 두 번 호출되는데, 첫 번째 호출과 두 번째 호출에 다른 응답을 모킹해야 합니다.
- `response.json()`을 모킹해야 합니다.
- `console.log`와 `console.error`가 올바르게 호출되었는지 감시(Spying)해야 합니다.
- 네트워크 실패 케이스(try/catch)를 테스트해야 합니다.

이 함수의 핵심 비즈니스 로직은 `users.filter(user => user.status === 'active')`라는 **단 한 줄** 입니다. 이 한 줄을 테스트하기 위해 우리는 수십 줄의 모킹 코드를 작성해야 합니다.


#### 3.1.2. 예측 불가능성과 재사용성 저하


- **예측 불가능성** : 이 함수는 네트워크 상태에 따라, `/api/users` 응답 내용에 따라, `/api/notify`의 성공 여부에 따라 완전히 다른 결과를 반환하거나 에러를 던집니다. '동일한 입력(없음)에 대해 동일한 출력을 반환'하는 순수 함수의 원칙이 완전히 무너졌습니다.
- **재사용성 저하** : 만약 "비활성 사용자(inactive users)"를 찾는 로직이 필요하다면 어떻게 할까요? 이 함수를 재사용할 수 없습니다. "알림(notify)을 보내지 않고" 활성 사용자를 찾고 싶다면? 역시 재사용할 수 없습니다. 로직과 부수 효과가 강하게 결합(Tightly Coupled)되어 있기 때문입니다.

------


### 3.2. 핵심 전략: 순수 코어와 불순한 쉘 (Pure Core, Impure Shell)


이 문제를 해결하기 위한 데이터 지향 프로그래밍의 핵심 아키텍처 패턴이 바로 **'순수 코어, 불순한 쉘'** 입니다.

애플리케이션을 두 개의 영역으로 명확히 구분하는 것입니다.

1. **순수 코어 (Pure Core) / 비즈니스 로직** :

   - 애플리케이션의 '두뇌'입니다.
   - 오직 순수 함수와 불변 데이터 구조로만 구성됩니다. (제1장)
   - 데이터 변환 파이프라인(제2장)이 여기에 속합니다.
   - `f(data) = newData` 형태의 함수들입니다.
   - 예: `filterActiveUsers(users)`, `normalizeApiResponse(response)`, `calculateCartTotal(items)`.
   - 이 영역은 **절대** 외부 세계(API, DOM, `localStorage`)에 대해 알지 못해야 합니다.

2. **불순한 쉘 (Impure Shell) / 실행 영역** :

   - 애플리케이션의 '손발'입니다.

   - 모든 부수 효과는 **오직** 이 영역에서만 발생해야 합니다.

   - 예: React의 `useEffect`, `useQuery`, 이벤트 핸들러(`onClick`), Redux Thunk/Saga, Zustand의 비동기 `actions`.

   - 이 영역의 역할은 '오케스트레이션(Orchestration)'입니다.

     a. 부수 효과를 실행합니다. (예: fetch 호출)

     b. 부수 효과의 **결과(데이터)** 를 얻습니다. (예: response.json())

     c. 이 데이터를 '순수 코어'의 파이프라인에 주입합니다. (예: filterActiveUsers(data))

     d. 파이프라인이 반환한 **'새로운 데이터'** 를 받습니다.

     e. 이 새로운 데이터로 또 다른 부수 효과를 실행합니다. (예: setState(newData), localStorage.setItem(newData))

------


### 3.3. 격리 기법 및 TypeScript 예제


이제 3.1.1의 '나쁜 예'를 '순수 코어'와 '불순한 쉘'로 리팩토링해 보겠습니다.


#### 3.3.1. 1단계: 순수 코어(로직) 분리하기


먼저, 모든 비즈니스 로직을 순수 함수로 추출합니다. 이 함수들은 오직 데이터에만 의존합니다.

```typescript
/*
 * 파일명: userLogic.ts (순수 코어 영역)
 * 이 파일은 브라우저 API(fetch, console)나 React에 의존하지 않습니다.
 */

interface User {
  id: number;
  name: string;
  status: 'active' | 'inactive';
}

// 👍 순수 함수 1: 활성 사용자 필터링
export function filterActiveUsers(users: User[]): User[] {
  return users.filter(user => user.status === 'active');
}

// 👍 순수 함수 2: 알림 메시지 생성
// (로직이 복잡해질수록 이 또한 분리하는 것이 좋습니다)
export function createNotificationMessage(activeUsers: User[]): string | null {
  if (activeUsers.length === 0) {
    return null; // 메시지를 보낼 필요 없음
  }
  return `활성 사용자: ${activeUsers.length}명`;
}
```

이 `userLogic.ts` 파일은 이제 100% 단위 테스트가 가능합니다.

```typescript
// userLogic.test.ts
import { filterActiveUsers, createNotificationMessage } from './userLogic';

test('활성 사용자만 필터링해야 한다', () => {
  const users = [
    { id: 1, name: 'Alice', status: 'active' },
    { id: 2, name: 'Bob', status: 'inactive' },
    { id: 3, name: 'Charlie', status: 'active' },
  ];
  const expected = [
    { id: 1, name: 'Alice', status: 'active' },
    { id: 3, name: 'Charlie', status: 'active' },
  ];
  expect(filterActiveUsers(users)).toEqual(expected);
});

test('알림 메시지를 올바르게 생성해야 한다', () => {
  const activeUsers = [{ id: 1, name: 'Alice', status: 'active' }];
  expect(createNotificationMessage(activeUsers)).toBe('활성 사용자: 1명');
});

test('활성 사용자가 없으면 null을 반환해야 한다', () => {
  expect(createNotificationMessage([])).toBeNull();
});
```

모킹(Mocking)이 전혀 필요 없습니다. 오직 데이터 입/출력만 검증합니다.


#### 3.3.2. 2단계: 불순한 쉘(I/O) 분리하기


다음으로, 부수 효과 자체도 '최대한 멍청하게(Dumb)' 만듭니다. 즉, 데이터 I/O만 담당하는 함수로 분리합니다.

```typescript
/*
 * 파일명: userApi.ts (불순한 쉘의 일부 - API 계층)
 * 이 파일은 '어떻게' 데이터를 가져오고 보내는지만 압니다.
 */

// API 응답 타입 정의 (중요!)
interface ApiResponse {
  users: User[]; // (실제로는 User 타입과 다를 수 있지만, 예시상 동일하게)
}

// 👍 부수 효과 1: 사용자 목록 가져오기
export async function fetchUsers(): Promise<User[]> {
  const response = await fetch('/api/users');
  if (!response.ok) {
    throw new Error('사용자 목록 페치 실패');
  }
  // (여기서 응답을 User[]로 변환하는 최소한의 파싱은 허용)
  const data: ApiResponse = await response.json(); 
  return data.users;
}

// 👍 부수 효과 2: 알림 보내기
export async function postNotification(message: string): Promise<void> {
  const response = await fetch('/api/notify', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message }),
  });
  if (!response.ok) {
    throw new Error('알림 전송 실패');
  }
}
```

이 `userApi.ts`의 함수들은 여전히 부수 효과를 포함하지만, **비즈니스 로직(`filter`, `createMessage`)을 포함하지 않습니다.** 오직 I/O만 담당합니다.


#### 3.3.3. 3단계: 쉘에서 코어 오케스트레이션하기


이제, 이 두 영역을 조율하는 '최상위 불순한 쉘'을 만듭니다. React 환경이라면 이 역할은 Custom Hook이나 이벤트 핸들러가 맡게 됩니다.

```typescript
/*
 * 파일명: useUserNotifier.ts (불순한 쉘 - React Hook)
 * 이 훅은 React와 API, 로직을 '조율(Orchestrate)'합니다.
 */

import { useState, useEffect } from 'react';
import { fetchUsers, postNotification } from './userApi'; // 불순한 I/O
import { filterActiveUsers, createNotificationMessage } from './userLogic'; // 순수한 로직

interface UseUserNotifierResult {
  isLoading: boolean;
  activeUsers: User[];
  error: Error | null;
}

export function useUserNotifier(notify: boolean): UseUserNotifierResult {
  const [isLoading, setIsLoading] = useState(false);
  const [activeUsers, setActiveUsers] = useState<User[]>([]);
  const [error, setError] = useState<Error | null>(null);

  useEffect(() => {
    // 이것이 '오케스트레이터' 함수입니다.
    async function runProcess() {
      setIsLoading(true);
      setError(null);
      
      try {
        // 1. 부수 효과 실행 (I/O)
        const allUsers = await fetchUsers();

        // 2. 순수 코어 호출 (로직) 💥
        const filteredUsers = filterActiveUsers(allUsers);
        
        // 3. 부수 효과 실행 (상태 업데이트)
        setActiveUsers(filteredUsers);

        // (조건부 로직)
        if (notify) {
          // 4. 순수 코어 호출 (로직) 💥
          const message = createNotificationMessage(filteredUsers);

          if (message) {
            // 5. 부수 효과 실행 (I/O)
            await postNotification(message);
          }
        }
        
      } catch (err) {
        // 6. 부수 효과 실행 (에러 상태 업데이트)
        setError(err as Error);
      } finally {
        // 7. 부수 효과 실행 (로딩 상태 업데이트)
        setIsLoading(false);
      }
    }

    runProcess();
  }, [notify]); // 의존성 배열

  return { isLoading, activeUsers, error };
}
```

이제 우리는 완벽하게 분리된 아키텍처를 갖추었습니다.

- `userLogic.ts` (코어): 비즈니스 규칙. 100% 테스트 가능. 재사용 가능.
- `userApi.ts` (쉘): 네트워크 통신. (필요시 이 부분만 모킹하여 테스트)
- `useUserNotifier.ts` (쉘): 이 둘을 조립하는 접착제.

만약 "알림 없이 활성 사용자만 UI에 표시"하는 기능이 필요하다면?

fetchUsers()와 filterActiveUsers()만 호출하는 새로운 훅을 쉽게 만들 수 있습니다. 로직은 완벽히 재사용됩니다.

------


### 3.4. 상태 관리 라이브러리와의 관계


이 '순수 코어 / 불순한 쉘' 패턴은 모든 현대 프론트엔드 상태 관리 라이브러리의 근간입니다.


### Redux


- **순수 코어** : **리듀서(Reducer)** . `(state, action) => newState`. 리듀서는 부수 효과가 금지된, 가장 순수한 영역입니다.
- **불순한 쉘** : **미들웨어(Middleware)** (예: Redux Thunk, Redux Saga).
  - **Thunk**: `fetch`를 호출하고(`dispatch(fetchStart())`), 응답을 받아 `normalize`(순수 파이프라인)를 실행한 뒤, 그 결과를 `dispatch(fetchSuccess(normalizedData))`로 리듀서(순수 코어)에 전달합니다.
  - **Saga**: 부수 효과 자체를 '선언적'으로 관리하는(예: `yield call(api.fetchUsers)`) 더 정교한 쉘입니다.


### Zustand / Jotai / Recoil


- **순수 코어** : 상태를 정의하는 '아톰(Atom)' 또는 `create` 함수의 `set`을 호출하는 순수 로직. (예: `set({ count: state.count + 1 })`)
- **불순한 쉘** : `create` 함수 내부에 정의된 비동기 `action` 함수.

```typescript
// Zustand 예시
import { create } from 'zustand';
import { fetchUsers, postNotification } from './userApi';
import { filterActiveUsers, createNotificationMessage } from './userLogic';

interface UserStore {
  users: User[];
  isLoading: boolean;
  
  // '불순한 쉘' (Action)
  loadAndFilterUsers: () => Promise<void>; 
}

const useUserStore = create<UserStore>((set, get) => ({
  users: [],
  isLoading: false,
  
  loadAndFilterUsers: async () => {
    set({ isLoading: true }); // 부수 효과 (상태 변경)
    try {
      const allUsers = await fetchUsers(); // 부수 효과 (I/O)
      
      // 순수 코어(로직) 호출 💥
      const activeUsers = filterActiveUsers(allUsers); 
      
      set({ users: activeUsers, isLoading: false }); // 부수 효과 (상태 변경)
    } catch (error) {
      set({ isLoading: false }); // 부수 효과 (상태 변경)
    }
  },
}));
```

`loadAndFilterUsers` 함수는 `fetch`를 호출하고 `set`을 호출하는 '불순한 쉘'의 오케스트레이터입니다. 그리고 그 안에서 `filterActiveUsers`라는 '순수 코어'를 사용합니다.

------


### 3.5. 결론: 격리를 통한 자유


제1부 '기초 개념 및 패러다임'의 여정은 '데이터와 로직의 분리'라는 하나의 목표를 향해 달려왔습니다.

1. **순수 함수와 불변 데이터 (1장)** : 우리의 '로직'과 '데이터'를 신뢰할 수 있는 재료로 만들었습니다.
2. **데이터 변환 파이프라인 (2장)** : 이 순수한 재료들을 조립하여 '로직의 흐름'을 설계했습니다.
3. **부수 효과 격리 (3장)** : 이 '순수한 로직'을 '불순한 현실'로부터 보호하는 방화벽을 세웠습니다.

부수 효과를 비즈니스 로직에서 격리함으로써, 우리는 역설적으로 '자유'를 얻습니다.

- **테스트로부터의 자유** : 모킹의 지옥에서 벗어나 간단한 입/출력 테스트만으로 핵심 로직을 검증할 수 있습니다.
- **리팩토링의 자유** : `userLogic.ts`의 필터링 규칙을 변경해도 API나 React 훅 코드는 한 줄도 건드릴 필요가 없습니다.
- **재사용의 자유** : `filterActiveUsers` 로직은 웹, 모바일, 서버 어디서든 재사용할 수 있습니다.

이제 우리는 단단한 기초를 다졌습니다. '데이터'와 '로직'을 어떻게 다루어야 하는지 배웠습니다. 다음 제2부 '상태 관리의 데이터 중심 접근'에서는 이 원칙을 바탕으로 애플리케이션의 가장 중심이 되는 '상태(State)' 그 자체를 어떻게 데이터 지향적으로 설계하고 관리할 것인지 깊이 있게 탐구할 것입니다.

------

네, 알겠습니다. 데이터 지향 프로그래밍의 핵심인 '상태' 그 자체의 설계에 대해 다루는 제2부의 첫 번째 장을 시작하겠습니다.

------


## 4. 정규화(normalization)된 상태 구조 설계


> "데이터는 중력을 가지고 있다. 그리고 중복된 데이터는 필연적으로 비일관성이라는 블랙홀로 붕괴한다. 정규화는 이 중력을 길들이고, 단 하나의 진실만을 남기는 설계의 기술이다."

제1부에서 우리는 '데이터와 로직'을 분리하는 원칙을 확립했습니다. 순수한 함수(로직)를 불순한 세계(부수 효과)로부터 격리하고, 이 로직들을 파이프라인으로 연결했습니다. 이제 우리는 이 파이프라인이 처리하는 대상, 즉 애플리케이션의 심장인 **'상태(State)'** 그 자체의 '구조'에 대해 깊이 파고들어야 합니다.

데이터를 어떻게 구조화하는지는 애플리케이션의 복잡성, 성능, 그리고 유지보수성을 결정하는 가장 중요한 요소입니다.

대부분의 프론트엔드 애플리케이션은 **'API가 주는 대로(API-shaped)'** 상태를 저장하려는 안일한 함정에 빠집니다. 서버가 중첩된(nested) JSON을 반환하면, 그 중첩된 구조를 그대로 `useState`나 Redux 스토어에 저장합니다. 이는 재앙의 시작입니다.

본 장에서는 데이터베이스 설계의 핵심 원칙인 **정규화(Normalization)** 를 프론트엔드 상태 관리에 적용하는 방법을 탐구합니다. 왜 중첩된 구조가 나쁜지, 그리고 이를 어떻게 '평탄화(flattening)'하여 예측 가능하고 효율적인 상태 저장소를 설계하는지 TypeScript 예제와 함께 상세히 다룹니다.

------


### 4.1. 지옥의 문: 중첩된 상태 (Denormalized State)의 문제점


'비정규화(Denormalization)' 또는 '중첩'된 상태는 데이터를 사용하는 UI 구조와 유사하게 데이터를 구성하는 방식입니다. 블로그 애플리케이션을 예로 들어보겠습니다.

**[나쁜 예: API가 반환한 중첩된(Nested) 데이터 구조]**

```typescript
// API 응답 (/api/posts/1)
const apiResponse = {
  postId: "p1",
  author: {
    userId: "u1",
    name: "Alice",
  },
  title: "정규화에 대하여",
  body: "...",
  comments: [
    {
      commentId: "c1",
      commenter: {
        userId: "u2",
        name: "Bob",
      },
      text: "좋은 글입니다.",
    },
    {
      commentId: "c2",
      commenter: {
        userId: "u1",
        name: "Alice", // 🚨 'Alice' 데이터 중복!
      },
      text: "감사합니다.",
    },
  ],
};

// 이 구조를 그대로 상태에 저장한다고 가정
const state = {
  post: apiResponse,
  isLoading: false,
};
```

이 구조는 얼핏 보기에 `post.comments[0].text`처럼 접근하기 쉬워 보이지만, 애플리케이션이 조금만 복잡해져도 다음과 같은 심각한 문제에 직면합니다.

1. **데이터 중복 (Data Duplication)** :

   - 위 예시에서 'Alice'(`u1`)는 게시글의 `author`이자 `comments[1].commenter`입니다. 'Alice'의 이름이 "Alice Kim"으로 변경된다면, `post.author.name`과 `post.comments[1].commenter.name`을 **모두** 찾아 변경해야 합니다. 하나라도 놓치면 데이터는 비일관성 상태에 빠집니다.
   - 만약 다른 게시글(`p2`)도 'Alice'가 작성했다면, `state.posts['p2'].author.name`도 변경해야 합니다.

2. **극도로 어려운 업데이트 로직 (Complex Updates)** :

   - **요구사항**: "댓글 `c1`의 텍스트를 '수정된 텍스트'로 변경하라."
   - 불변성을 지키면서 이 업데이트를 수행하는 코드는 지옥 그 자체입니다.

   ```typescript
   // 👎 'c1' 댓글 하나를 수정하기 위한 끔찍한 불변 업데이트
   const newText = "수정된 텍스트";
   const commentIdToUpdate = "c1";
   
   const newState = {
     ...state,
     post: {
       ...state.post,
       comments: state.post.comments.map(comment => {
         // 1. 수정할 댓글을 찾는다
         if (comment.commentId === commentIdToUpdate) {
           // 2. 찾았으면 '새로운' 댓글 객체를 반환
           return {
             ...comment,
             text: newText,
           };
         }
         // 3. 아니면 원본 반환
         return comment;
       }),
     },
   };
   ```

   - 이 코드는 중첩이 단 2단계일 때 이 정도입니다. 3, 4단계로 깊어지면 코드는 장황해지고 버그를 유발하기 쉬워집니다. `immer.js`를 사용하면 `draft.post.comments[0].text = newText`로 간소화할 순 있지만, **'어떤' 댓글을 수정할지 찾기 위해 여전히 `find`나 `map`을 사용해야 하는** 근본적인 탐색 문제는 해결되지 않습니다.

3. **참조 비일관성 (Reference Instability)** :

   - 만약 `state.post.author` 객체를 React 컴포넌트(`UserProfile`)의 `prop`으로 전달했다고 가정해 봅시다.
   - 위의 '댓글 수정' 로직이 실행되면, `newState.post`는 새로운 객체가 됩니다. 이 `post` 객체를 `prop`으로 받는 모든 컴포넌트가 리렌더링됩니다.
   - `newState.post.author`는 `...state.post`로 인해 새로운 참조를 갖진 않지만 (얕은 복사), 만약 `post` 자체가 교체되면 `author` 참조도 깨질 수 있습니다.
   - 무엇보다, `c1` 댓글과 아무 상관없는 `c2` 댓글 컴포넌트도 `comments` 배열이 새로 생성(`map`으로 인해)되었기 때문에 불필요한 리렌더링이 발생할 수 있습니다.

------


### 4.2. 해결책: 상태 정규화 (State Normalization)


정규화는 이 모든 문제의 근본 원인인 **'중복'** 과 **'중첩'** 을 제거하는 프로세스입니다.

아이디어는 간단합니다. "애플리케이션 상태를 작은 데이터베이스처럼 취급하라."

데이터베이스가 관계를 표현하기 위해 '외래 키(Foreign Key)'를 사용하듯, 프론트엔드 상태는 'ID 참조'를 사용합니다.

정규화된 상태는 다음 세 가지 원칙을 따릅니다.

1. **엔티티(Entities) 분리** :
   - 각 유형의 데이터를 '테이블'처럼 분리된 공간에 저장합니다.
   - (예: `users`, `posts`, `comments` 테이블)
2. **ID 기반 인덱싱 (Indexing)** :
   - 각 엔티티는 고유 ID를 키(key)로, 데이터 객체를 값(value)으로 하는 맵(Map) 또는 레코드(Record) 형태로 저장합니다.
   - 이는 `Array.find()`(시간 복잡도 $O(n)$) 대신 ID로 즉시 데이터를 조회(시간 복잡도 $O(1)$)하기 위함입니다.
3. **ID 참조 (ID References)** :
   - 엔티티 간의 관계는 객체를 직접 중첩하는 대신 ID의 배열로 표현합니다.

------


### 4.3. 정규화된 스키마 설계 (TypeScript)


4.1의 '나쁜 예'를 정규화된 스키마로 재설계해 보겠습니다.

```typescript
/**
 * 정규화된 상태 스키마
 *
 * 'entities'는 우리의 '데이터베이스' 역할을 합니다.
 * 각 '테이블'(users, posts, comments)은 ID를 키로 하는 레코드입니다.
 */
interface NormalizedState {
  entities: {
    users: Record<string, User>;      // 'users' 테이블
    posts: Record<string, Post>;      // 'posts' 테이블
    comments: Record<string, Comment>;  // 'comments' 테이블
  };
  // UI 상태 (예: 현재 선택된 게시글 ID)
  ui: {
    selectedPostId: string | null;
    loading: boolean;
  };
}

// 'users' 테이블의 행(Row)
interface User {
  id: string;
  name: string;
}

// 'posts' 테이블의 행(Row)
interface Post {
  id: string;
  authorId: string;   // 관계: User의 ID (외래 키)
  title: string;
  body: string;
  commentIds: string[]; // 관계: Comment의 ID 목록 (1:N)
}

// 'comments' 테이블의 행(Row)
interface Comment {
  id: string;
  commenterId: string; // 관계: User의 ID (외래 키)
  postId: string;      // 관계: Post의 ID (외래 키)
  text: string;
}
```


#### 4.3.1. 데이터 변환 파이프라인 적용


제2장에서 배운 '데이터 변환 파이프라인'이 여기서 사용됩니다. API 응답(비정규화)을 받아 이 정규화된 상태 구조로 변환하는 순수 함수가 필요합니다.

```typescript
// (제2장에서 다룬 normalizr 라이브러리나 유사한 로직)

function normalizePostResponse(apiResponse: ApiPostResponse): NormalizedEntities {
  const entities = {
    users: {},
    posts: {},
    comments: {},
  };

  // 1. Author (User) 엔티티 추출
  entities.users[apiResponse.author.userId] = {
    id: apiResponse.author.userId,
    name: apiResponse.author.name,
  };

  // 2. Comments 및 Commenter (User) 엔티티 추출
  const commentIds = apiResponse.comments.map(comment => {
    entities.comments[comment.commentId] = {
      id: comment.commentId,
      commenterId: comment.commenter.userId,
      postId: apiResponse.postId,
      text: comment.text,
    };
    // 3. Commenter (User) 엔티티 추출 (중복 저장 방지)
    if (!entities.users[comment.commenter.userId]) {
      entities.users[comment.commenter.userId] = {
        id: comment.commenter.userId,
        name: comment.commenter.name,
      };
    }
    return comment.commentId;
  });

  // 4. Post 엔티티 추출
  entities.posts[apiResponse.postId] = {
    id: apiResponse.postId,
    authorId: apiResponse.author.userId,
    title: apiResponse.title,
    body: apiResponse.body,
    commentIds: commentIds,
  };
  
  return entities;
}
```

이 파이프라인을 거치면 `apiResponse` 데이터는 `NormalizedEntities` 형태로 변환되어 스토어에 병합(merge)됩니다.

------


### 4.4. 정규화의 압도적인 이점 (The Payoff)


이 설계가 가져다주는 이점은 4.1의 문제점들을 정확히 뒤집습니다.

1. **단일 진실 공급원 (Single Source of Truth, SSoT)** :

   - 'Alice'(`u1`) 사용자는 이제 `state.entities.users['u1']`라는 **단 한 곳** 에만 존재합니다.
   - 'Alice'의 이름이 변경되면, 이 한 곳만 수정하면 됩니다. `u1` ID를 참조하는 모든 컴포넌트(게시글 작성자, 댓글 작성자)는 자동으로 최신 데이터를 반영합니다. **데이터 일관성이 100% 보장됩니다.** (이 주제는 다음 장 'SSoT 구현'에서 더 깊이 다룹니다.)

2. **극도로 단순한 업데이트 로직 (Simple Updates)** :

   - **요구사항**: "댓글 `c1`의 텍스트를 '수정된 텍스트'로 변경하라."
   - 정규화된 상태에서는 이 작업이 믿을 수 없을 만큼 간단해집니다.

   ```typescript
   // 👍 ID를 사용한 O(1) 시간 복잡도의 직접 접근
   const newText = "수정된 텍스트";
   const commentIdToUpdate = "c1";
   
   // immer.js를 사용한 Redux Toolkit 리듀서 예시
   // (state는 draft 객체라고 가정)
   
   // 1. users, posts, 다른 comments를 순회(map)할 필요가 '전혀' 없음
   // 2. 'c1' ID로 댓글 테이블에 직접 접근하여 수정
   state.entities.comments[commentIdToUpdate].text = newText;
   
   /* // immer 없이 순수 불변성 코드로 작성해도 훨씬 간단
   const newState = {
     ...state,
     entities: {
       ...state.entities,
       comments: {
         ...state.entities.comments,
         [commentIdToUpdate]: { // 'c1' 키만 덮어쓰기
           ...state.entities.comments[commentIdToUpdate],
           text: newText,
         }
       }
     }
   };
   */
   ```

   - 데이터 구조의 깊이와 상관없이, 업데이트 로직의 복잡도는 항상 `O(1)` 수준으로 일정합니다.

3. **최적화된 렌더링 (Optimized Re-renders)** :

   - '댓글 `c1`'이 수정되어도 `state.entities.posts['p1']` 객체나 `commentIds` 배열은 변경되지 않습니다. `state.entities.comments` 객체의 참조만 변경됩니다.
   - React 컴포넌트가 `useSelector(state => state.entities.posts['p1'])`처럼 `post` 데이터만 구독하고 있다면, 댓글이 수정되어도 **절대 리렌더링되지 않습니다.**
   - `useSelector(state => state.entities.comments['c1'])`처럼 `c1` 댓글만 구독하는 컴포넌트**만** 정확하게 리렌더링됩니다.
   - 이는 React의 성능 최적화(`memo`)와 완벽하게 맞아떨어집니다.

------


### 4.5. 데이터를 다시 '조합'하기 (Reselecting)


한 가지 질문이 남습니다. "상태는 평탄화되었는데, UI는 중첩된 데이터를 필요로 하면 어떡하나요?"

(예: 게시글과 그에 달린 댓글 목록을 함께 렌더링해야 할 때)

답은 **"상태(Source of Truth)는 정규화된 채로 두고, 렌더링 직전에 '파생 상태(Derived State)'로 재조합한다"** 입니다. 이 역할을 하는 것이 바로 **셀렉터(Selectors)** 입니다. (이 주제는 3장 '파생 상태와 계산된 값'에서 자세히 다룹니다.)

```typescript
// (reselect 라이브러리 사용 예시)

// 기본 셀렉터: 각 엔티티 테이블에 접근
const selectPostsEntities = (state: NormalizedState) => state.entities.posts;
const selectCommentsEntities = (state: NormalizedState) => state.entities.comments;

// props로 postId를 받는 재조합 셀렉터
// (state, postId) => PostWithComments
export const selectPostWithComments = createSelector(
  [selectPostsEntities, selectCommentsEntities, (state, postId) => postId],
  (posts, comments, postId) => {
    const post = posts[postId];
    if (!post) {
      return null;
    }

    // 💥 '파생(계산)' 단계: ID 배열을 실제 데이터 객체로 재조합
    const postComments = post.commentIds.map(commentId => comments[commentId]);

    // UI가 사용하기 편한 '중첩된' View Model 반환
    return {
      ...post,
      comments: postComments,
    };
  }
);
```

이 `selectPostWithComments` 셀렉터는 **메모이제이션(Memoization)** 되어, `posts`나 `comments` 테이블, 또는 `postId`가 변경되지 않는 한 재계산되지 않습니다. 즉, 데이터의 '재조합' 비용을 최소화합니다.

------


### 4.6. 결론: 복잡성을 '업데이트'에서 '조회'로 이동하기


정규화는 공짜가 아닙니다. API 응답을 정규화된 형태로 변환하는 파이프라인(2장)을 구축해야 하고, UI에 데이터를 전달하기 위해 셀렉터(3장)를 설계해야 하는 '설계 비용'이 발생합니다.

하지만 정규화는 **애플리케이션의 본질적인 복잡성을 관리 가능한 영역으로 이동** 시킵니다.

- **비정규화(중첩) 상태** : '조회(Read)'는 쉽지만, '업데이트(Write)' 로직이 재앙 수준으로 복잡해집니다.
- **정규화된 상태** : '업데이트(Write)'는 $O(1)$로 극도로 단순해지는 대신, '조회(Read)' 시 데이터를 재조합하는 비용이 발생합니다.

프론트엔드 애플리케이션의 버그 90%는 '상태 업데이트' 로직이 꼬여서 발생합니다. 정규화는 이 복잡성의 핵심을 정면으로 타격하여 단순화시킵니다. 데이터베이스 설계자들이 수십 년간 검증해 온 이 강력한 패턴은, 복잡한 프론트엔드 애플리케이션을 구축하는 우리에게 가장 강력한 무기 중 하나입니다.

------

네, 알겠습니다. 제2부의 두 번째 장 '단일 진실 공급원(SSoT) 구현' 집필을 시작하겠습니다.

------


## 5. 단일 진실 공급원(Single Source of Truth) 구현


> "두 개의 시계가 있다면, 당신은 지금 몇 시인지 절대 확신할 수 없다. SSoT는 애플리케이션 전체에 단 하나의 시계만을 허용하는 엄격한 원칙이다. 데이터가 어디서 왔는지, 어디가 최신인지 고민하는 순간, 당신의 코드는 이미 버그를 잉태한 것이다."

제4장 '정규화된 상태 구조 설계'에서 우리는 데이터의 **중복**을 제거하고 **일관성**을 확보하는 기반을 닦았습니다. 정규화는 SSoT(Single Source of Truth, 단일 진실 공급원)를 달성하기 위한 '어떻게(How)'에 대한 구조적 해답입니다.

이제 우리는 SSoT의 '왜(Why)'와 '어디에(Where)'에 대해 집중해야 합니다. SSoT는 단순히 "데이터를 한 곳에 모아두자"라는 소극적인 개념이 아닙니다. 이는 **애플리케이션 내의 모든 데이터 조각에 대해 "이 데이터의 마스터(Master) 사본은 오직 여기뿐이다"라고 선언하는 적극적인 아키텍처 결정** 입니다.

프론트엔드 애플리케이션은 수많은 '암묵적인 상태' 공급원과 싸우고 있습니다.

- 서버 데이터베이스 (진짜 진실)
- 글로벌 상태 저장소 (예: Redux, Zustand)
- 컴포넌트 로컬 상태 (예: `useState`)
- URL 파라미터 (예: `/users/123`)
- 브라우저 저장소 (예: `localStorage`)
- DOM 그 자체 (예: `input.value`)

이 중 어느 것이 '진짜' 데이터일까요? 사용자가 `input`에 값을 입력하는 순간, `input.value`와 `useState`에 저장된 값 중 어느 것이 진실인가요? SSoT는 이 혼돈 속에서 질서를 잡는 핵심 원칙입니다.

본 장에서는 프론트엔드에서 SSoT를 구현할 때 마주치는 현실적인 문제들을 식별하고, 정규화된 스토어를 중심으로 '진실'을 관리하는 전략을 TypeScript 예제와 함께 탐구합니다.

------


### 5.1. 왜 SSoT가 무너지면 안 되는가?


SSoT가 무너진 상태, 즉 **'진실의 분열(Split Truths)'** 은 프론트엔드에서 가장 흔하고 잡기 어려운 버그의 근원입니다.

예를 들어, '사용자 이름'이라는 데이터가 두 곳에 존재한다고 가정해 봅시다.

1. `globalStore.entities.users['u1'].name` (글로벌 스토어, 정규화된 SSoT)
2. `UserProfilePage.tsx`의 `useState(user.name)` (로컬 컴포넌트 상태)

**[시나리오: 프로필 수정]**

1. `UserProfilePage`가 로드됩니다.
2. `useEffect`가 글로벌 스토어에서 `users['u1']`을 읽어 `useState("Alice")`로 로컬 상태를 초기화합니다.
3. 사용자가 입력 필드를 수정하여 로컬 상태를 `useState("Alice Kim")`으로 변경합니다. (이때 `onChange` 핸들러가 `setName("Alice Kim")` 호출)
4. 사용자가 '저장' 버튼을 누릅니다. API에 "Alice Kim"을 전송하고 성공 응답을 받습니다.
5. **치명적 실수** : 개발자가 API 성공 후 `globalStore`를 업데이트하는 것을 잊거나, 실패했다고 가정해 봅시다.
6. **현재 상태** :
   - `UserProfilePage`의 로컬 상태: "Alice Kim" (UI는 올바르게 보임)
   - `globalStore`의 SSoT: "Alice" (진실이 오염됨)
7. 사용자가 다른 페이지(예: `Header`)로 이동합니다. `Header` 컴포넌트는 `globalStore`의 `users['u1'].name`을 구독하고 있습니다.
8. **버그 발생** : `Header`에는 "Alice"라고 표시됩니다. 사용자는 분명 "Alice Kim"으로 저장했는데도 말입니다.

이 문제는 `UserProfilePage`가 **SSoT(글로벌 스토어)의 데이터를 '복사(Copy)'하여 자신만의 '두 번째 진실(로컬 상태)'을 만들었기 때문에** 발생했습니다.

SSoT 원칙은 이 '복사'를 엄격히 금지합니다. 데이터는 **'소유(Owned)'** 되거나 **'참조(Referenced)'** 되어야 하며, 절대 '복사'되어서는 안 됩니다.

------


### 5.2. SSoT의 위치 결정: 어디가 '진실'인가?


SSoT를 구현하는 첫 번째 단계는 "이 데이터의 마스터는 누구인가?"를 결정하는 것입니다.


#### 5.2.1. 서버 상태 vs 클라이언트 상태


가장 큰 구분선입니다.

1. **서버 상태 (Server State)** :
   - **진실의 소유자** : **서버 데이터베이스**
   - (예: 사용자 정보, 게시글, 상품 목록)
   - 프론트엔드는 이 데이터의 '마스터'가 아닙니다. 우리는 단지 서버의 진실을 빌려와 **'캐시(Cache)'** 하는 것뿐입니다.
   - **SSoT 구현** : `React Query`, `SWR` 같은 서버 상태 관리 라이브러리. 이 라이브러리들은 내부적으로 정규화와 유사한 '캐시 키' 기반으로 데이터를 관리하며, 이 캐시가 프론트엔드 내에서의 SSoT 역할을 합니다.
   - *데이터 지향적 관점*: 이 캐시된 데이터(예: `useQuery`의 `data`)를 **읽기 전용(Read-only) 진실** 로 취급해야 합니다.
2. **클라이언트 상태 (Client State)** :
   - **진실의 소유자** : **프론트엔드 애플리케이션**
   - (예: 다크 모드 활성 여부, 모달 창 열림 상태, 장바구니 내용, 작성 중인 폼 데이터)
   - 이 데이터는 서버와 동기화될 필요가 없거나(UI 상태), 동기화되기 전(폼 데이터)의 상태입니다.
   - **SSoT 구현** : `Zustand`, `Redux`, `Jotai` 같은 클라이언트 상태 라이브러리. 또는 `useState`, `useReducer` (컴포넌트 트리 하위에서만 사용될 경우).

**데이터 지향 프로그래밍은 이 두 상태를 명확히 분리할 것을 요구합니다.** 서버 상태 캐시와 클라이언트 상태 스토어를 혼합하는 것은 SSoT를 모호하게 만듭니다.

(단, `Redux Toolkit Query(RTK Query)`는 RTK라는 단일 스토어 내에서 서버 상태 캐시(엔티티)와 클라이언트 상태(UI 슬라이스)를 함께 관리하는 통합 SSoT 접근 방식을 제공하기도 합니다.)

------


### 5.3. '진실'을 구현하는 전략: 정규화된 스토어


제4장에서 설계한 **정규화된 스토어(Normalized Store)** 는 클라이언트 상태와 캐시된 서버 상태 모두를 담을 수 있는 가장 이상적인 SSoT 구현체입니다.

이제 SSoT 원칙 하에 이 스토어를 어떻게 운영하는지 살펴봅니다.


#### 5.3.1. 전략 1: 데이터는 '흐르게' 하고, '복사'하지 마라 (Flow, Don't Copy)


앞서 5.1의 `UserProfilePage` 문제를 해결하는 올바른 방법은 데이터를 '복사'하는 `useState`를 제거하고 SSoT로부터 데이터를 '직접 참조(Flow)'하는 것입니다.

**[좋은 예: SSoT로부터 직접 데이터 흐름 받기]**

```typescript
// (Redux Toolkit 또는 Zustand 같은 스토어 사용 가정)

// 1. 우리의 SSoT (제4장에서 설계한 스토어)
// state.entities.users['u1'].name = "Alice"

// 2. 컴포넌트는 SSoT를 '구독(Subscribe)'한다.
function UserProfilePage({ userId }: { userId: string }) {
  // 👍 SSoT에서 직접 '진실'을 읽어온다.
  const userName = useUserStore(state => state.entities.users[userId]?.name);
  
  // (폼 관리를 위한 로컬 상태는 'UI 상태'이며, 이는 '데이터의 복사본'이 아님)
  // (이 로컬 상태는 '수정 중인 값'이라는 별개의 진실을 가짐)
  const [editingName, setEditingName] = useState(userName);

  // SSoT의 '진실'이 변경되면(예: 다른 곳에서 이름이 바뀜), 
  // 로컬 폼 상태도 동기화한다.
  useEffect(() => {
    setEditingName(userName);
  }, [userName]);

  const handleNameChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    // 로컬 폼 상태(editingName)를 업데이트
    setEditingName(e.target.value);
  };

  const handleSave = async () => {
    try {
      // 3. API로 '수정 중인 값'을 전송 (부수 효과)
      await api.updateUser(userId, { name: editingName });
      
      // 4. 💥 SSoT를 업데이트하는 '액션'을 디스패치한다. (가장 중요!)
      // 컴포넌트가 직접 SSoT를 수정하는 것이 아니라,
      // 스토어에 "진실을 업데이트하라"고 요청(Action)한다.
      useUserStore.getState().updateUserName(userId, editingName);
      
    } catch (error) {
      // ... 에러 처리 ...
    }
  };
  
  return (
    <div>
      {/* 입력 필드는 로컬 'editingName' 상태를 제어 */}
      <input value={editingName} onChange={handleNameChange} />
      <button onClick={handleSave}>저장</button>
    </div>
  );
}

// 5. Header 컴포넌트도 동일한 SSoT를 구독한다.
function Header() {
  const userName = useUserStore(state => state.entities.users['u1']?.name);
  return <header>안녕하세요, {userName}님</header>; // "Alice"
}
```

**[흐름 분석]**

1. `UserProfilePage`와 `Header`는 모두 `users['u1'].name`("Alice")을 SSoT에서 읽어옵니다.
2. 사용자가 `input`을 "Alice Kim"으로 수정합니다. (`editingName` 상태만 변경)
3. '저장' 클릭 -> `handleSave` 실행.
4. `useUserStore.getState().updateUserName("u1", "Alice Kim")` 액션이 SSoT를 변경합니다.
5. **SSoT의 진실이 변경** : `state.entities.users['u1'].name`이 "Alice Kim"이 됩니다.
6. **전파(Propagation)** : SSoT가 변경되었으므로, 이를 구독하던 **모든** 컴포넌트가 자동으로 리렌더링됩니다.
7. `Header`는 `userName`이 "Alice Kim"으로 바뀌었음을 감지하고 UI를 업데이트합니다.
8. `UserProfilePage`도 `userName` 프롭(SSoT로부터 온)이 "Alice Kim"으로 바뀐 것을 감지하고 `useEffect`를 실행, `editingName`도 "Alice Kim"으로 동기화됩니다.

데이터는 SSoT(스토어)라는 **단 하나의 진실 공급원** 으로부터 UI 컴포넌트로 **흐릅니다(Flows)** . 컴포넌트는 절대 데이터를 '복사'하여 소유하지 않습니다.


#### 5.3.2. 전략 2: URL은 상태의 SSoT이다 (URL as a Source of Truth)


애플리케이션 상태 중 일부는 **URL**이 SSoT가 되어야 합니다.

- 현재 선택된 사용자 ID (예: `/users/u1`)
- 검색 쿼리 (예: `?q=typescript`)
- 필터 옵션 (예: `?status=active`)
- 페이지네이션 (예: `?page=2`)

이 데이터들은 **'애플리케이션의 현재 위치(Location)'** 를 나타내며, 북마크 가능하고 뒤로 가기/앞으로 가기가 동작해야 합니다. 이 값들을 `Zustand`나 `Redux` 스토어에만 저장하면 이 기능들이 깨집니다.

**[나쁜 예: URL과 스토어의 진실 분열]**

```typescript
// 스토어에만 '진실'이 있는 경우
const useStore = create(() => ({
  selectedUserId: "u1",
  setSelectedUserId: (id) => set({ selectedUserId: id }),
}));

function UserListPage() {
  const selectedUserId = useStore(s => s.selectedUserId);
  const setSelectedUserId = useStore(s => s.setSelectedUserId);
  
  // 사용자가 "u2"를 클릭
  const handleClickUser = (id: string) => {
    setSelectedUserId(id); 
    // 👎 URL은 /users 인데, 스토어 상태는 'u2'가 선택됨.
    // 사용자가 새로고침하면? selectedUserId는 'u1'(초기값)으로 돌아감.
  };
  // ...
}
```

**[좋은 예: URL을 SSoT로 사용]**

```typescript
// (react-router-dom 사용 예시)

function UserListPage() {
  // ...
  // 사용자가 "u2"를 클릭
  const navigate = useNavigate();
  const handleClickUser = (id: string) => {
    // 👍 '진실'인 URL을 변경한다.
    navigate(`/users/${id}`); 
  };
  // ...
}

function UserDetailPage() {
  // 👍 '진실'인 URL로부터 파라미터를 읽어온다.
  const { userId } = useParams<{ userId: string }>(); 

  // 👍 URL의 ID를 기반으로 '다른 진실(SSoT)'인 스토어에서 데이터를 조회한다.
  const user = useUserStore(state => state.entities.users[userId]);

  // ...
}
```

이 설계에서 `userId`의 SSoT는 **URL**입니다. `useUserStore`는 `user` 데이터의 SSoT입니다. `UserDetailPage`는 이 두 SSoT를 **조합(Compose)** 하여 UI를 그립니다.


#### 5.3.3. 전략 3: 서버 상태는 React Query가 SSoT이다


서버로부터 받은 데이터(예: `User`, `Post`)를 `Zustand`나 `Redux` 같은 클라이언트 스토어에 저장하는 것은 SSoT 원칙에 위배될 수 있습니다.

- `React Query`가 `/api/users`를 `['users']` 키로 캐시 (첫 번째 진실)
- `Zustand`가 `entities.users`에 이 데이터를 저장 (두 번째 진실)

이제 이 두 진실을 어떻게 동기화할 것인가? `React Query`가 `refetch`로 데이터를 갱신했을 때, `Zustand` 스토어는 어떻게 그 사실을 알 수 있을까요?

**해결책 1: SSoT 통합 (React Query가 SSoT)**

`React Query`(또는 `SWR`)를 서버 데이터의 **유일한 SSoT** 로 취급합니다.

```typescript
function UserProfile({ userId }: { userId: string }) {
  // 👍 서버 상태의 SSoT(React Query)에서 데이터를 직접 읽는다.
  const { data: user, isLoading } = useQuery({
    queryKey: ['users', userId],
    queryFn: () => api.fetchUser(userId),
  });

  // 클라이언트 UI 상태 (예: 모달)는 별개의 SSoT(Zustand)에서 읽는다.
  const isModalOpen = useUIStore(state => state.isProfileModalOpen);
  
  if (isLoading) return <Spinner />;

  return <div>{user.name} / {isModalOpen && <Modal />}</div>;
}
```

이 방식은 `React Query`의 강력한 캐시 관리, 자동 `refetch` 등의 이점을 모두 누리면서 SSoT를 명확하게 분리합니다.

**해결책 2: SSoT 동기화 (고급)**

`React Query`의 `onSuccess` 콜백 등을 이용해 `Zustand` 스토어(우리의 정규화된 SSoT)를 수동으로 업데이트할 수 있습니다.

```typescript
// 정규화된 SSoT (Zustand)
const useAppStore = create(() => ({
  entities: { users: {}, posts: {} },
  // ... 스토어 액션 (예: mergeEntities)
}));

function useNormalizedUserQuery(userId: string) {
  const mergeUsers = useAppStore(state => state.mergeUsers); // 스토어 업데이트 액션

  return useQuery({
    queryKey: ['users', userId],
    queryFn: () => api.fetchUser(userId), // API 호출
    onSuccess: (data) => {
      // 💥 API 성공 시, SSoT(Zustand 스토어)를 업데이트
      const { entities } = normalize(data, userSchema); // 정규화 파이프라인
      mergeUsers(entities.users);
    },
  });
}
```

이 방식은 모든 데이터를 단일 정규화 스토어에서 관리할 수 있게 해주지만, 동기화 로직을 직접 구현해야 하는 복잡성이 있습니다.

------


### 5.4. 결론: 진실은 하나여야 한다


SSoT는 기술이 아니라 '원칙'이자 '규율'입니다.

1. 애플리케이션의 모든 데이터 조각(사용자 이름, 모달 열림 상태, 현재 페이지 ID)에 대해 **"이 데이터의 마스터는 누구인가?"** 를 명확히 정의해야 합니다.
2. 서버 상태(캐시)와 클라이언트 상태(스토어), URL 상태를 명확히 분리하고, 각각의 SSoT를 지정합니다.
3. **데이터를 복사(Copy)하지 말고, SSoT로부터 직접 흐르게(Flow) 하십시오.** (예: `useState(prop)` 대신 `prop`을 직접 사용)
4. 데이터 '수정'이 필요할 때는, SSoT를 직접 수정하는 것이 아니라, SSoT에게 "진실을 변경해달라"는 **명령(Action)을 보내야 합니다.**

정규화된 상태 구조(4장)가 SSoT를 담는 '그릇'이라면, SSoT 원칙은 그 그릇을 운영하는 '규칙'입니다. 이 규칙이 확립될 때, 비로소 우리는 상태 변경을 예측하고 추적하며, 비일관성 버그에서 해방될 수 있습니다.

------

네, 알겠습니다. 제2부의 마지막 장이자, 상태 관리의 '읽기(read)' 측면을 완성하는 '파생 상태와 계산된 값 관리' 집필을 시작하겠습니다.

------


## 6. 파생 상태(derived state)와 계산된 값 관리


> "상태 저장소에 '계산될 수 있는' 값을 저장하는 것은 죄악이다. 그것은 두 번째 시계를 만드는 행위이며, 두 시계의 시간은 언젠가 반드시 어긋나게 된다. 진실은 오직 원천 데이터(SSoT)에만 존재해야 하며, 나머지는 모두 그로부터 파생되어야 한다."

제4장(정규화)과 제5장(SSoT)에서 우리는 애플리케이션 상태의 '쓰기(Write)' 측면을 견고하게 다졌습니다. 데이터는 중복 없이, 정규화된 형태로, 단 하나의 진실 공급원(SSoT)에 저장되어야 합니다.

하지만 UI는 종종 이 '날것(Raw)'의 SSoT 데이터를 그대로 원하지 않습니다.

- `cartItems` 배열(SSoT)이 아니라, `totalPrice`(총합)를 원합니다.
- `todos` 배열(SSoT)이 아니라, `filter`가 적용된 `visibleTodos`(필터링된 목록)를 원합니다.
- `entities.posts['p1']`과 `entities.comments`(SSoT)가 아니라, 댓글이 포함된 `postWithComments` 객체(중첩된 뷰 모델)를 원합니다.

이처럼 **SSoT에 저장된 원본 데이터를 기반으로 '계산'되어 나오는 모든 값을 '파생 상태(Derived State)'** 라고 부릅니다.

이 파생 상태를 관리하는 것은 '읽기(Read)' 측면의 핵심이며, 두 가지 큰 함정이 존재합니다.

1. **진실의 오염** : 파생 상태를 SSoT에 함께 저장하려는 유혹.
2. **성능 저하** : 파생 상태를 필요 이상으로 자주, 비효율적으로 계산하는 문제.

본 장에서는 이 두 가지 함정을 피하고, **메모이제이션(Memoization)** 을 통해 효율적이고 선언적인 '읽기 파이프라인'을 구축하는 방법을 탐구합니다.

------


### 6.1. 최악의 실수: 파생 상태를 SSoT에 저장하기


가장 흔하고 치명적인 실수는 파생 상태를 원본 상태와 함께 저장하는 것입니다. 장바구니 예시를 봅시다.

**[나쁜 예: `totalPrice`를 SSoT에 저장]**

```typescript
interface CartState {
  items: CartItem[];
  totalPrice: number; // 🚨 파생 상태를 SSoT에 저장!
}

// 초기 상태
const initialState: CartState = {
  items: [],
  totalPrice: 0,
};

// 'addItem' 리듀서 (Immer 사용 가정)
function addItem(state: CartState, action: PayloadAction<CartItem>) {
  const newItem = action.payload;
  
  // 1. SSoT(items) 업데이트
  state.items.push(newItem);
  
  // 2. 파생 상태(totalPrice)를 '수동'으로 업데이트
  state.totalPrice += newItem.price; 
}

// 'removeItem' 리듀서
function removeItem(state: CartState, action: PayloadAction<string>) {
  const idToRemove = action.payload;
  const itemIndex = state.items.findIndex(item => item.id === idToRemove);

  if (itemIndex > -1) {
    // 3. 파생 상태를 '수동'으로 먼저 계산
    const itemToRemove = state.items[itemIndex];
    state.totalPrice -= itemToRemove.price; // 🚨 버그 발생 가능성 (수량은?)
    
    // 4. SSoT(items) 업데이트
    state.items.splice(itemIndex, 1);
  }
}
```

이 접근 방식의 문제점:

- **SSoT 원칙 위반** : `totalPrice`의 진실은 `items` 배열입니다. 하지만 이제 `totalPrice`라는 '두 번째 진실'이 생겼습니다.
- **유지보수 지옥** : `items`를 변경하는 **모든** 리듀서(`addItem`, `removeItem`, `updateQuantity`, `clearCart`...)는 `totalPrice`를 **정확하게** 다시 계산하고 업데이트할 책임을 져야 합니다. `removeItem` 로직에서 수량을 고려하는 것을 잊는 순간, `totalPrice`는 SSoT(`items`)와 불일치하게 되며, 사용자는 잘못된 총액을 보게 됩니다.
- **로직의 분산** : '총합 계산'이라는 단일 로직이 `addItem`, `removeItem` 등 여러 리듀서에 흩어져 중복됩니다.

**해결책: 파생 상태는 SSoT에 절대 저장하지 않습니다. 오직 '읽는 시점'에 계산합니다.**

```typescript
// [좋은 예: SSoT는 최소한으로]
interface CartState {
  items: CartItem[];
  // totalPrice가 존재하지 않음!
}

const initialState: CartState = {
  items: [],
};
```

------


### 6.2. 순진한 해결책: 컴포넌트에서 직접 계산하기


그렇다면 파생 상태는 어디서 계산해야 할까요? 가장 간단한 방법은 컴포넌트 내부입니다.

```typescript
function CartComponent() {
  // 1. SSoT(items)를 구독
  const items = useStore(state => state.cart.items);

  // 2. 렌더링 시점에 '파생 상태'를 계산
  const totalPrice = items.reduce((acc, item) => acc + item.price, 0);

  return (
    <div>
      <span>총합: {totalPrice}</span>
      {/* ... items 렌더링 ... */}
    </div>
  );
}
```

이 코드는 SSoT 원칙을 완벽하게 지킵니다. `totalPrice`는 항상 `items`의 최신 상태를 반영합니다.

**하지만, 새로운 문제가 발생합니다: "성능".**

CartComponent가 리렌더링될 때마다 reduce 함수(총합 계산)가 매번 실행됩니다.

만약 items 배열이 아니라, CartComponent의 부모 컴포넌트가 리렌더링되어 CartComponent가 불필요하게 리렌더링된다면? items 배열은 변경되지 않았음에도 불구하고 reduce 계산은 또 실행됩니다.

총합 계산은 저렴하지만, 만약 이 계산이 **수천 개의 배열을 필터링하고 매핑하는 복잡한 작업** 이라면 심각한 성능 저하를 유발할 것입니다.

------


### 6.3. 현명한 해결책: 메모이제이션 셀렉터 (Memoized Selectors)


이 문제를 해결하는 열쇠는 **메모이제이션(Memoization)** 입니다.

> **메모이제이션**: "이전에 수행한 계산의 결과를 저장해두고, 동일한 입력이 다시 들어오면 계산하지 않고 저장된 결과를 즉시 반환하는 기술"

즉, `items` 배열이 **변경되지 않았다면** , `totalPrice`를 **재계산하지 않고 이전에 계산했던 값을 재사용** 하는 것입니다.

이 '메모이제이션이 적용된 파생 상태 계산 함수'를 **셀렉터(Selector)** 라고 부릅니다. React 생태계에서는 `reselect` 라이브러리가 이 패턴의 표준입니다.

`reselect`의 `createSelector`는 두 부분으로 구성됩니다.

1. **입력 셀렉터 (Input Selectors)** : SSoT에서 필요한 '날것'의 데이터 조각을 가져오는 단순한 함수들.
2. **조합 함수 (Combiner Function)** : 입력 셀렉터가 반환한 값들을 받아, '비싼' 계산을 수행하는 함수.

[핵심 동작]

createSelector는 '입력 셀렉터'가 반환한 값들(예: items 배열)을 이전 호출과 === (참조 비교)합니다.

- **만약 값이 같다면 (참조가 변경되지 않았다면)** : '조합 함수'를 실행하지 않고, 이전에 저장해둔(캐시된) 파생 상태 결과를 즉시 반환합니다.
- **만약 값이 다르다면 (참조가 변경되었다면)** : '조합 함수'를 실행하여 파생 상태를 새로 계산하고, 그 결과를 캐시한 뒤 반환합니다.

이것이 가능한 이유는 제1장(불변성)에서 배운 대로, `items` 배열에 변화가 생기면 '새로운' 배열 참조가 생성되기 때문입니다.

------


### 6.4. `reselect`를 사용한 파생 상태 관리


'보이는 할 일 목록(visible todos)'이라는 고전적인 예시를 통해 셀렉터를 구축해 보겠습니다.

**[1. SSoT 정의]**

```typescript
// SSoT (state.ts)
interface Todo {
  id: number;
  text: string;
  completed: boolean;
}

type Filter = 'all' | 'active' | 'completed';

interface TodoState {
  todos: Todo[];
  filter: Filter;
  // 🚨 visibleTodos를 여기에 저장하지 않는다!
}
```

**[2. 셀렉터 정의 (selectors.ts)]**

```typescript
import { createSelector } from 'reselect';

// 1. 입력 셀렉터 (SSoT에서 데이터 조각을 가져옴)
const selectTodos = (state: RootState) => state.todos.todos;
const selectFilter = (state: RootState) => state.todos.filter;

// 2. 메모이제이션된 '파생 상태' 셀렉터
export const selectVisibleTodos = createSelector(
  [selectTodos, selectFilter], // 입력 셀렉터 배열
  (todos, filter) => {         // 조합 함수 (Combiner)
    
    // 💥 이 '비싼' 계산은 todos 또는 filter가 변경될 때만 실행됨!
    console.log("파생 상태 계산 중: selectVisibleTodos"); 
    
    switch (filter) {
      case 'active':
        return todos.filter(t => !t.completed);
      case 'completed':
        return todos.filter(t => t.completed);
      case 'all':
      default:
        return todos;
    }
  }
);
```

**[3. 컴포넌트에서 사용 (TodoList.tsx)]**

```typescript
function TodoList() {
  // 👍 SSoT가 아닌 '파생 상태 셀렉터'를 구독
  const visibleTodos = useStore(selectVisibleTodos); 
  const dispatch = useDispatch();

  // (다른 로직... 예: filter 변경 버튼)
  const setFilter = (filter: Filter) => {
    dispatch(todoActions.setFilter(filter));
  };
  
  // ...
  // 만약 <Header> 컴포넌트가 리렌더링되어 TodoList가 불필요하게
  // 리렌더링되더라도, 'selectVisibleTodos'는 재계산되지 않고
  // 캐시된 'visibleTodos' 배열을 반환합니다. (console.log가 찍히지 않음)
  //
  // 만약 사용자가 'setFilter'를 호출하여 'filter' SSoT가 변경되면,
  // 'selectVisibleTodos'는 재계산되어 새로운 배열을 반환하고
  // 컴포넌트는 리렌더링됩니다.
  // ...
}
```

------


### 6.5. 셀렉터 체이닝: '읽기' 파이프라인의 완성


셀렉터의 진정한 힘은 '조합성'에 있습니다. 셀렉터는 **다른 셀렉터를 입력으로** 받을 수 있습니다.

이는 제2장(데이터 변환 파이프라인)에서 다룬 로직의 '파이프라이닝'을 '읽기' 영역에서 구현하는 것입니다.

```typescript
// (selectors.ts 계속)

// 1. 이미 'selectVisibleTodos'가 있습니다.

// 2. 'selectVisibleTodos'의 결과를 입력으로 받는 새로운 셀렉터
export const selectVisibleTodoCount = createSelector(
  [selectVisibleTodos], // 입력: 파생 상태
  (visibleTodos) => {
    console.log("파생 상태 계산 중: selectVisibleTodoCount");
    return visibleTodos.length; // 2차 파생
  }
);

// 3. 'selectTodos'를 입력으로 받는 또 다른 셀렉터
export const selectCompletedTodoCount = createSelector(
  [selectTodos], // 입력: SSoT
  (todos) => {
    console.log("파생 상태 계산 중: selectCompletedTodoCount");
    return todos.filter(t => t.completed).length;
  }
);
```

`SSoT (todos, filter)` → `selectVisibleTodos` → `selectVisibleTodoCount`

이 구조는 **데이터 흐름 그래프** 를 형성합니다.

- `filter`만 변경되면: `selectVisibleTodos`와 `selectVisibleTodoCount`만 재계산됩니다. `selectCompletedTodoCount`는 재계산되지 않습니다.
- `todos` 배열만 변경되면: 세 개의 셀렉터가 모두 재계산됩니다.
- 상태의 **전혀 다른 부분** (`state.auth.user`)이 변경되면: `selectTodos`, `selectFilter` 모두 이전과 `===`인 값을 반환하므로, **위의 어떤 셀렉터도 재계산되지 않습니다.**

이것이 정규화된 상태(4장)와 셀렉터를 결합한 힘입니다. 제4장의 `selectPostWithComments` 셀렉터(정규화된 SSoT를 UI용 중첩 데이터로 '재조합'하는) 역시 이 메모이제이션된 파생 상태 셀렉터의 완벽한 예시입니다.

------


### 6.6. 결론: 쓰기(SSoT)와 읽기(Selectors)의 분리


제2부 '상태 관리의 데이터 중심 접근'을 마무리하며, 우리는 견고한 상태 관리의 두 기둥을 확립했습니다.

1. **쓰기(Write) 측면: SSoT (4, 5장)**
   - 상태는 **정규화**되어야 합니다. (중복 없음)
   - 상태는 **단일 진실 공급원** 에 존재해야 합니다. (파생 상태 저장 금지)
   - 상태는 **불변성**을 가지고 업데이트되어야 합니다.
2. **읽기(Read) 측면: 파생 상태 (6장)**
   - UI가 필요한 데이터는 SSoT로부터 **파생**되어야 합니다.
   - 이 파생 로직은 **셀렉터**로 캡슐화되어야 합니다.
   - 셀렉터는 **메모이제이션**되어 불필요한 재계산을 방지하고 성능을 보장해야 합니다.

`UI = f(state)`라는 공식에서, `state`는 SSoT를 의미하고, `f`는 **메모이제이션된 셀렉터 파이프라인** 을 의미하게 됩니다.

이로써 우리는 '상태' 그 자체를 데이터 지향적으로 다루는 기초를 완성했습니다. 이제 제3부 '실전 아키텍처 패턴'에서는 이 원칙들을 기반으로 더 크고 복잡한 애플리케이션 구조(ECS, CQRS 등)를 탐구할 준비를 마쳤습니다.

------

네, 알겠습니다. 이제 데이터 지향 프로그래밍의 원칙을 실제 아키텍처 패턴에 적용하는 제3부의 첫 번째 장을 시작하겠습니다. 게임 개발의 세계에서 프론트엔드 아키텍처의 미래를 엿볼 수 있는 'Entity-Component-System' 패턴입니다.

------


## 7. Entity-Component-System (ECS) 패턴 - 게임 개발에서 배우는 프론트엔드 아키텍처


> "객체(Object)에 '무엇을 할 수 있는지(logic)'를 묻지 마라. 그냥 데이터(data)를 가져와서 '무엇이든(logic)' 하라. ECS는 행동이 아닌 존재에 집중하는 설계이며, 이는 프론트엔드에 놀라운 유연성을 선사한다."

지금까지 우리는 '데이터와 로직의 분리'라는 핵심 사상을 파고들었습니다. 순수 함수(1장), 파이프라인(2장), 부수 효과 격리(3장)를 통해 로직을 격리했습니다. 그리고 정규화된 SSoT(4장, 5장)와 파생 상태(6장)를 통해 데이터를 견고하게 관리하는 법을 배웠습니다.

이제 이 모든 원칙을 극단까지 밀어붙여 '구조화'하는 아키텍처 패턴을 소개합니다. 바로 **Entity-Component-System (ECS)** 입니다.

ECS는 원래 *Overwatch*, *Unity*, *Unreal*과 같은 고성능 실시간 게임 엔진을 위해 탄생했습니다. 게임 개발자들은 수만 개의 객체(몬스터, 총알, 파티클)가 매초 60번씩 상호작용하는 극도의 복잡성을 관리해야 했습니다. 그들이 찾은 해답은 전통적인 객체 지향 프로그래밍(OOP)을 버리고, 데이터를 중심으로 시스템을 재편하는 것이었습니다.

놀랍게도, 현대의 복잡한 프론트엔드 애플리케이션(예: Figma, Google Sheets, Discord)은 수많은 상태와 이벤트가 실시간으로 상호작용한다는 점에서 게임과 매우 유사합니다. ECS는 프론트엔드가 OOP의 상속과 캡슐화라는 굴레에서 벗어나, 데이터 지향의 유연함과 성능을 극대화할 수 있는 강력한 청사진을 제공합니다.

본 장에서는 ECS의 세 가지 구성 요소를 분해하고, 이것이 왜 프론트엔드 아키텍처의 미래가 될 수 있는지 탐구합니다.

------


### 7.1. ECS의 세 기둥: 정의와 분리


ECS는 그 이름처럼 세 가지 단순한 개념으로 모든 것을 설명합니다.

1. **Entity (엔티티)** : "존재" 그 자체.
2. **Component (컴포넌트)** : "데이터". 존재가 가진 속성.
3. **System (시스템)** : "로직". 속성을 기반으로 동작하는 행위.

이 셋은 **철저하게 분리됩니다.**


#### 7.1.1. Entity: 단순한 ID


엔티티는 **아무것도 아닙니다.** 논리도, 데이터도 없습니다. 그저 "세상에 존재하는 무언가"를 식별하는 **고유한 ID** 일 뿐입니다.

- `1`
- `"user-123"`
- `"submit-button"`
- `Symbol('player-entity')`

엔티티는 그 자체로 `User`이거나 `Button`이 아닙니다. 그냥 '1번 존재'입니다.


#### 7.1.2. Component: 순수한 데이터 (Data Only)


컴포넌트는 엔티티에게 '의미'를 부여하는 **순수한 데이터 덩어리(Data Bag)** 입니다. 컴포넌트는 **절대** 메서드(`update()`, `onClick()`)를 가져서는 안 됩니다. 오직 상태(속성)만 가집니다.

```typescript
// (ECS의 컴포넌트는 React 컴포넌트가 아닙니다! 순수 데이터입니다.)

// 위치 속성
interface Position {
  x: number;
  y: number;
}

// 속도 속성
interface Velocity {
  dx: number;
  dy: number;
}

// 렌더링 가능 속성
interface Renderable {
  sprite: string; // 'player.png'
  layer: number;
}

// 체력 속성
interface Health {
  current: number;
  max: number;
}

// '클릭 가능' 속성 (프론트엔드적 해석)
interface Clickable {
  action: { type: 'NAVIGATE'; payload: '/home' }; // 클릭 시 발생할 '액션' 데이터
}

// '데이터 소유' 속성 (프론트엔드적 해석)
interface UserData {
  name: string;
  email: string;
}
```

엔티티는 이러한 컴포넌트들을 '소유'합니다.

- **`Entity 1`** 은 `Position{10, 20}`, `Velocity{1, 0}`, `Renderable{'player.png', 1}` 컴포넌트를 가집니다. → 아, 이건 '움직이는 플레이어'로군요.
- **`Entity 2`** 는 `Position{100, 50}`, `Renderable{'tree.png', 0}` 컴포넌트를 가집니다. → 이건 '나무'로군요.
- **`Entity 3`** 는 `Position{200, 400}`, `Renderable{'button.png', 2}`, `Clickable{...}` 컴포넌트를 가집니다. → 이건 '클릭 가능한 버튼'이군요.

**핵심은 '조합(Composition)'입니다.** `Entity 3`에 `Velocity` 컴포넌트를 추가하기만 하면, '움직이는 버튼'이 즉시 탄생합니다. 상속이 필요 없습니다.


#### 7.1.3. System: 순수한 로직 (Logic Only)


시스템은 **순수한 로직** 입니다. 시스템은 '특정 컴포넌트 조합을 가진 모든 엔티티'를 찾아내어, 해당 데이터를 처리(변환)합니다.

시스템은 상태를 소유하지 않습니다. 데이터를 입력받아(읽기), 로직을 실행하고, 데이터를 변경(쓰기)합니다. (제2장 '데이터 변환 파이프라인'과 제3장 '부수 효과 격리'의 개념과 정확히 일치합니다.)

```typescript
/**
 * 시스템 1: MovementSystem (움직임 시스템)
 * - 관심 대상: 'Position'과 'Velocity' 컴포넌트를 '둘 다' 가진 모든 엔티티
 * - 하는 일: Position 데이터를 Velocity 데이터만큼 변경한다.
 */
function movementSystem(entities: Entity[], positions: Record<EntityID, Position>, velocities: Record<EntityID, Velocity>): Record<EntityID, Position> {
  const newPositions = { ...positions }; // (불변성 유지)
  
  for (const id of entities) {
    const pos = positions[id];
    const vel = velocities[id];

    // 이 엔티티가 두 컴포넌트를 모두 가졌는지 확인
    if (pos && vel) {
      // 💥 로직 실행: 데이터를 변환
      newPositions[id] = {
        x: pos.x + vel.dx,
        y: pos.y + vel.dy,
      };
    }
  }
  return newPositions; // 변경된 데이터 반환
}

/**
 * 시스템 2: RenderSystem (렌더링 시스템)
 * - 관심 대상: 'Position'과 'Renderable' 컴포넌트를 가진 모든 엔티티
 * - 하는 일: 화면에 렌더링 (부수 효과)
 */
function renderSystem(entities: Entity[], positions: Record<EntityID, Position>, renderables: Record<EntityID, Renderable>): void {
  // (이 시스템은 '불순한 쉘'에 속함)
  for (const id of entities) {
    const pos = positions[id];
    const render = renderables[id];

    if (pos && render) {
      // 💥 부수 효과 실행: DOM이나 Canvas에 그리기
      drawSprite(render.sprite, pos.x, pos.y, render.layer);
    }
  }
}
```

------


### 7.2. OOP의 몰락과 ECS의 부상


전통적인 OOP 방식이 왜 게임과 복잡한 프론트엔드에서 실패했는지 비교해 봅시다.

**[OOP의 접근 방식 (캡슐화)]**

```typescript
// 👎 데이터와 로직이 '캡슐화'라는 이름으로 강하게 결합
class Player {
  position: Position;
  velocity: Velocity;
  sprite: string;

  constructor() {
    this.position = { x: 0, y: 0 };
    this.velocity = { x: 1, y: 0 };
    this.sprite = 'player.png';
  }
  
  // 메서드 (로직)
  update() {
    this.position.x += this.velocity.dx;
    this.position.y += this.velocity.dy;
  }
  
  render() {
    drawSprite(this.sprite, this.position.x, this.position.y);
  }
}

const player1 = new Player();
gameLoop(() => {
  player1.update(); // 객체가 스스로 로직을 실행
  player1.render();
});
```

문제점:

- **상속의 지옥** : '날아다니는 몬스터'와 '기어다니는 몬스터'는? `FlyingMonster extends Monster`, `CrawlingMonster extends Monster`? 만약 '날아다니고 독을 뿜는' 몬스터가 필요하면? 다중 상속 문제가 발생합니다.
- **유연성 부족** : `Player` 객체를 '클릭 가능하게' 만들려면 어떻게 해야 할까요? `Player` 클래스 자체를 수정하거나, `ClickablePlayer extends Player` 같은 파생 클래스를 만들어야 합니다.
- **로직의 분산** : `update` 로직이 `Player` 클래스에, `Monster` 클래스에, `Bullet` 클래스에 모두 흩어져 있습니다. '물리'라는 단일 관심사가 수백 개의 클래스 파일에 분산됩니다.
- **데이터 지역성 (성능)** : `player1`, `monster1`, `player2` 객체는 메모리상에 흩어져 있습니다. (제3부 '성능 최적화'에서 자세히 다룸)

**[ECS의 접근 방식 (데이터 지향)]**

```typescript
// 👍 데이터와 로직의 완벽한 분리

// 1. 데이터베이스 (Component Storage) - (제4장 '정규화'와 동일!)
const world = {
  positions: {
    'p1': { x: 0, y: 0 },
    'm1': { x: 100, y: 50 },
  },
  velocities: {
    'p1': { x: 1, y: 0 },
  },
  renderables: {
    'p1': { sprite: 'player.png' },
    'm1': { sprite: 'monster.png' },
  }
};
const entities = ['p1', 'm1'];

// 2. 시스템 (순수 로직)
const newPositions = movementSystem(entities, world.positions, world.velocities);

// 3. 메인 루프 (오케스트레이터)
gameLoop(() => {
  // 시스템이 데이터를 '읽고' -> '변환' -> '쓴다'
  const newPositions = movementSystem(entities, world.positions, world.velocities);
  world.positions = newPositions; // SSoT 업데이트
  
  // 렌더 시스템은 '부수 효과'만 실행
  renderSystem(entities, world.positions, world.renderables); 
});
```

장점:

- **궁극의 유연성** : '날아다니는 몬스터'(`m1`)? `world.velocities['m1'] = {x: 0, y: 1}` 컴포넌트를 추가하면 끝입니다. `movementSystem`이 다음 틱(tick)에 알아서 `m1`을 움직입니다.
- **관심사 집중** : '물리' 로직은 오직 `movementSystem`에만 존재합니다.
- **테스트 용이성** : `movementSystem`은 데이터 입출력이 명확한 순수 함수(또는 파이프라인)이므로 테스트가 극도로 쉽습니다.
- **데이터 지역성** : `positions` 데이터는 `positions` 객체(또는 배열)에 모여 있으므로 캐시 친화적입니다. (성능)

------


### 7.3. 프론트엔드에 ECS 적용하기


"알겠습니다. 게임에 좋은 건 알겠는데, 이게 `<div>`와 `<button>`을 만드는 프론트엔드와 무슨 상관인가요?"

**전통적인 React 컴포넌트는 OOP의 `Player` 클래스와 같습니다.**

```typescript
// 👎 전통적인 React 컴포넌트 (OOP 방식)
function UserCard({ userId }: { userId: string }) {
  // 1. 컴포넌트가 '자신의' 상태(데이터)를 소유
  const [isExpanded, setIsExpanded] = useState(false);
  const [userData, setUserData] = useState<User | null>(null);
  
  // 2. 컴포넌트가 '자신의' 로직(메서드)을 소유
  useEffect(() => {
    // 부수 효과 (데이터 페칭)
    api.fetchUser(userId).then(setUserData);
  }, [userId]);

  const handleClick = () => {
    // UI 로직
    setIsExpanded(!isExpanded);
  };
  
  // 3. 렌더링 로직
  return (
    <div onClick={handleClick}>
      {userData?.name}
      {isExpanded && <div>{userData?.email}</div>}
    </div>
  );
}
```

이 `UserCard`는 데이터(`isExpanded`, `userData`)와 로직(`useEffect`, `handleClick`)이 **강하게 결합** 되어 있습니다. 이 컴포넌트는 재사용이 어렵고, 테스트하기 까다로우며, 수많은 책임을 떠안은 '갓 오브젝트(God Object)'가 되기 쉽습니다.

**[ECS의 접근 방식 (데이터 지향)]**

우리의 **SSoT(Redux, Zustand 등)를 ECS의 '월드(World)' 또는 '컴포넌트 저장소'** 라고 상상해 봅시다. (이는 제4장에서 배운 '정규화된 상태' 그 자체입니다.)

```typescript
// 1. ECS 월드 (우리의 정규화된 SSoT)
// Entities: "card-1", "card-2" ...
// Components: UiState, UserLink, IsExpanded
interface AppState {
  entities: {
    uiState: Record<string, { // 예: 'card-1'
      isExpanded: boolean;
      isLoading: boolean;
    }>;
    userLinks: Record<string, { // 예: 'card-1'
      userId: 'u1'; // 'u1' 엔티티를 가리키는 포인터
    }>;
    users: Record<string, { // 예: 'u1'
      name: string;
      email: string;
    }>;
    // ...
  };
}
```

이제 **React 컴포넌트(View)** 와 **로직(System)** 을 분리합니다.

**A. React 컴포넌트 (RenderSystem의 일부)**

React 컴포넌트의 역할은 오직 하나입니다. SSoT(월드)에서 **데이터(컴포넌트)를 조회** 하여 화면에 그리는 것입니다. **React 컴포넌트는 로직을 소유하지 않습니다.**

```typescript
// 👍 ECS 방식의 React 컴포넌트 (멍청한 뷰)
function UserCardView({ entityId }: { entityId: string }) {
  // 1. SSoT(월드)에서 '엔티티'에 연결된 '컴포넌트'들을 조회
  const uiState = useStore(state => state.entities.uiState[entityId]);
  const userLink = useStore(state => state.entities.userLinks[entityId]);
  const user = useStore(state => state.entities.users[userLink.userId]);

  const dispatch = useDispatch(); // (시스템에 '명령'을 보내기 위함)

  const handleClick = () => {
    // 👎 setIsExpanded(true) (X)
    // 👍 시스템에게 '엔티티'의 상태 변경을 '요청'
    dispatch({ 
      type: 'systems/toggleExpand', // 'ToggleExpandSystem'을 실행하라
      payload: { entityId: entityId } 
    });
  };

  // 2. 렌더링 로직만 수행 (데이터 -> 뷰)
  return (
    <div onClick={handleClick}>
      {user?.name}
      {uiState.isExpanded && <div>{user?.email}</div>}
    </div>
  );
}
```

**B. 로직 (Systems)**

모든 로직은 React 외부의 '시스템'으로 격리됩니다. (이는 제3장의 '부수 효과 격리'와 제5장의 '액션' 개념입니다.)

```typescript
// (Redux Toolkit의 리듀서나 Thunk, Saga가 'System' 역할을 함)

// 👍 시스템 1: ToggleExpandSystem (Redux 리듀서)
// - 관심 대상: 'uiState' 컴포넌트를 가진 엔티티
// - 트리거: 'systems/toggleExpand' 액션
createReducer(initialState, (builder) => {
  builder.addCase('systems/toggleExpand', (state, action) => {
    const { entityId } = action.payload;
    const uiState = state.entities.uiState[entityId];
    if (uiState) {
      // 💥 로직 실행: 'uiState' 컴포넌트의 데이터를 변환
      uiState.isExpanded = !uiState.isExpanded;
    }
  });
});

// 👍 시스템 2: UserFetchSystem (Redux Thunk)
// - 관심 대상: 'userLinks'는 있지만 'users' 데이터는 없는 엔티티
// - 트리거: (컴포넌트 마운트 시 또는 특정 액션)
const fetchUserSystem = createAsyncThunk(
  'systems/fetchUser',
  async (entityId: string, { getState }) => {
    const state = getState();
    const userLink = state.entities.userLinks[entityId];
    const user = state.entities.users[userLink.userId];
    
    if (userLink && !user) {
      // 💥 부수 효과 실행
      const userData = await api.fetchUser(userLink.userId);
      // 'users' 컴포넌트 저장소에 데이터 쓰기
      return { [userLink.userId]: userData }; 
    }
  }
);
```

------


### 7.4. 결론: ECS, 데이터 지향의 궁극적인 청사진


ECS는 프론트엔드 개발자에게 전통적인 OOP의 컴포넌트 모델을 버리고 **데이터와 로직을 완전히 분리** 하는 새로운 사고방식을 요구합니다.

- **Entity**: UI를 구성하는 각 요소를 'ID'로 취급합니다.
- **Component**: 이 ID에 연결된 모든 '상태'를 SSoT(정규화된 스토어)에 **순수 데이터** 로 저장합니다.
- **System**: 사용자의 입력이나 이벤트에 반응하여, SSoT의 **데이터를 변환** 하는 **순수 로직** 으로 분리합니다.

React 컴포넌트는 더 이상 '똑똑한' 객체가 아닙니다. 그저 SSoT의 데이터를 화면에 그리는 '멍청한' 뷰(View)가 됩니다.

이 아키텍처는 제1부와 제2부에서 배운 모든 원칙(순수 함수, 불변성, 정규화, SSoT, 파생 상태)이 응집된 궁극적인 형태입니다. 모든 로직은 '시스템'에 집중되어 테스트와 재사용이 극도로 용이해지며, 모든 데이터는 '컴포넌트'로 SSoT에 집중되어 예측 가능성이 극대화됩니다.

다음 장에서는 이 ECS 패턴을 React 환경에서 구체적으로 어떻게 적용할 수 있는지 더 실용적인 기법들을 탐구해 보겠습니다.

------

네, 알겠습니다. 제3부의 두 번째 장, 'React에서 ECS 패턴 적용하기' 집필을 시작하겠습니다. 이전 장에서 배운 추상적인 ECS 개념이 React의 현실 세계와 어떻게 만나 시너지를 내는지 실용적인 관점에서 깊이 있게 탐구합니다.

------


## 8. React에서 ECS 패턴 적용하기


> "React 컴포넌트에 로직을 두지 마라. React 컴포넌트가 로직 그 자체가 되게 하라. React의 본질은 'RenderSystem'이며, 우리가 할 일은 그 시스템이 읽을 '데이터'를 잘 설계하는 것뿐이다."

제7장 'ECS 패턴'에서 우리는 데이터(Component), 로직(System), 그리고 ID(Entity)라는 세 가지 축으로 세상을 분해하는 강력한 아키텍처를 배웠습니다. 이 모델은 데이터와 로직을 완벽하게 분리하여 궁극의 유연성과 테스트 용이성을 제공합니다.

하지만 우리는 커다란 도전에 직면합니다. **React는 본질적으로 ECS 아키텍처가 아닙니다.**

React는 '컴포넌트'라는 객체 지향(OOP)과 유사한 모델을 기반으로 합니다. React 컴포넌트(`UserCard`)는 자신의 상태(state, **데이터**)와 생명주기 메서드(`useEffect`, **로직**), 그리고 이벤트 핸들러(`handleClick`, **로직**)를 하나의 '캡슐' 안에 함께 묶습니다. 이는 ECS가 그토록 피하고자 했던 '데이터와 로직의 결합' 바로 그 자체입니다.

그렇다면 우리는 React를 버려야 할까요? 아닙니다.

우리의 목표는 React를 대체하는 것이 아닙니다. 대신, **React의 작동 방식을 ECS의 '원칙'에 맞게 '재해석'하고 '적용'하는 것** 입니다. 우리는 React의 장점(선언적 렌더링, 거대한 생태계)을 그대로 누리면서, React 컴포넌트를 ECS의 'RenderSystem'으로 격리시키는 방법을 배울 것입니다.

본 장에서는 React의 세계관 안에서 Entity, Component, System을 각각 어떻게 구현하고 연결하는지 구체적인 TypeScript 예제와 함께 탐구합니다.

------


### 8.1. ECS 개념과 React 생태계 매핑하기


React 환경에서 ECS를 구현하는 것은 '라이브러리'의 문제가 아니라 '정신 모델(Mental Model)'의 문제입니다. 우리가 이미 배운 도구들을 ECS의 관점으로 재배치해 봅시다.


#### 8.1.1. Entity: `id` Prop


ECS의 Entity는 단순한 ID입니다. React에서 이는 `prop`으로 전달되는 `string` 또는 `number`입니다.

```typescript
// 엔티티 ID 'todo-1'과 'todo-2'를 렌더링하도록 '명령'
function TodoApp() {
  const todoIds = ['todo-1', 'todo-2']; // (실제로는 스토어에서 가져옴)

  return (
    <div>
      {/* TodoItemView 컴포넌트에게 "entityId 'todo-1'을 렌더링하라"고 지시.
        TodoItemView는 'todo-1'이 무엇인지, 어떻게 동작하는지 모른다.
      */}
      {todoIds.map(id => (
        <TodoItemView key={id} entityId={id} />
      ))}
    </div>
  );
}
```

엔티티 ID는 React 컴포넌트에게 "네가 렌더링할 대상이 무엇인지" 알려주는 유일한 식별자입니다.


#### 8.1.2. Component (Data): SSoT (Zustand, Redux)


ECS의 Component는 순수한 데이터 덩어리입니다. 이 데이터는 어디에 저장해야 할까요? 바로 제4장(정규화)과 제5장(SSoT)에서 구축한 **글로벌 상태 저장소(Store)** 입니다.

우리의 **정규화된 `entities` 객체** 가 바로 ECS의 **'컴포넌트 데이터 저장소(World)'** 그 자체입니다.

```typescript
// (Zustand 스토어 예시)
// 💥 이 AppState가 ECS의 'World'입니다.
interface AppState {
  // 'entities' 객체가 모든 'Component' 데이터를 저장
  entities: {
    // Position 컴포넌트 저장소
    positions: Record<string, { x: number; y: number }>;
    
    // Renderable 컴포넌트 저장소
    renderables: Record<string, { sprite: string }>;
    
    // Health 컴포넌트 저장소
    healths: Record<string, { current: number; max: number }>;
    
    // (프론트엔드) Todo 컴포넌트 저장소
    todos: Record<string, { text: string; completed: boolean }>;
  };
  
  // ... (System은 잠시 후)
}

// 'todo-1' 엔티티의 상태는?
// state.entities.todos['todo-1'] -> { text: '...', completed: false }
// 'player' 엔티티의 상태는?
// state.entities.positions['player'] -> { x: 10, y: 20 }
// state.entities.renderables['player'] -> { sprite: 'player.png' }
```

이 구조에서, 엔티티 'player'는 `Position`과 `Renderable` 컴포넌트를 '소유'합니다.


#### 8.1.3. System (Logic): Store Actions와 Reducers


ECS의 System은 데이터를 변환하는 순수한 로직입니다. 이 로직은 React 컴포넌트 내부에 있어서는 안 됩니다.

이 로직의 완벽한 위치가 바로 **스토어의 '액션(Actions)' 또는 '리듀서(Reducers)'** 입니다.

- **순수 데이터 변환 (Pure Systems)** :
  - (예: `MovementSystem`, `ToggleTodoSystem`)
  - **Zustand**: `set` 함수 내부의 동기적 로직.
  - **Redux**: 순수 함수인 '리듀서' 그 자체.
- **비동기/부수 효과 (Impure Systems)** :
  - (예: `FetchSystem`, `NotificationSystem`)
  - **Zustand**: `create` 함수 내부에 정의된 비동기 `action` 함수.
  - **Redux**: 'Thunk' 또는 'Saga'.

**[Zustand 스토어에 System 구현하기]**

```typescript
// (이전 AppState 인터페이스에 System을 추가)
interface AppState {
  entities: { ... }; // Component 데이터

  // --- Systems (Logic) ---
  
  // Pure System: 엔티티의 위치를 변경
  movementSystem: (entityId: string, dx: number, dy: number) => void;
  
  // Pure System: Todo의 완료 상태를 토글
  toggleTodoSystem: (entityId: string) => void;
  
  // Impure System: 엔티티의 체력을 API에서 가져옴
  fetchHealthSystem: (entityId: string) => Promise<void>;
}

// 스토어 구현
const useWorld = create<AppState>((set, get) => ({
  entities: { ... }, // 데이터 초기값

  // --- System 구현 ---
  
  movementSystem: (entityId, dx, dy) => set((state) => {
    const pos = state.entities.positions[entityId];
    if (!pos) return state; // 해당 컴포넌트가 없으면 무시

    // 💥 핵심 로직 (순수 함수)
    const newPos = { x: pos.x + dx, y: pos.y + dy };
    
    // 불변성 업데이트 (SSoT 쓰기)
    return produce(state, (draft) => {
      draft.entities.positions[entityId] = newPos;
    });
  }),
  
  toggleTodoSystem: (entityId) => set((state) => {
    const todo = state.entities.todos[entityId];
    if (!todo) return state;
    
    // 💥 핵심 로직 (순수 함수)
    return produce(state, (draft) => {
      draft.entities.todos[entityId].completed = !todo.completed;
    });
  }),
  
  fetchHealthSystem: async (entityId) => {
    try {
      // 💥 부수 효과 (Impure Shell)
      const healthData = await api.fetchHealth(entityId); 
      
      // SSoT 쓰기
      set(produce((state) => {
        draft.entities.healths[entityId] = healthData;
      }));
    } catch (e) { ... }
  },
}));
```

------


### 8.2. React의 역할: 오직 `RenderSystem`


이제 모든 데이터(Component)와 로직(System)이 스토어(`useWorld`)에 중앙화되었습니다. 그렇다면 React 컴포넌트는 대체 무엇을 해야 할까요?

**React 컴포넌트의 유일한 역할은 ECS의 `RenderSystem`이 되는 것입니다.**

`RenderSystem`의 책임:

1. **관심 있는 엔티티** 의 **데이터(Component)를 조회(Read)** 합니다. (제6장 셀렉터 활용)
2. 조회한 데이터를 기반으로 **DOM을 렌더링** 합니다. (부수 효과)
3. 사용자 입력(`onClick` 등)을 받으면, **로직을 실행하지 않고** , 대신 **'명령(Command)'을 중앙 시스템에 '전송(Dispatch)'** 합니다.


#### 8.2.1. "멍청한 뷰" (Dumb View) 패턴


ECS 스타일의 React 컴포넌트는 극도로 '멍청(Dumb)'해야 합니다.

**[ECS 스타일의 React 컴포넌트 예제]**

```typescript
// 1. 엔티티 ID만 prop으로 받음
function TodoItemView({ entityId }: { entityId: string }) {
  
  // 1. READ: SSoT(World)에서 이 엔티티의 'Component' 데이터를 조회
  // 'useShallow'는 불필요한 리렌더링을 막는 최적화
  const { todo, toggleSystem } = useWorld(
    (state) => ({
      todo: state.entities.todos[entityId], // 데이터(Component)
      toggleSystem: state.toggleTodoSystem, // 로직(System)
    }),
    useShallow // Zustand의 shallow-compare 훅
  );

  if (!todo) {
    return null; // 이 엔티티는 'todo' 컴포넌트가 없음
  }

  const handleClick = () => {
    // 3. DISPATCH: 로직을 직접 실행하지 않음
    // 👎 todo.completed = !todo.completed (X)
    // 👎 setTodoState(...) (X)
    
    // 👍 System에게 "이 엔티티를 토글하라"는 '명령'을 전송
    toggleSystem(entityId);
  };

  // 2. RENDER: 조회한 데이터를 기반으로 렌더링
  return (
    <li
      style={{ textDecoration: todo.completed ? 'line-through' : 'none' }}
      onClick={handleClick}
    >
      {todo.text}
    </li>
  );
}
```

이 `TodoItemView` 컴포넌트를 보십시오. 이 컴포넌트는 `todo`의 `completed` 상태가 **'어떻게'** 토글되는지 전혀 모릅니다. `toggleSystem`이라는 블랙박스를 호출할 뿐입니다.

`useEffect`, `useState`, `useCallback`이 모두 사라졌습니다. 오직 SSoT로부터 데이터를 **읽고(Read)** , SSoT에게 명령을 **전송(Dispatch)** 할 뿐입니다.

------


### 8.3. React-ECS 접근 방식의 장점


이 모델은 제7장의 ECS 장점을 React 환경에 그대로 가져옵니다.

1. **궁극의 관심사 분리 (SoC)** :

   - **React 컴포넌트 (`.tsx`)** : '무엇을 그릴 것인가' (View)
   - **스토어/시스템 (`.ts`)** : '무엇을 할 것인가' (Logic)
   - `TodoItemView.tsx`를 수정하지 않고도 `toggleTodoSystem`의 로직(예: 토글 시 API 호출 추가)을 마음껏 변경할 수 있습니다.

2. **쉬운 테스트** :

   - `toggleTodoSystem` 로직을 테스트하기 위해 React 컴포넌트를 렌더링하거나 `fireEvent.click`을 할 필요가 없습니다.
   - 스토어의 인스턴스를 만들고, `state`를 설정한 뒤, `useWorld.getState().toggleTodoSystem('todo-1')`을 호출하고, `state`의 변경을 검증하면 끝입니다. 로직 테스트가 React와 완전히 분리됩니다.

3. **최고의 유연성 (조합)** :

   - **요구사항**: "Todo 항목을 '삭제'할 수 있게 해주세요."

   - **OOP 방식** : `TodoItem` 컴포넌트를 열고, `handleDelete` 로직을 추가하고, `useState`로 '삭제 중' 상태를 추가하고...

   - **ECS 방식** :

     1. (데이터) `useWorld` 스토어에 `deletable: Record<string, boolean>` 컴포넌트 저장소를 추가합니다. (혹은 `todo` 컴포넌트에 `deletable: true` 속성 추가)

     2. (로직) `deleteTodoSystem: (entityId: string) => void` 시스템을 스토어에 구현합니다.

     3. (뷰) `TodoItemView.tsx`를 수정합니다.

        ```typescript
        // 1. READ (Deletable 컴포넌트와 Delete 시스템 조회)
        const isDeletable = useWorld(state => ...);
        const deleteSystem = useWorld(state => state.deleteTodoSystem);
        
        // 2. RENDER (삭제 버튼 추가)
        {isDeletable && <button onClick={() => deleteSystem(entityId)}>삭제</button>}
        ```

   - `TodoItemView`는 '삭제' 로직을 몰라도 됩니다. 그저 '삭제 가능'(`isDeletable`) 컴포넌트가 있으면 '삭제' 시스템을 호출하는 버튼을 렌더링할 뿐입니다.

4. **로직의 중앙화 및 재사용** :

   - `toggleTodoSystem` 로직은 `TodoItemView`의 `handleClick`에 갇혀있지 않습니다.
   - '모두 완료' 버튼이 필요하다면? 그저 모든 `todoId`를 `map` 돌면서 `toggleTodoSystem(id)`를 호출하면 됩니다.
   - 웹소켓 이벤트로 'todo'가 토글되어야 한다면? 웹소켓 핸들러가 `toggleTodoSystem(id)`를 호출하면 됩니다.
   - 로직이 중앙화되어 어디서든 재사용할 수 있습니다.

------


### 8.4. '갓 스토어(God Store)' 문제에 대한 고찰


이 접근법에 대한 가장 흔한 비판은 "모든 로직을 하나의 거대한 스토어에 몰아넣어 '갓 오브젝트' 문제를 '갓 스토어' 문제로 바꾼 것뿐이지 않느냐?"는 것입니다.

일리가 있는 지적이지만, 이는 **관점의 차이** 입니다.

1. **중앙화는 의도된 설계** : 로직을 중앙화하는 것은 '버그'가 아니라 '기능'입니다. 로직을 '관심사(Concern)'별로 묶는 것은(예: `todoSystems.ts`, `userSystems.ts`) 수백 개의 뷰 컴포넌트에 로직이 흩어지는 것보다 훨씬 관리하기 쉽습니다.
2. **분리(Slicing)는 가능** : '갓 스토어'를 피하는 방법은 이미 존재합니다.
   - **Redux**: `combineReducers`와 'Slices'가 이 역할을 합니다.
   - **Zustand**: 여러 개의 스토어를 만들거나(`useTodoWorld`, `useUserWorld`), 미들웨어를 사용해 스토어를 조합할 수 있습니다.
   - **Jotai**: 'Atom' 자체가 ECS의 '컴포넌트 데이터'와 유사한 극도로 분리된 모델을 제공합니다.

핵심은 **'뷰(View)의 계층'과 '로직(Logic)의 계층'을 분리** 하는 것입니다. React 컴포넌트는 뷰 계층에 속하고, 시스템(스토어)은 로직 계층에 속합니다. 이 둘이 `entityId`와 '명령(Action)'을 통해서만 소통하는 것이 React-ECS 모델의 핵심입니다.


### 8.5. 결론: React는 훌륭한 RenderSystem이다


React와 ECS는 적대적 관계가 아닙니다. React-ECS 모델은 React의 강점(선언적 렌더링)을 극대화하고 약점(데이터와 로직의 결합)을 보완합니다.

- React 컴포넌트를 **'RenderSystem'** 으로 취급하십시오. 그들의 유일한 임무는 데이터를 렌더링하고, 입력을 받아 '명령'을 시스템에 전달하는 것입니다.
- 글로벌 스토어(Zustand, Redux)를 **'World'** 로 취급하십시오. 이곳은 모든 **'Component(데이터)'** 가 정규화되어 저장되고, 모든 **'System(로직)'** 이 액션/리듀서로 정의되는 중앙 허브입니다.

이 모델은 우리가 1부, 2부에서 배운 모든 원칙(순수 함수, 불변성, 정규화, SSoT, 파생 상태)이 자연스럽게 녹아드는 하나의 일관된 청사진입니다.

이제 이 '조합(Composition)'의 힘을 한 단계 더 발전시켜, React 컴포넌트 자체의 조합 방식을 새롭게 정의하는 다음 장으로 나아갈 준비가 되었습니다.

------

네, 알겠습니다. 제3부의 세 번째 장, '컴포넌트 조합(composition)의 새로운 접근' 집필을 시작하겠습니다. 이 장에서는 ECS 패턴의 데이터 조합 사상이 어떻게 React UI 컴포넌트의 조합 방식을 근본적으로 변화시키는지 탐구합니다.

------


## 9. 컴포넌트 조합(composition)의 새로운 접근


> "React의 '컴포넌트'는 상속받기 위해 존재하는 것이 아니라 조합되기 위해 존재한다. 하지만 무엇을, 어떻게 조합할 것인가? 데이터 지향 설계는 '슬롯(Slot)'이 아닌 '데이터' 그 자체를 조합의 기준으로 삼으라고 말한다."

제7장과 제8장에서 우리는 Entity-Component-System(ECS)이라는 강력한 데이터 지향 아키텍처를 React 환경에 적용하는 법을 배웠습니다. 이 모델의 핵심은 **데이터(Component)와 로직(System)의 완벽한 분리** 였습니다. React 컴포넌트는 모든 로직을 스토어(World)의 '시스템'에게 위임하고, 자신은 `entityId`를 받아 데이터를 SSoT에서 조회하여 렌더링만 담당하는 '멍청한 RenderSystem'의 역할을 맡았습니다.

이로써 우리는 '로직의 분리'라는 절반의 목표를 달성했습니다. 하지만 '조합(Composition)'이라는 나머지 절반의 문제가 남았습니다.

전통적인 React 컴포넌트(`UserCard`)는 여전히 `user` 데이터, `settings` 데이터, `permissions` 데이터를 모두 알아야 하는 **모놀리식(Monolithic) 갓 컴포넌트** 가 되기 쉽습니다. `UserCard`가 `entityId`만 받도록 리팩토링했다 해도, 그 내부는 여전히 `useUser(entityId)`, `useSettings(entityId)` 등을 호출하며 해당 엔티티의 *모든* 데이터 측면을 알아야 합니다.

ECS의 진정한 사상은 **"데이터 조각(Component)을 조합하여 존재(Entity)를 정의한다"** 는 것입니다.

그렇다면 우리의 UI(React 컴포넌트) 역시, **"UI 조각(Renderer)을 조합하여 엔티티의 뷰(View)를 정의한다"** 는 사상을 따라야 하지 않을까요? 본 장에서는 전통적인 '슬롯 기반 조합'과 '훅 기반 조합'을 넘어, ECS의 데이터 모델을 UI 계층에 그대로 반영하는 **'데이터 주도 조합(Data-Driven Composition)'** 이라는 새로운 접근법을 탐구합니다.

------


### 9.1. 전통적인 React 조합 방식의 한계


React는 조합을 핵심 원칙으로 삼지만, 그 방식은 크게 두 가지로 나뉩니다.


#### 9.1.1. 슬롯 기반 조합 (Slot-based Composition)


'children' prop이나 명명된 prop(예: `header`, `footer`)을 통해 컴포넌트의 '슬롯'에 다른 컴포넌트를 끼워 넣는 방식입니다.

```typescript
// 👎 슬롯 기반 조합
// Card 컴포넌트는 'header'와 'body'라는 슬롯을 '기대'한다.
function Card({ header, body }: { header: React.ReactNode; body: React.ReactNode }) {
  return (
    <div>
      <header>{header}</header>
      <main>{body}</main>
    </div>
  );
}

// 부모 컴포넌트가 슬롯을 채워야 한다.
function Page() {
  return <Card 
           header={<h1>제목</h1>} 
           body={<p>내용...</p>} 
         />;
}
```

- **문제점**: 이 조합은 **정적(Static)** 입니다. `Card` 컴포넌트는 자신이 `header`와 `body`를 가진다는 사실을 미리 알고 정의해야 합니다. 만약 '이미지' 슬롯을 추가하려면 `Card` 컴포넌트 자체를 수정해야 합니다. 유연성이 떨어집니다.


#### 9.1.2. 훅 기반 조합 (Hook-based Composition)


더 현대적인 방식은 커스텀 훅을 사용하여 로직과 상태를 조합하는 것입니다.

```typescript
// 👎 훅 기반 조합 (갓 컴포넌트의 탄생)
function UserProfile({ entityId }: { entityId: string }) {
  // 1. 이 컴포넌트는 자신이 보여줄 '모든' 데이터의 존재를 알고 있다.
  const user = useUser(entityId);
  const settings = useSettings(entityId);
  const permissions = usePermissions(entityId);

  // 2. 이 컴포넌트는 '모든' 데이터를 렌더링할 책임을 진다.
  return (
    <div>
      <h1>{user.name}</h1>
      <section>
        <h2>설정</h2>
        <input type="checkbox" checked={settings.darkMode} />
      </section>
      <section>
        <h2>권한</h2>
        {permissions.canEdit && <button>수정</button>}
      </section>
    </div>
  );
}
```

- **문제점**: 제8장에서 지적했듯이, `UserProfile`은 '사용자 데이터', '설정 데이터', '권한 데이터'의 존재를 모두 알아야 하는 거대한 책임을 가집니다. "설정" 기능을 제거하려면 `UserProfile` 컴포넌트 코드를 직접 수정해야 합니다. 데이터와 뷰가 여전히 강하게 결합되어 있습니다.

------


### 9.2. 새로운 접근: 'Renderer per Component' 패턴


ECS 사상은 우리에게 다른 해답을 제시합니다. **"하나의 데이터 `Component`는, 하나의 UI `Renderer`에 대응한다."**

`UserProfile`이라는 모놀리식 컴포넌트 대신, 우리는 각 데이터 조각을 렌더링하는 극도로 작고 멍청한 'Renderer' 컴포넌트들을 만듭니다.

```typescript
// (SSoT는 제8장에서 정의한 'World' 스토어를 사용)

// 1. UserData(Component)를 위한 Renderer
function UserDataRenderer({ entityId }: { entityId: string }) {
  const user = useWorld(state => state.entities.users[entityId]);
  if (!user) return null;
  return <h1>{user.name}</h1>;
}

// 2. Settings(Component)를 위한 Renderer
function SettingsRenderer({ entityId }: { entityId: string }) {
  const settings = useWorld(state => state.entities.settings[entityId]);
  if (!settings) return null;
  return (
    <section>
      <h2>설정</h2>
      <input type="checkbox" checked={settings.darkMode} />
      {/* ... 로직은 System에 위임 ... */}
    </section>
  );
}

// 3. Permissions(Component)를 위한 Renderer
function PermissionsRenderer({ entityId }: { entityId: string }) {
  const permissions = useWorld(state => state.entities.permissions[entityId]);
  if (!permissions) return null;
  return (
    <section>
      <h2>권한</h2>
      {permissions.canEdit && <button>수정</button>}
    </section>
  );
}
```

이 'Renderer' 컴포넌트들은 **자신이 담당하는 데이터 외에는 아무것도 모릅니다.** `SettingsRenderer`는 `PermissionsRenderer`의 존재 자체를 알지 못합니다. 이들은 완벽하게 분리되어 있습니다.

------


### 9.3. 데이터 주도 조합 (Data-Driven Composition)


이제 이 'Renderer 조각'들을 어떻게 조합할까요?

여기서 '데이터 주도 조합'이 등장합니다. 우리는 엔티티의 뷰를 렌더링하는 `EntityRenderer`라는 루트 컴포넌트를 만듭니다. 이 컴포넌트의 유일한 임무는 SSoT(World)를 확인하여, **"이 엔티티가 '어떤' 데이터 컴포넌트를 가졌는지"** 를 보고, 그에 **해당하는 'Renderer'를 조건부로 렌더링** 하는 것입니다.

**[데이터 주도 조합의 구현]**

```typescript
// (모든 Renderer들을 맵으로 관리)
const componentRenderers: Record<string, React.ComponentType<{ entityId: string }>> = {
  users: UserDataRenderer,
  settings: SettingsRenderer,
  permissions: PermissionsRenderer,
  // ... (새로운 Renderer가 생기면 여기에 추가)
};

// 엔티티가 가진 데이터 컴포넌트의 '키(key)' 목록
const componentKeys = Object.keys(componentRenderers);

/**
 * 💥 데이터 주도 조합의 핵심: EntityRenderer
 */
function EntityRenderer({ entityId }: { entityId: string }) {
  
  // 1. 이 엔티티가 가진 '모든' 데이터 컴포넌트의 존재 여부를 SSoT에서 확인
  const entityDataComponents = useWorld(
    (state) => {
      const components: Record<string, boolean> = {};
      for (const key of componentKeys) {
        // state.entities['users'][entityId]가 있는지?
        // state.entities['settings'][entityId]가 있는지?
        components[key] = state.entities[key]?.[entityId] != null;
      }
      return components;
    },
    useShallow // 객체 비교를 위한 최적화
  );

  // 2. 데이터가 '존재하는' Renderer들만 조합하여 렌더링
  return (
    <div data-entity-id={entityId}>
      {componentKeys.map(key => {
        const hasComponent = entityDataComponents[key];
        if (hasComponent) {
          const Renderer = componentRenderers[key];
          return <Renderer key={key} entityId={entityId} />;
        }
        return null;
      })}
    </div>
  );
}

// --- 사용 예시 ---
function App() {
  const entityId = 'user-1';
  return <EntityRenderer entityId={entityId} />;
}
```

이 `EntityRenderer`는 '슬롯'을 정의하지 않습니다. `UserProfile`처럼 '무엇을' 렌더링할지 미리 알지 못합니다.

`EntityRenderer`는 SSoT의 **데이터 구조 그 자체를 '반영(Reflect)'** 합니다.

------


### 9.4. '데이터 주도 조합'의 압도적인 유연성


이 새로운 접근 방식이 가져오는 이점은 거대합니다.

1. **동적 UI (Dynamic UI by Default)** :
   - **요구사항**: "'user-1'에게서 '설정' 기능을 일시적으로 제거하고 싶다."
   - **전통 방식** : `UserProfile`에 `showSettings={false}` prop을 추가하고, 내부 로직을 수정해야 합니다.
   - **ECS 방식** : **React 코드를 한 줄도 수정하지 않습니다.**
     - 스토어의 '시스템'을 호출하여 `state.entities.settings['user-1']` 데이터 **컴포넌트 자체를 SSoT에서 '제거'** 합니다.
     - `EntityRenderer`는 `entityDataComponents.settings`가 `false`가 된 것을 감지합니다.
     - `SettingsRenderer`는 렌더링 목록에서 **자동으로 제외** 됩니다. (언마운트됨)
   - UI의 구조가 SSoT의 데이터 구조에 의해 1:1로 동적으로 결정됩니다.
2. **궁극의 관심사 분리 (SoC)** :
   - `SettingsRenderer`는 `PermissionsRenderer`를 몰라도 됩니다.
   - `EntityRenderer`는 `SettingsRenderer`가 *무엇을* 하는지 몰라도 됩니다.
   - 각 Renderer는 자신이 맡은 데이터 외에는 아무것도 알 필요가 없습니다.
3. **확장성 (Scalability)** :
   - **요구사항**: "엔티티에 '인벤토리' 기능을 추가하고 싶다."
   - **전통 방식** : `UserProfile`을 열고 `useInventory` 훅을 추가하고, 렌더링 JSX를 추가합니다.
   - **ECS 방식** :
     1. (데이터) SSoT에 `entities.inventories` 저장소를 추가합니다.
     2. (로직) `InventorySystem`을 스토어에 추가합니다.
     3. (뷰) `InventoryRenderer.tsx` 파일을 **새로 생성** 합니다.
     4. `componentRenderers` 맵에 `'inventories': InventoryRenderer`를 **한 줄 추가** 합니다.
   - `UserProfile` 같은 기존 코드를 전혀 건드리지 않고도 기능이 완벽하게 추가됩니다. 이는 **OCP(개방-폐쇄 원칙)** 의 완벽한 구현입니다.
4. **진정한 재사용성 (True Reusability)** :
   - `HealthBarRenderer`가 있다고 상상해 봅시다.
   - '플레이어'(`user-1`), '몬스터'(`monster-1`), '파괴 가능한 상자'(`box-1`)가 있습니다.
   - 이 셋은 완전히 다른 존재입니다.
   - 하지만 **셋 다 SSoT에 `entities.healths[...]` 데이터 컴포넌트를 가지고 있다면?**
   - `EntityRenderer`는 `user-1`, `monster-1`, `box-1` 모두에게 **동일한 `HealthBarRenderer`를 자동으로 렌더링** 해 줍니다.
   - UI 컴포넌트가 `type === 'player'` 같은 분기문에서 해방됩니다. 오직 '데이터의 존재'만이 중요합니다.

------


### 9.5. 결론: UI도 데이터다


'컴포넌트 조합의 새로운 접근'이란, UI 컴포넌트를 조립하는 방식마저도 **데이터 지향적** 으로 바꾸는 것을 의미합니다.

- **전통적인 조합** : "이 `Card`는 `header`와 `body`라는 **슬롯**을 가진다." (뷰가 구조를 정의)
- **데이터 주도 조합** : "이 `Entity`는 `Position`과 `Health`라는 **데이터**를 가진다. 그러므로 `PositionRenderer`와 `HealthBarRenderer`를 렌더링한다." (데이터가 구조를 정의)

이 모델은 React 컴포넌트 트리를 SSoT 데이터 구조의 **실시간 '반영(Reflection)'** 으로 만듭니다. React의 선언적 렌더링 파워와 ECS의 동적 데이터 조합 파워가 만나는 지점입니다.

이제 우리는 데이터(Component)를 조합하여 존재(Entity)를 정의하고, 로직(System)으로 이를 변환하며, UI(Renderer)를 조합하여 이를 화면에 그리는, 완벽하게 분리되고 일관된 데이터 지향 아키텍처의 청사진을 완성했습니다.

------

네, 알겠습니다. 제3부의 네 번째 장, '이벤트 소싱과 CQRS'의 첫 번째 파트인 '프론트엔드에서의 이벤트 소싱 구현' 집필을 시작하겠습니다. 이 장에서는 상태를 '덮어쓰는' 방식이 아닌, '기록하는' 방식으로 시스템을 설계하는 근본적인 패러다임의 전환을 탐구합니다.

------


## 10. 이벤트 소싱과 CQRS - 프론트엔드에서의 이벤트 소싱 구현


> "상태(State)는 거짓말이다. 그것은 어느 한순간의 스냅샷일 뿐, 진실을 담고 있지 않다. 진실은 오직 그 상태에 도달하기까지의 '과정(Events)' 속에만 존재한다."

지금까지 우리는 '상태'를 애플리케이션의 중심으로 다루었습니다. 제4장(정규화)과 제5장(SSoT)에서 우리는 '현재(current)' 상태를 어떻게 잘 구조화하고 단일 진실 공급원으로 관리할지에 대해 집중했습니다. 사용자가 이름을 "Alice"에서 "Bob"으로 바꾸면, 우리는 `state.users['u1'].name = "Bob"`으로 **데이터를 덮어썼습니다.** "Alice"라는 이전 정보는 사라졌습니다. 이것이 바로 **'상태 지향(State-Oriented)'** 설계입니다.

하지만 만약, 우리가 데이터를 덮어쓰는 대신, 발생한 **'모든 사건(Events)'** 을 시간 순서대로 **'기록(Log)'** 한다면 어떨까요?

- `[10:01] UserCreated (id: 'u1', name: 'Alice')`
- `[10:05] UserRenamed (id: 'u1', newName: 'Bob')`
- `[10:07] UserAvatarChanged (id: 'u1', avatarUrl: '...')`

이것이 바로 **이벤트 소싱(Event Sourcing, ES)** 의 핵심입니다. 이벤트 소싱에서 **SSoT(단일 진실 공급원)는 '현재 상태'가 아니라, '이벤트의 전체 로그(Log)'** 그 자체입니다.

'현재 상태'는 무엇일까요? 그것은 이 이벤트 로그를 처음부터(혹은 특정 시점부터) 순서대로 '재생(Replay)'하여 **계산해낸 결과(Projection)** 일 뿐입니다. `State = f(Event1, Event2, ... EventN)`입니다.

가장 완벽한 비유는 **은행 계좌 원장** 입니다. 은행은 당신의 '현재 잔액'을 SSoT로 저장하지 않습니다. 모든 '입금'과 '출금'이라는 **거래 내역(이벤트)** 을 SSoT로 저장합니다. 당신의 '현재 잔액'은 이 거래 내역을 처음부터 끝까지 합산하여 *계산된 파생 상태*일 뿐입니다.

프론트엔드에서 이 패턴은 Redux DevTools의 '시간 여행 디버깅'을 통해 이미 그 강력함을 증명했습니다. 본 장에서는 이 이벤트 소싱의 원칙을 프론트엔드 아키텍처에 어떻게 적용할 수 있는지 깊이 있게 탐구합니다.

------


### 10.1. 왜 프론트엔드에서 이벤트 소싱인가?


전통적인 백엔드(예: MSA)에서 이벤트 소싱은 시스템 간의 데이터 일관성, 감사 추적(Audit Trail), 확장성을 위해 사용됩니다. 프론트엔드에서는 조금 더 구체적이고 즉각적인 이점을 얻을 수 있습니다.

1. **궁극의 디버깅: 시간 여행 (Time Travel Debugging)**
   - 프론트엔드 버그의 90%는 "어떻게 이 상태가 되었지?"를 추적하는 과정입니다.
   - 상태 지향 모델에서는 'Bob'이라는 현재 상태만 알 뿐, 'Alice'였다가 'Bob'이 된 것인지, 'Charlie'였다가 'Bob'이 된 것인지 알 수 없습니다.
   - 이벤트 소싱에서는 **사용자가 수행한 모든 액션(이벤트)이 로그에 그대로** 남아있습니다. 버그가 발생한 시점까지 이벤트를 그대로 재현(Replay)하면 100% 버그를 재현할 수 있습니다. Redux DevTools가 바로 이 원리로 동작합니다.
2. **간편한 Undo / Redo 구현**
   - Figma, Google Docs, 포토샵 같은 복잡한 애플리케이션을 생각해 봅시다. '실행 취소(Undo)'는 핵심 기능입니다.
   - 상태 지향 모델에서 'Undo'를 구현하는 것은 재앙입니다. `UserRenamed`의 '반대(inverse)' 액션인 `UserRenamedInverse`를 계산하는 복잡한 로직이 필요합니다.
   - 이벤트 소싱 모델에서 **'Undo'는 그저 "마지막 이벤트를 제외하고 처음부터 다시 재생"** 하라는 명령일 뿐입니다. `Redo`는 "제외했던 이벤트를 다시 포함하여 재생"하라는 명령입니다. 로직이 믿을 수 없을 만큼 단순해집니다.
3. **강력한 분석 및 감사 (Analytics & Audit)**
   - 사용자가 장바구니에서 어떤 순서로 아이템을 담고, 빼고, 쿠폰을 적용했는지 정확히 알 수 있습니다.
   - `['ITEM_ADDED', 'ITEM_ADDED', 'COUPON_APPLIED', 'ITEM_REMOVED']` 로그는 '현재 장바구니 상태'보다 훨씬 더 가치 있는 비즈니스 데이터입니다.
4. **로직의 분리 (Decoupling)**
   - 시스템(System)은 '상태'를 구독하는 대신 '이벤트'를 구독할 수 있습니다. (ECS 패턴과 연결)
   - `CHECKOUT_COMPLETED` 이벤트가 발생하면, `AnalyticsSystem`은 이 이벤트를 받아 GA로 전송하고, `CacheSystem`은 장바구니 캐시를 비웁니다. 두 시스템은 서로의 존재를 알 필요가 없습니다.

------


### 10.2. 프론트엔드 이벤트 소싱의 구성 요소 (TypeScript)


이벤트 소싱 아키텍처를 TypeScript로 구현하는 것은 세 가지 핵심 요소로 나뉩니다.

1. **이벤트 (Events)** : *'무슨 일이 일어났는가'*를 기술하는 불변의 사실. (데이터)
2. **이벤트 로그 (Event Log)** : 이벤트를 저장하는 SSoT. (데이터베이스)
3. **프로젝터 (Projector)** : 이벤트 로그를 읽어 '현재 상태'를 계산하는 순수 함수. (로직)


#### 10.2.1. 이벤트 (Events) 정의하기


이벤트는 시스템에서 발생할 수 있는 모든 '사건'을 의미합니다. TypeScript의 **식별 가능한 유니언(Discriminated Unions)** 은 이벤트를 모델링하는 데 완벽한 도구입니다.

```typescript
// (장바구니 예시)
// 💥 핵심: 이벤트는 '과거형'으로 명명하며, '무엇이' 일어났는지 명시합니다.
// 'UpdateQuantity' (명령)가 아니라, 'QuantityUpdated' (사건)입니다.

type CartEvent =
  | {
      type: 'CART_CREATED';
      timestamp: number;
      payload: { userId: string };
    }
  | {
      type: 'ITEM_ADDED';
      timestamp: number;
      payload: { itemId: string; name: string; price: number };
    }
  | {
      type: 'ITEM_REMOVED';
      timestamp: number;
      payload: { itemId: string };
    }
  | {
      type: 'QUANTITY_UPDATED';
      timestamp: number;
      payload: { itemId: string; quantity: number };
    }
  | {
      type: 'CHECKOUT_STARTED';
      timestamp: number;
      payload: {};
    };
```

이 `CartEvent` 타입 정의가 시스템의 모든 비즈니스 로직을 문서화하는 '명세서'가 됩니다.


#### 10.2.2. 이벤트 로그 (Event Log)


이벤트 로그는 SSoT이며, 본질적으로 **이벤트의 불변 배열** 입니다.

```typescript
// SSoT는 '상태'가 아니라 '이벤트 로그'입니다.
// 실제 앱에서는 이 로그가 IndexedDB, localStorage, 
// 또는 Zustand/Redux 스토어의 '한 조각'일 수 있습니다.
let eventLog: CartEvent[] = [];

// '명령(Command)'을 받아 '이벤트'를 생성하고 로그에 추가하는 함수
// (이것은 '불순한 쉘'에 속합니다)
function addItemToCart(itemId: string, name: string, price: number) {
  // ... (유효성 검사 등) ...
  
  // 1. 이벤트 생성
  const event: CartEvent = {
    type: 'ITEM_ADDED',
    timestamp: Date.now(),
    payload: { itemId, name, price }
  };
  
  // 2. SSoT(로그)에 이벤트를 '저장' (덮어쓰기가 아님!)
  eventLog.push(event);
  
  // (이후 이 이벤트를 브로드캐스팅하여 상태 프로젝터를 실행)
}
```


#### 10.2.3. 프로젝터 (Projector)와 현재 상태


**프로젝터(Projector)**는 이벤트 로그를 '읽어서' '현재 상태(뷰 모델)'를 계산하는 **순수 함수**입니다.

이것이 어디서 많이 본 패턴 같지 않나요? (previousState, event) => newState

네, 이것은 Redux의 리듀서(Reducer)와 100% 동일한 개념입니다.

```typescript
// (우리가 UI에 보여줄 '파생 상태'의 타입)
interface CartItem {
  id: string;
  name: string;
  price: number;
  quantity: number;
}
interface CartState {
  items: Record<string, CartItem>;
  status: 'pending' | 'checkout' | 'ordered';
}

// 1. 프로젝션의 초기 상태
const initialState: CartState = {
  items: {},
  status: 'pending'
};

// 2. 프로젝터 (리듀서)
// 💥 (state, event) => newState 형태의 순수 함수
function cartStateProjector(state: CartState, event: CartEvent): CartState {
  switch (event.type) {
    case 'CART_CREATED':
      return initialState;

    case 'ITEM_ADDED':
      return produce(state, draft => {
        const { itemId, name, price } = event.payload;
        if (draft.items[itemId]) {
          draft.items[itemId].quantity += 1; // 이미 있으면 수량 증가
        } else {
          draft.items[itemId] = { id: itemId, name, price, quantity: 1 };
        }
      });
      
    case 'ITEM_REMOVED':
      return produce(state, draft => {
        delete draft.items[event.payload.itemId];
      });

    case 'QUANTITY_UPDATED':
      return produce(state, draft => {
        const item = draft.items[event.payload.itemId];
        if (item) {
          item.quantity = event.payload.quantity;
        }
      });

    case 'CHECKOUT_STARTED':
      return produce(state, draft => {
        draft.status = 'checkout';
      });

    default:
      // 이 프로젝터가 관심 없는 이벤트는 무시
      return state;
  }
}

// 3. 현재 상태 계산 (SSoT인 로그를 reduce)
function getCurrentState(log: CartEvent[]): CartState {
  console.time('프로젝션 계산');
  const currentState = log.reduce(cartStateProjector, initialState);
  console.timeEnd('프로젝션 계산');
  return currentState;
}
```

------


### 10.3. 성능 문제와 스냅샷 (Snapshots)


`getCurrentState` 함수를 본 여러분은 즉시 의문을 제기할 것입니다. "이벤트가 100만 개 쌓이면, 상태를 한 번 볼 때마다 100만 번의 `reduce`를 실행해야 하나요? 앱이 멈출 겁니다."

정확한 지적입니다. 이것이 '순수한' 이벤트 소싱의 가장 큰 성능적 허들입니다.

해결책은 '은행 원장'의 비유로 돌아가는 것입니다. 은행은 매번 태초의 거래부터 잔액을 계산하지 않습니다. **'월말 결산'**이나 **'일일 마감'**을 통해 특정 시점의 잔액 **스냅샷(Snapshot)**을 저장합니다.

프론트엔드에서도 동일합니다.

1. **스냅샷(Snapshot)**: 특정 시점(예: 100번째 이벤트)의 '계산된 상태'를 별도로 저장합니다.

2. 현재 상태 계산:

   a. 가장 최신의 스냅샷을 불러옵니다.

   b. 스냅샷이 생성된 이후의 이벤트들만 eventLog에서 가져옵니다.

   c. 스냅샷 상태를 초기값으로, '새로운' 이벤트들만 reduce(프로젝션)합니다.

```typescript
interface StateSnapshot {
  state: CartState;
  lastEventTimestamp: number; // 마지막으로 처리한 이벤트의 타임스탬프
}

// (실제로는 localStorage나 IndexedDB에 저장)
let latestSnapshot: StateSnapshot = {
  state: initialState,
  lastEventTimestamp: 0
};

function getCurrentStateOptimized(log: CartEvent[]): CartState {
  // 1. 스냅샷 이후의 새 이벤트만 필터링
  const newEvents = log.filter(
    event => event.timestamp > latestSnapshot.lastEventTimestamp
  );

  if (newEvents.length === 0) {
    return latestSnapshot.state; // 변경 없음
  }

  // 2. 스냅샷 상태를 초기값으로, '새 이벤트'만 프로젝션
  const currentState = newEvents.reduce(
    cartStateProjector,
    latestSnapshot.state // 💥 초기값이 initialState가 아님!
  );

  // 3. (성능을 위해) 새 스냅샷 저장
  // (실제로는 100개 이벤트마다, 또는 5초마다 등 전략적으로 수행)
  latestSnapshot = {
    state: currentState,
    lastEventTimestamp: log[log.length - 1].timestamp
  };

  return currentState;
}
```


### 10.4. Redux는 이벤트 소싱인가? (매우 중요한 질문)


**아닙니다. 하지만 강력하게 영감을 받았습니다.**

이 차이를 이해하는 것이 프론트엔드 아키텍처를 설계하는 데 매우 중요합니다.

- **순수 이벤트 소싱 (Pure ES)**:
  - **SSoT**: 이벤트 로그 (`eventLog: Event[]`)
  - **현재 상태**: 파생 상태 (로그를 `reduce`하여 계산)
  - **장점**: 완벽한 로그, Undo/Redo 용이.
  - **단점**: 상태를 읽을 때마다 계산 비용 발생 (스냅샷으로 완화).
- **Redux (및 Zustand, MobX 등)**:
  - **SSoT**: **현재 상태** (`currentState: State`)
  - **이벤트 로그**: Redux DevTools에 의해 **부수적으로** 수집되는 임시 데이터. (프로덕션 빌드에서는 보통 비활성화됨)
  - **장점**: 상태 읽기 비용이 없음. `useStore(state => state.cart)`는 $O(1)$입니다.
  - **단점**: '로그'가 SSoT가 아니므로, 프로덕션에서 Undo/Redo나 감사 추적을 하려면 **직접 로그(스택)를 구현해야 합니다.**

**Redux는 이벤트 소싱의 '프로젝터(리듀서)' 개념과 '이벤트(액션)' 개념만 차용한, '상태 지향' 아키텍처입니다.**

프론트엔드에서 '순수 ES'를 구현하는 것은 오프라인 우선(Offline-first) 앱이나 Yjs, Automerge 같은 CRDT 기반의 **협업(Collaborative) 애플리케이션**처럼 '이벤트의 순서' 자체가 비즈니스 로직의 핵심일 때 사용됩니다. (이는 5부 '고급 주제'에서 다룹니다)

------


### 10.5. 결론: '무엇'이 아닌 '왜'에 집중하기


이벤트 소싱은 '현재 상태'라는 좁은 시야에서 벗어나, "이 상태가 *어떻게* 만들어졌는가"라는 **'과정'과 '역사'**에 집중하는 패러다임입니다.

비록 대부분의 프론트엔드 앱이 Redux처럼 '현재 상태'를 SSoT로 사용하는 실용적인 '상태 지향' 모델을 택할지라도, 이벤트 소싱의 정신을 이해하는 것은 중요합니다.

- **명령(Command)**과 **이벤트(Event)**를 분리하십시오.
  - `dispatch(updateQuantity(5))`는 '명령'입니다.
  - 리듀서가 `QUANTITY_UPDATED` '이벤트'를 처리하는 것입니다.
- 상태 변경 로직을 **순수한 프로젝터(리듀서)**로 격리하십시오.
- 디버깅이 어렵다면, '현재 상태'만 보지 말고 '액션 로그(이벤트)'의 순서를 살펴보십시오.

이벤트 소싱이 '쓰기(Write)' 모델(이벤트 로그)과 '읽기(Read)' 모델(프로젝션된 상태)을 자연스럽게 분리한다는 점에 주목하십시오. 이는 다음 장에서 다룰 **CQRS (Command Query Responsibility Segregation)** 패턴의 완벽한 준비 단계가 됩니다.

------

네, 알겠습니다. 제3부의 다섯 번째 장, '시간 여행 디버깅과 Undo/Redo 구현' 집필을 시작하겠습니다. 바로 앞 10장에서 다룬 '이벤트 소싱'의 원리가 어떻게 프론트엔드 개발자의 가장 강력한 무기 중 두 가지로 이어지는지 상세히 탐구합니다.

------


## 11. 이벤트 소싱과 CQRS - 시간 여행 디버깅과 Undo/Redo 구현


> "과거를 지배하는 자가 미래를 지배하고, 현재를 지배하는 자가 과거를 지배한다. 이벤트 로그를 가진 개발자는 과거, 현재, 미래를 모두 지배한다."
>
> (조지 오웰의 '1984'를 각색)

제10장 '이벤트 소싱 구현'에서 우리는 시스템의 진실(SSoT)을 '현재 상태'가 아닌 '이벤트의 전체 로그'에 두는 혁신적인 패러다임을 배웠습니다. `State = f(Event1, Event2, ... EventN)`라는 이 공식은, 현재 상태가 단지 이벤트 로그를 '프로젝션(Projection)'한 결과임을 의미합니다.

이 설계는 단순한 아키텍처적 순수성을 넘어, 프론트엔드 개발자에게 두 가지 강력하고 실용적인 '초능력'을 선물합니다.

1. **시간 여행 디버깅 (Time Travel Debugging)**: 애플리케이션의 모든 상태 변경을 과거로 되돌려가며 재생(replay)하는 능력.
2. **Undo/Redo (실행 취소/다시 실행)**: 사용자를 위한 핵심 기능인 '실행 취소'를 거의 공짜로 구현하는 능력.

이 두 기능은 모두 "현재 상태는 이벤트 로그의 산물이다"라는 동일한 원리에서 파생됩니다. 본 장에서는 이 두 기능을 TypeScript로 구현하는 원리와 실용적인 패턴을 깊이 있게 탐구합니다.

------


### 11.1. 시간 여행 디버깅: 버그의 재구성


"대체 이 상태가 왜 이렇게 됐지?"

이것은 프론트엔드 개발자가 매일 마주하는 가장 고통스러운 질문입니다. 전통적인 디버깅(console.log(state))은 특정 시점의 '스냅샷'만 보여줄 뿐, 그 상태가 '어떻게' 만들어졌는지, 그 '역사'를 알려주지 않습니다.

**시간 여행 디버깅**은 이 문제를 정면으로 해결합니다. 이벤트 소싱(또는 Redux처럼 이벤트를 로깅하는) 아키텍처에서, 개발자는 다음과 같은 일을 할 수 있습니다.

1. 사용자가 앱에서 수행한 모든 액션(이벤트)의 로그를 확인합니다. (예: `['ADD_ITEM', 'ADD_ITEM', 'APPLY_COUPON']`)
2. 슬라이더를 움직여 특정 이벤트가 발생하기 '직전'의 상태로 애플리케이션 뷰를 되돌립니다.
3. '재생' 버튼을 눌러 이벤트가 순서대로 다시 발생하며 상태(및 UI)가 변경되는 과정을 프레임 단위로 관찰합니다.

버그가 발생한 지점(`'COUPON_INVALID'` 이벤트)을 찾았다면, 그 이벤트를 발생시킨 '명령(Command)'과 당시의 '상태(State)'를 정확히 알 수 있으므로 버그의 원인을 즉시 특정할 수 있습니다.


#### 11.1.1. 시간 여행은 어떻게 작동하는가?


Redux DevTools가 이 기능의 가장 유명한 예시입니다. 그 원리는 제10장의 '프로젝터(Projector)'와 정확히 일치합니다.

시간 여행 디버거는 본질적으로 다음과 같은 일을 합니다.

1. **이벤트 가로채기(Intercepting)**: 모든 이벤트(Redux에서는 '액션')가 발생할 때마다, 리듀서로 가기 전에 이 이벤트를 별도의 `eventLog: Event[]` 배열에 복사해 둡니다.
2. **현재 상태 계산**: `currentState = eventLog.reduce(reducer, initialState)`
3. **시간 여행 (특정 시점으로 이동)**: 사용자가 `N`번째 이벤트 시점으로 슬라이더를 옮기면, 디버거는 `eventLog.slice(0, N)` (처음부터 N번째 이벤트까지)를 가져옵니다.
4. **과거 상태 프로젝션**: `pastState = eventLog.slice(0, N).reduce(reducer, initialState)`
5. **UI 렌더링**: 이 `pastState`를 애플리케이션의 루트 컴포넌트에 강제로 주입하여 UI를 다시 렌더링합니다.

**[간단한 시간 여행 디버거의 원리 (TypeScript)]**

```typescript
// (제10장의 CartState, CartEvent, cartStateProjector 사용)
const eventLog: CartEvent[] = [];
const initialState: CartState = { items: {}, status: 'pending' };

// 디버거 UI가 호출할 함수
function timeTravelTo(eventIndex: number): CartState {
  // 1. 여행할 시점까지의 이벤트만 선택
  const logUntilThatTime = eventLog.slice(0, eventIndex + 1);

  // 2. 초기 상태부터 해당 시점까지 '재생' (프로젝션)
  console.log(`[디버거] ${eventIndex + 1}개 이벤트 재생 중...`);
  const stateAtThatTime = logUntilThatTime.reduce(
    cartStateProjector, // 우리의 순수 리듀서
    initialState
  );

  return stateAtThatTime;
}

// 애플리케이션 로직 (이벤트 발생)
function dispatch(event: CartEvent) {
  eventLog.push(event); // 1. 로그에 기록
  
  // 2. 현재 상태 계산 (실제 앱은 이 상태를 UI에 바인딩)
  const currentState = timeTravelTo(eventLog.length - 1);
  console.log('현재 상태:', currentState);
}

// --- 시뮬레이션 ---
dispatch({ type: 'CART_CREATED', ... });
dispatch({ type: 'ITEM_ADDED', payload: { itemId: 'a', ... }, ... });
dispatch({ type: 'ITEM_ADDED', payload: { itemId: 'b', ... }, ... });

// 3개 이벤트 발생 (index 0, 1, 2)
console.log('--- 시간 여행 시작 ---');

// 버그 분석: 'a' 아이템만 담겼을 때의 상태를 보자
const stateAtIndex1 = timeTravelTo(1); 
// [디버거] 2개 이벤트 재생 중...
console.log('Index 1의 상태:', stateAtIndex1); // { items: { 'a': ... }, ... }
```

**핵심 전제 조건**: 이 모든 것이 가능하려면 프로젝터(`cartStateProjector`, 리듀서)가 **100% 순수 함수**여야 하며, 상태는 **불변**해야 합니다. 동일한 이벤트 로그를 입력하면 언제나 동일한 상태가 출력됨이 보장되어야 합니다.

------


### 11.2. Undo / Redo: 사용자를 위한 시간 여행


시간 여행 디버깅이 '개발자'를 위한 기능이라면, Undo/Redo는 '사용자'를 위한 동일한 원리의 기능입니다. Figma, Google Docs, Notion 같은 현대적인 웹 앱에서 이 기능은 선택이 아닌 필수입니다.


#### 11.2.1. 왜 상태 지향 모델에서 Undo가 어려운가?


'현재 상태'만 저장하는 전통적인 방식(Event Sourcing이 아닌)에서 Undo는 끔찍하게 복잡합니다.

- **방법 1: 상태 스냅샷 스택 (고비용)**
  - 모든 상태 변경마다 `previousState`를 `undoStack: State[]`에 `push`합니다.
  - **Undo**: `currentState`를 `redoStack`에 `push`하고, `undoStack.pop()`을 `currentState`로 설정합니다.
  - **문제점**: 상태 객체가 거대하다면(예: Figma의 전체 캔버스 객체), `undoStack`은 엄청난 메모리를 소모합니다.
- **방법 2: 역연산(Inverse Operation) (고복잡성)**
  - `ITEM_ADDED`의 역연산(`ITEM_REMOVED`)을, `QUANTITY_UPDATED(5)`의 역연산(`QUANTITY_UPDATED(3)`)을 수동으로 계산해야 합니다.
  - 로직이 두 배로 복잡해지고, 버그가 발생하기 쉽습니다.


#### 11.2.2. 이벤트 로그를 이용한 Undo / Redo


이벤트 소싱(또는 로깅) 모델은 이 문제를 우아하게 해결합니다. 우리는 '상태' 스택 대신 '이벤트' 스택을 관리합니다.

`currentState`는 SSoT가 아닙니다. SSoT는 `pastEvents: Event[]`입니다.

- **`pastEvents: Event[]` (Undo 스택)**: 초기 상태부터 *현재*까지 발생한 이벤트 로그. (SSoT)
- **`futureEvents: Event[]` (Redo 스택)**: 사용자가 'Undo'하여 취소된 이벤트 로그.

**[Zustand 스토어에 Undo/Redo 시스템 구현하기]**

Zustand 같은 '상태 지향' 스토어에서도 '이벤트 로깅'을 흉내 내어 강력한 Undo/Redo 미들웨어를 만들 수 있습니다.

```typescript
import { create, StateCreator } from 'zustand';
import { produce } from 'immer';

// 1. 우리가 관리할 '현재 상태' (SSoT는 여전히 '상태'임)
interface CoreState {
  count: number;
}

// 2. 상태 변경을 기술하는 '이벤트' (Redux의 '액션'과 동일)
type CoreEvent = 
  | { type: 'INCREMENT'; payload: number }
  | { type: 'DECREMENT'; payload: number };

// 3. '현재 상태'를 계산하는 '프로젝터' (리듀서)
// 💥 이것이 상태 변경 로직의 유일한 SSoT
const coreReducer = (state: CoreState, event: CoreEvent): CoreState => {
  switch (event.type) {
    case 'INCREMENT':
      return { count: state.count + event.payload };
    case 'DECREMENT':
      return { count: state.count - event.payload };
    default:
      return state;
  }
};

// 4. Undo/Redo 기능을 추가하는 '미들웨어' 인터페이스
interface WithUndo {
  pastEvents: CoreEvent[];
  futureEvents: CoreEvent[];
  
  // '이벤트'를 SSoT(pastEvents)에 전달하는 유일한 방법
  dispatch: (event: CoreEvent) => void; 
  
  // 시스템: Undo
  undo: () => void;
  // 시스템: Redo
  redo: () => void;
  
  // 파생 상태: 현재 상태 (항상 로그로부터 계산됨)
  currentState: CoreState;
}

// 5. 초기 상태
const initialState: CoreState = { count: 0 };
const initialEventState = {
  pastEvents: [],
  futureEvents: [],
  currentState: initialState,
};

// 6. 스토어 생성
const useUndoStore = create<WithUndo>((set, get) => ({
  ...initialEventState,

  // 'dispatch' 시스템: 이벤트가 발생했을 때
  dispatch: (event: CoreEvent) => {
    const { pastEvents } = get();
    
    // 1. 새 이벤트를 '과거' 로그에 추가
    const newPastEvents = [...pastEvents, event];
    
    // 2. SSoT(pastEvents)로부터 '현재 상태'를 *재계산* (프로젝션)
    const newState = newPastEvents.reduce(coreReducer, initialState);
    
    // 3. 상태 업데이트 (Redo 스택은 비움)
    set({
      pastEvents: newPastEvents,
      currentState: newState,
      futureEvents: [], // 새로운 이벤트가 발생하면 Redo 기록은 사라짐
    });
  },

  // 'undo' 시스템: 실행 취소
  undo: () => {
    const { pastEvents, futureEvents } = get();
    if (pastEvents.length === 0) return; // Undo할 게 없음

    // 1. 마지막 이벤트를 '과거'에서 '미래(Redo)'로 이동
    const eventToUndo = pastEvents[pastEvents.length - 1];
    const newPastEvents = pastEvents.slice(0, pastEvents.length - 1);
    const newFutureEvents = [eventToUndo, ...futureEvents];

    // 2. '새로운 과거' 로그로부터 '현재 상태'를 *재계산*
    const newState = newPastEvents.reduce(coreReducer, initialState);
    
    // 3. 상태 업데이트
    set({
      pastEvents: newPastEvents,
      currentState: newState,
      futureEvents: newFutureEvents,
    });
  },

  // 'redo' 시스템: 다시 실행
  redo: () => {
    const { pastEvents, futureEvents } = get();
    if (futureEvents.length === 0) return; // Redo할 게 없음

    // 1. 첫 번째 Redo 이벤트를 '미래'에서 '과거'로 이동
    const eventToRedo = futureEvents[0];
    const newFutureEvents = futureEvents.slice(1);
    const newPastEvents = [...pastEvents, eventToRedo];

    // 2. '새로운 과거' 로그로부터 '현재 상태'를 *재계산*
    const newState = newPastEvents.reduce(coreReducer, initialState);
    
    // 3. 상태 업데이트
    set({
      pastEvents: newPastEvents,
      currentState: newState,
      futureEvents: newFutureEvents,
    });
  },
}));
```


#### 11.2.3. React 컴포넌트에서의 사용


React 컴포넌트는 이제 '로직'을 전혀 모릅니다. 그저 `dispatch`, `undo`, `redo` 시스템을 호출할 뿐입니다.

```typescript
function Counter() {
  // 👍 컴포넌트는 '현재 상태'와 '시스템'만 구독
  const currentState = useUndoStore(state => state.currentState);
  const dispatch = useUndoStore(state => state.dispatch);
  const undo = useUndoStore(state => state.undo);
  const redo = useUndoStore(state => state.redo);
  
  // 파생 상태 (Undo/Redo 가능 여부)
  const canUndo = useUndoStore(state => state.pastEvents.length > 0);
  const canRedo = useUndoStore(state => state.futureEvents.length > 0);

  return (
    <div>
      <h1>Count: {currentState.count}</h1>
      <button onClick={() => dispatch({ type: 'INCREMENT', payload: 1 })}>+1</button>
      <button onClick={() => dispatch({ type: 'DECREMENT', payload: 1 })}>-1</button>
      
      <button onClick={undo} disabled={!canUndo}>Undo</button>
      <button onClick={redo} disabled={!canRedo}>Redo</button>
    </div>
  );
}
```

이 접근 방식(이벤트 로그 전체 재계산)은 이벤트가 수만 개가 되면 성능 문제가 생길 수 있습니다 (제10장의 스냅샷 기법이 필요). 하지만 대부분의 프론트엔드 UI 상태(수백~수천 개 이벤트)에서는 차고 넘치도록 빠르며, 로직의 단순함이 주는 이점이 성능 비용을 압도합니다.

------


### 11.3. 결론: 이벤트는 기록이다


'시간 여행 디버깅'과 'Undo/Redo'는 별개의 기능이 아닙니다. 이 둘은 **"애플리케이션의 역사를 이벤트 로그로 취급한다"**는 동일한 설계 사상에서 나온 두 개의 다른 '뷰(View)'입니다.

- **시간 여행**: 개발자를 위한 '읽기 전용(Read-only)' 역사 뷰.
- **Undo/Redo**: 사용자를 위한 '수정 가능한(Writable)' 역사 뷰.

이벤트 소싱(또는 로깅)의 핵심은 **데이터의 '변경'을 '파괴적인 덮어쓰기'로 취급하지 않고, '측정 가능하고 되돌릴 수 있는 기록'으로 취급**하는 데 있습니다.

우리는 이제 '이벤트'를 통해 시스템의 '쓰기(Write)' 측면을 완벽하게 모델링했습니다. 하지만 '읽기(Read)'는 어떻습니까? 위 예제에서 `pastEvents.reduce`를 매번 실행하는 것은 비효율적입니다.

다음 장에서는 이 '쓰기(Command)'와 '읽기(Query)'의 책임을 명확하게 분리하여, 이벤트 소싱의 성능 문제를 해결하고 시스템을 극도로 최적화하는 **CQRS (Command Query Responsibility Segregation)** 패턴을 탐구합니다.

------

네, 알겠습니다. 제3부의 마지막 장이자 이벤트 소싱과 CQRS 섹션을 마무리하는 'Command와 Query의 분리' 집필을 시작하겠습니다. 이 장에서는 '쓰기'와 '읽기'의 책임을 분리하는 것이 왜 데이터 지향 아키텍처의 정점인지 탐구합니다.

------


## 12. 이벤트 소싱과 CQRS - Command와 Query의 분리


> "시스템에게 '상태를 변경하면서 동시에 데이터를 반환하라'고 요구하는 것은, 한 배우에게 무대 좌측에서 퇴장하면서 동시에 우측에서 등장하라고 요구하는 것과 같다. 최고의 성능과 명확성은 오직 책임을 분리할 때만 나온다."

우리는 지난 두 장(10, 11장)에서 이벤트 소싱(ES)이라는 강력한 '쓰기(Write)' 모델을 탐구했습니다. 모든 상태 변경을 '이벤트'로 기록함으로써, 시간 여행 디버깅과 Undo/Redo라는 놀라운 이점을 얻었습니다.

하지만 우리는 치명적인 트레이드오프에 직면했습니다. **SSoT가 이벤트 로그(Event Log)가 되자, '읽기(Read)'가 복잡하고 비싸졌습니다.**

`getCurrentState()`를 위해 매번 이벤트 로그 전체를 `reduce`하는 것은 이벤트가 수백 개만 되어도 비효율적입니다. 스냅샷(Snapshot) 기법으로 이를 완화할 순 있지만, '읽기' 작업이 여전히 '쓰기' 모델(이벤트 로그)에 종속되어 있다는 근본적인 문제는 해결되지 않습니다.

이 문제를 해결하기 위한 아키텍처 패턴이 바로 **CQRS (Command Query Responsibility Segregation, 명령 조회 책임 분리)**입니다.

CQRS는 단순하고도 강력한 하나의 원칙을 제시합니다.

"데이터를 변경하는 '명령(Command)'과 데이터를 조회하는 '조회(Query)'의 책임을 완전히 분리하라."

이는 '데이터와 로직의 분리'(1부)를 시스템 전체 아키텍처 레벨로 확장한 것입니다. '쓰기'를 위한 코드와 '읽기'를 위한 코드는 서로 다른 경로, 다른 모델, 심지어 다른 데이터베이스(프론트엔드에서는 '다른 스토어')를 사용해야 합니다.

본 장에서는 이벤트 소싱과 CQRS가 어떻게 완벽한 한 쌍을 이루어, 프론트엔드에서 '쓰기'의 무결성과 '읽기'의 성능을 모두 달성하는지 그 구체적인 구현을 탐구합니다.

------


### 12.1. CQRS의 두 세계: 명령과 조회


CQRS는 애플리케이션을 두 개의 독립적인 '스택(Stack)'으로 분리합니다.


#### 12.1.1. 명령(Command) 스택: 쓰기 전용


- **역할**: 시스템의 상태를 변경하는 모든 작업을 담당합니다.
- **흐름**: `UI` → `Command` → `Command Handler` → `Event(s)` → `Event Log (Write Model)`
- **특징**:
  - **명령 (Command)**: "무엇을 할지"에 대한 의도. (예: `CreateUserCommand`, `UpdateCartQuantityCommand`) **(주의: '명령형'임)**
  - **명령 핸들러 (Command Handler)**: 명령을 받아 비즈니스 로직(유효성 검사 등)을 수행하고, 성공하면 하나 이상의 '이벤트'를 생성합니다.
  - **쓰기 모델 (Write Model)**: SSoT. **이벤트 소싱(ES)에서는 이것이 바로 '이벤트 로그'**입니다. 이 모델은 오직 쓰기(append)에만 최적화됩니다.
  - **반환 값**: 이 스택은 **데이터를 반환하지 않습니다(No return value)**. 오직 '성공(void)' 또는 '실패(Error)'만 반환합니다.


#### 12.1.2. 조회(Query) 스택: 읽기 전용


- **역할**: UI에 필요한 데이터를 제공하는 모든 작업을 담당합니다.
- **흐름**: `UI` → `Query` → `Query Handler` → `Read Model` → `DTO (View Model)`
- **특징**:
  - **조회 (Query)**: "무엇을 원하는지"에 대한 요청. (예: `GetUserByIdQuery`, `GetCartViewModelQuery`)
  - **읽기 모델 (Read Model)**: **'읽기'에 극도로 최적화된** 데이터 저장소. 이것은 SSoT가 아닌 **'캐시(Cache)'**입니다. 제4장(정규화)에서 배운 '정규화된 상태'나, 아예 UI에 맞게 '비정규화된' 객체일 수 있습니다. (제6장 '파생 상태'와 유사)
  - **조회 핸들러 (Query Handler)**: 읽기 모델에서 데이터를 직접, 최대한 빠르고 멍청하게(Dumb) 읽어서 반환합니다.
  - **절대 금지**: 조회 스택은 **절대** 시스템의 상태를 변경해서는 안 됩니다. (예: 로깅조차 금지)

------


### 12.2. 이벤트 소싱(ES)과 CQRS의 결합


이제 마법이 일어나는 지점입니다. ES와 CQRS는 서로의 약점을 완벽하게 보완합니다.

- **ES의 문제**: 쓰기(이벤트 로그)는 완벽하지만, 읽기(프로젝션)가 비싸다.
- **CQRS의 문제**: 쓰기 모델과 읽기 모델이 분리되면, 이 둘을 **'어떻게 동기화할 것인가'**라는 문제가 생긴다.

**해결책: 이벤트 핸들러 (프로젝터)**

ES의 '프로젝터(Projector)'(제10장)가 바로 CQRS의 두 스택을 연결하는 '다리' 역할을 합니다.

1. **쓰기 (Command)**: `UpdateCartQuantityCommand`가 `CommandHandler`로 전송됩니다.
2. `CommandHandler`가 유효성을 검사한 뒤, `ITEM_QUANTITY_UPDATED` **이벤트**를 **'이벤트 로그(Write Model)'**에 저장합니다. (여기까지가 Command 스택)
3. **동기화 (Bridge)**: **'이벤트 핸들러(Event Handler)'** (즉, 프로젝터/리듀서)가 이 `ITEM_QUANTITY_UPDATED` 이벤트를 구독(listen)합니다.
4. `EventHandler`는 이 이벤트를 받아, **'읽기 모델(Read Model)'**의 상태를 그에 맞게 **업데이트(변환)**합니다. (예: `readModel.items['a'].quantity = 5`)
5. **읽기 (Query)**: UI 컴포넌트가 `GetCartViewModelQuery`를 전송합니다.
6. `QueryHandler`는 이미 최신 상태로 업데이트된 **'읽기 모델'**에서 데이터를 즉시($O(1)$) 읽어 UI에 반환합니다.

이 구조에서, 프론트엔드 UI는 더 이상 이벤트 로그를 `reduce`할 필요가 없습니다. UI는 그저 **'읽기 모델'만 구독**하면 됩니다. '읽기 모델'을 업데이트하는 비싼 비용(프로젝션)은 `EventHandler`에 의해 **백그라운드에서 비동기적(Asynchronous)**(또는 동기적)으로 처리됩니다.

------


### 12.3. 프론트엔드에서 CQRS 구현하기 (TypeScript)


제11장의 Undo/Redo 스토어를 '순수 CQRS + ES' 아키텍처로 리팩토링해 보겠습니다.

```typescript
import { create } from 'zustand';
import { produce } from 'immer';

// --- 1. 이벤트 (ES) ---
// (제11장과 동일)
type CoreEvent = 
  | { type: 'INCREMENT'; payload: number }
  | { type: 'DECREMENT'; payload: number };

// --- 2. 쓰기 모델 (Write Model) ---
// SSoT는 오직 이벤트 로그 뿐
interface WriteModel {
  eventLog: CoreEvent[];
  // (Undo/Redo를 위해 futureEvents도 포함)
  futureEvents: CoreEvent[];
}
const initialWriteModel: WriteModel = { eventLog: [], futureEvents: [] };

// --- 3. 읽기 모델 (Read Model) ---
// UI가 소비할, '읽기'에 최적화된 상태
interface ReadModel {
  count: number;
  canUndo: boolean;
  canRedo: boolean;
}
const initialReadModel: ReadModel = { count: 0, canUndo: false, canRedo: false };

// --- 4. 프로젝터 (ES -> Read Model Bridge) ---
// 💥 이벤트 로그 '전체'를 받아 '읽기 모델'을 계산하는 순수 함수
// (이것이 이벤트 핸들러의 핵심 로직)
function projector(log: CoreEvent[]): { count: number } {
  // 제11장 undo/redo 예제의 reduce 로직과 동일
  const coreState = log.reduce(coreReducer, { count: 0 }); // coreReducer는 +,- 로직
  return { count: coreState.count };
}


// --- 5. Zustand 스토어 (CQRS 구현체) ---
interface CqrsStore {
  // === 읽기 스택 (Query Side) ===
  readModel: ReadModel;
  
  // === 쓰기 스택 (Command Side) ===
  // (Undo/Redo를 위해 쓰기 모델도 스토어에 두지만, UI는 구독하지 않음)
  writeModel: WriteModel;
  
  // '명령 핸들러' (Command Handlers)
  dispatch: (event: CoreEvent) => void; // (간결함을 위해 Event를 Command로 간주)
  undo: () => void;
  redo: () => void;
}

const useCqrsStore = create<CqrsStore>((set, get) => ({
  readModel: initialReadModel,
  writeModel: initialWriteModel,
  
  // --- Command Handler: dispatch ---
  dispatch: (event: CoreEvent) => {
    // 1. (Write) '쓰기 모델(Event Log)' 업데이트
    const newWriteModel: WriteModel = {
      eventLog: [...get().writeModel.eventLog, event],
      futureEvents: [], // Redo 스택 초기화
    };

    // 2. (Bridge) '읽기 모델'을 *재계산* (프로젝션)
    const { count } = projector(newWriteModel.eventLog);
    const newReadModel: ReadModel = {
      count: count,
      canUndo: newWriteModel.eventLog.length > 0,
      canRedo: newWriteModel.futureEvents.length > 0,
    };

    // 3. (Commit) 두 모델을 동시에 set (동기식 CQRS)
    set({ writeModel: newWriteModel, readModel: newReadModel });
  },

  // --- Command Handler: undo ---
  undo: () => {
    const { eventLog, futureEvents } = get().writeModel;
    if (eventLog.length === 0) return;

    // 1. (Write) '쓰기 모델(Event Log)' 업데이트
    const eventToUndo = eventLog[eventLog.length - 1];
    const newWriteModel: WriteModel = {
      eventLog: eventLog.slice(0, eventLog.length - 1),
      futureEvents: [eventToUndo, ...futureEvents],
    };

    // 2. (Bridge) '읽기 모델'을 *재계산* (프로젝션)
    const { count } = projector(newWriteModel.eventLog);
    const newReadModel: ReadModel = {
      count: count,
      canUndo: newWriteModel.eventLog.length > 0,
      canRedo: newWriteModel.futureEvents.length > 0,
    };
    
    // 3. (Commit) 두 모델을 동시에 set
    set({ writeModel: newWriteModel, readModel: newReadModel });
  },
  
  // (redo 핸들러는 undo와 유사하게 구현...)
  redo: () => { ... }
}));
```


#### 12.3.1. React 컴포넌트: 오직 Query만 구독


이제 React 컴포넌트는 극도로 단순해집니다. `writeModel`의 존재 자체를 알 필요가 없습니다. 오직 `readModel`만 구독하고 `Command`만 호출합니다.

```typescript
function Counter() {
  // --- Query Side ---
  // 👍 UI는 '읽기 모델'만 구독 (매우 빠름)
  const readModel = useCqrsStore(state => state.readModel);
  
  // --- Command Side ---
  // 👍 UI는 '명령 핸들러'만 호출
  const dispatch = useCqrsStore(state => state.dispatch);
  const undo = useCqrsStore(state => state.undo);
  const redo = useCqrsStore(state => state.redo);

  return (
    <div>
      {/* 1. 읽기 모델에서 직접 데이터 바인딩 */}
      <h1>Count: {readModel.count}</h1>
      
      {/* 2. 명령 핸들러 호출 */}
      <button onClick={() => dispatch({ type: 'INCREMENT', payload: 1 })}>+1</button>
      <button onClick={() => dispatch({ type: 'DECREMENT', payload: 1 })}>-1</button>
      
      <button onClick={undo} disabled={!readModel.canUndo}>Undo</button>
      <button onClick={redo} disabled={!readModel.canRedo}>Redo</button>
    </div>
  );
}
```

이 `Counter` 컴포넌트는 `projector`가 얼마나 복잡한지, `eventLog`가 얼마나 긴지 전혀 신경 쓰지 않습니다. 그저 `readModel`이라는 최적화된 '파생 상태'를 읽을 뿐입니다.

------


### 12.4. CQRS가 프론트엔드에 주는 이점


1. **최고의 읽기 성능 (Performance)**: UI는 이벤트 로그를 `reduce`하는 비용을 절대 치르지 않습니다. `readModel`에서 $O(1)$로 상태를 조회합니다. 이는 제6장(파생 상태)에서 `reselect`로 달성하려던 목표의 궁극적인 형태입니다.
2. **관심사의 완벽한 분리 (SoC)**:
   - `CommandHandler` (쓰기 로직)
   - `Projector` (변환 로직)
   - `QueryHandler` (읽기 로직 - 위 예제에서는 `state => state.readModel`이 그 역할)
   - 이 셋은 물리적으로 분리되어 독립적으로 테스트하고 수정할 수 있습니다.
3. **유연한 읽기 모델 (Flexible Read Models)**:
   - 이것이 핵심입니다. **하나의 '이벤트 로그(Write Model)'**에서 **여러 개의 '읽기 모델'**을 파생시킬 수 있습니다.
   - `cartProjector` → `CartViewModel` (장바구니 UI용)
   - `analyticsProjector` → `AnalyticsModel` (GA 전송용)
   - `searchIndexProjector` → `SearchableItems` (검색 UI용)
   - '읽기'의 요구사항이 아무리 복잡해져도, '쓰기(SSoT)' 로직은 전혀 건드릴 필요가 없습니다.


### 12.5. 결론: 데이터 지향의 완성


'이벤트 소싱과 CQRS'는 제3부 '실전 아키텍처 패턴'을 마무리하는 완벽한 조합입니다.

- **ECS (7~9장)**는 `Entity + Component(Data) + System(Logic)`이라는 구조적 분리를 가르쳐 줬습니다.
- **ES (10~11장)**는 `System`의 '쓰기' 로직을 '이벤트'라는 불변의 기록으로 모델링하는 방법을 가르쳐 줬습니다.
- **CQRS (12장)**는 '쓰기(Command/Event)'와 '읽기(Query/ReadModel)'의 책임을 시스템 레벨에서 완전히 분리하여, ES의 성능 문제를 해결하고 '읽기'와 '쓰기'가 서로를 오염시키지 않는 견고한 아키텍처를 완성했습니다.

UI = f(ReadModel)

ReadModel = g(EventLog)

EventLog = h(Commands)

이것이 바로 데이터 지향 프로그래밍이 추구하는, 예측 가능하고, 테스트 가능하며, 성능이 최적화된 시스템의 청사진입니다.

------

네, 알겠습니다. 제4부 '성능 최적화'의 첫 번째 장을 시작하겠습니다. (목차상으로는 '스키마 기반 개발'이 제3부의 7번째 장(3-7)에 해당하지만, 요청하신 순서대로 '성능 최적화' 파트의 첫 번째 장으로 집필하겠습니다. 만약 '스키마 기반 개발' 파트(3-7, 3-8, 3-9)를 먼저 진행하길 원하시면 다시 말씀해 주세요.)

------


## 13. 메모리 효율적인 데이터 구조 (Struct of Arrays vs Array of Structs)


> "성능의 적은 추상화가 아니라 잘못된 데이터 레이아웃이다. 현대 CPU는 계산하는 시간보다 메모리에서 데이터를 기다리는 시간에 훨씬 더 많은 시간을 쓴다. 데이터를 CPU 친화적으로 배치하는 것이야말로 진정한 최적화의 시작이다."

지금까지 우리는 '아키텍처' 레벨에서 데이터 지향 프로그래밍을 탐구했습니다. 로직을 분리하고(1~3장), 상태를 정규화하며(4~6장), ECS와 CQRS 같은 패턴(7~12장)으로 시스템을 구조화했습니다. 이 모든 것은 코드의 **유지보수성, 테스트 용이성, 유연성**을 극대화하기 위함이었습니다.

이제 우리는 데이터 지향 프로그래밍의 또 다른 얼굴, 즉 **'성능(Performance)'**에 대해 이야기할 시간입니다.

데이터 지향 프로그래밍은 원래 고성능 게임 개발과 과학 컴퓨팅 분야에서 태동했습니다. 이 분야의 핵심은 **"CPU 캐시를 어떻게 최대한 활용할 것인가?"**입니다. 현대의 프론트엔드, 특히 차트, 그래프, 3D 렌더링(Three.js), 대규모 데이터 그리드, 실시간 협업 도구(Figma)를 다루는 애플리케이션 역시 동일한 성능 병목에 부딪힙니다.

이 병목을 해결하는 첫걸음은 우리가 데이터를 메모리에 '어떻게' 배치하는지 이해하는 것입니다. 본 장에서는 프론트엔드 개발자에게는 생소하지만, 고성능 컴퓨팅의 기본인 **Struct of Arrays (SoA)**와 **Array of Structs (AoS)**라는 두 가지 데이터 레이아웃을 비교 분석합니다.

------


### 13.1. 우리에게 익숙한 방식: Array of Structs (AoS)


AoS(Array of Structs, 구조체 배열)는 객체 지향 프로그래밍과 프론트엔드 개발자에게 가장 직관적이고 익숙한 방식입니다. '관련된 데이터는 하나로 묶는다(캡슐화)'는 원칙을 따릅니다.

1000명의 파티클(Particle) 데이터를 관리한다고 가정해 봅시다.

```typescript
// (Struct: 구조체, TypeScript에서는 '객체')
interface Particle {
  id: number;
  position: { x: number; y: number };
  velocity: { dx: number; dy: number };
  color: { r: number; g: number; b: number; a: number };
  life: number;
}

// 💥 Array of Structs (AoS)
const particles: Particle[] = [
  // Particle 0
  {
    id: 0,
    position: { x: 10, y: 20 },
    velocity: { dx: 1, dy: 0 },
    color: { r: 255, g: 0, b: 0, a: 1 },
    life: 100
  },
  // Particle 1
  {
    id: 1,
    position: { x: 30, y: 50 },
    velocity: { dx: 0, dy: -1 },
    color: { r: 0, g: 255, b: 0, a: 1 },
    life: 80
  },
  // ... 998개 더
];
```

AoS의 메모리 레이아웃 (추상적):

메모리에는 Particle 0의 모든 데이터(position, velocity, color, life)가 연달아 배치되고, 그 다음에 Particle 1의 모든 데이터가 배치됩니다.

```text
[P0_pos, P0_vel, P0_col, P0_life] [P1_pos, P1_vel, P1_col, P1_life] [...]
```


#### 13.1.1. AoS의 문제점: 캐시 미스 (Cache Miss)


AoS는 '하나의 파티클'을 통째로 다룰 때는 훌륭합니다. (예: particles[5])

하지만 '모든 파티클의 특정 속성'을 순회할 때는 재앙적인 성능을 보입니다.

**요구사항**: "1000개 파티클의 `position`을 `velocity`에 따라 업데이트하라." (제7장 ECS의 `MovementSystem`과 동일)

```typescript
// AoS 방식의 'MovementSystem'
function movementSystemAoS(particles: Particle[]): void {
  for (let i = 0; i < particles.length; i++) {
    const p = particles[i];
    
    // 1. p.position 데이터 접근
    p.position.x += p.velocity.dx;
    p.position.y += p.velocity.dy;
    
    // 2. p.life 데이터 접근 (예시)
    p.life -= 1;
  }
}
```

이 코드는 단순해 보이지만, CPU 입장에서는 매우 비효율적입니다.

1. 루프가 `i = 0`일 때, CPU는 `particles[0]`의 데이터를 메모리에서 읽어옵니다. `P0`의 모든 데이터(`pos`, `vel`, `col`, `life`)가 CPU 캐시(작고 빠른 메모리)에 올라옵니다.
2. 코드는 `p.position`과 `p.velocity`, `p.life`만 사용합니다. **`p.color` 데이터는 사용되지 않았지만 캐시 공간만 차지했습니다.** (낭비)
3. 루프가 `i = 1`이 되면, CPU는 `particles[1]`의 데이터를 메모리에서 읽어와야 합니다.
4. 만약 `Particle` 객체 하나가 캐시 라인(예: 64바이트)보다 크다면, 매 루프마다 **캐시 미스(Cache Miss)**가 발생할 확률이 높습니다. 캐시 미스는 CPU가 메인 메모리(RAM)에서 데이터를 가져올 때까지 수백 사이클을 '대기(Stall)'해야 함을 의미합니다.

이 시스템은 '움직임'과 '수명'만 관심 있는데도, `color`를 비롯한 **관심 없는 데이터**까지 메모리에서 함께 끌고 와야 합니다. 데이터가 '캡슐화'되어 있어 분리할 수 없기 때문입니다.

------


### 13.2. 데이터 지향적 방식: Struct of Arrays (SoA)


SoA(Struct of Arrays, 배열의 구조체)는 이 문제를 정면으로 해결합니다. 이 방식은 제7장(ECS)의 데이터 모델과 정확히 일치합니다.

"관련된 데이터를 묶지 말고, **'같은 타입'의 데이터를 묶어라.**"

```typescript
// 💥 Struct of Arrays (SoA)
// (ECS의 'Component Storage'와 동일)
interface ParticleWorld {
  // 각 속성을 '배열'로 관리
  // 이 'Struct'는 배열들로 이루어짐
  
  // (id는 배열의 index로 대체 가능)
  positions: { x: number; y: number }[]; // 1000개
  velocities: { dx: number; dy: number }[]; // 1000개
  colors: { r: number; g: number; b: number; a: number }[]; // 1000개
  lives: number[]; // 1000개
  count: number;
}

const particleWorld: ParticleWorld = {
  positions: [
    { x: 10, y: 20 }, { x: 30, y: 50 }, // ...
  ],
  velocities: [
    { dx: 1, dy: 0 }, { dx: 0, dy: -1 }, // ...
  ],
  colors: [
    { r: 255, g: 0, b: 0, a: 1 }, { r: 0, g: 255, b: 0, a: 1 }, // ...
  ],
  lives: [
    100, 80, // ...
  ],
  count: 1000,
};
```

SoA의 메모리 레이아웃 (추상적):

positions 배열의 모든 데이터(P0_pos, P1_pos, ...)가 메모리상에 연속적으로(contiguously) 배치됩니다. velocities 배열도 마찬가지입니다.

[P0_pos, P1_pos, P2_pos, ...]

[P0_vel, P1_vel, P2_vel, ...]

[P0_col, P1_col, P2_col, ...]

[P0_life, P1_life, P2_life, ...]


#### 13.2.1. SoA의 압도적인 이점: 캐시 히트 (Cache Hit)


이제 'MovementSystem'을 SoA 방식으로 다시 작성해 봅시다.

```typescript
// SoA 방식의 'MovementSystem'
function movementSystemSoA(world: ParticleWorld): void {
  // 시스템이 '관심 있는' 데이터 배열만 가져옴
  const positions = world.positions;
  const velocities = world.velocities;
  const lives = world.lives;
  
  // 💥 이 루프는 'colors' 배열을 절대 건드리지 않음
  for (let i = 0; i < world.count; i++) {
    // 1. position 데이터 접근
    positions[i].x += velocities[i].dx;
    positions[i].y += velocities[i].dy;
    
    // 2. life 데이터 접근
    lives[i] -= 1;
  }
}
```

이 코드가 CPU에서 실행될 때 일어나는 일입니다.

1. CPU가 `positions[0]`을 읽습니다. 메인 메모리에서 `positions` 배열의 시작 부분을 캐시로 가져옵니다. 이때 `positions[1]`, `positions[2]`, `positions[3]` 등 **앞으로 사용될 데이터**가 캐시 라인에 함께 딸려옵니다. (이를 **'프리페칭(Prefetching)'**이라고 합니다.)
2. 루프가 `i = 1`일 때, `positions[1]` 데이터는 **이미 CPU 캐시에 존재할 확률이 매우 높습니다.** (→ **캐시 히트!**)
3. `velocities` 배열과 `lives` 배열도 마찬가지입니다.
4. CPU는 메인 메모리를 기다리며 '대기'하는 시간 없이, 캐시에서 데이터를 즉시 가져와 계산을 맹렬하게(hot path) 수행할 수 있습니다.
5. 가장 중요한 것은, 이 시스템과 **전혀 상관없는 `colors` 배열 데이터는 메모리에서 읽히지도, 캐시를 오염시키지도 않는다**는 것입니다.

이것이 바로 제7장 ECS 아키텍처가 게임에서 압도적인 성능을 내는 이유입니다. `MovementSystem`은 `positions`와 `velocities` 배열(Component Storage)만 순회하고, `RenderSystem`은 `positions`와 `colors` 배열만 순회합니다. 관심사가 분리되자 데이터 접근도 분리되어 캐시 효율이 극대화됩니다.

------


### 13.3. JavaScript/TypeScript에서의 한계와 실용적 접근


"잠깐, JavaScript는 메모리를 직접 제어할 수 없는데 이게 의미가 있나요?"

의미 있습니다. V8(Chrome), SpiderMonkey(Firefox) 같은 JavaScript 엔진은 우리가 AoS와 SoA 중 어떤 패턴을 사용하는지 '인지'하고 최적화를 시도합니다.

- **히든 클래스(Hidden Classes)**: V8 엔진은 AoS 패턴(`Particle[]`)을 만나면, `Particle` 객체들이 동일한 '모양(shape)'을 가졌다고 판단하고 내부적으로 최적화합니다.
- **배열 최적화**: 엔진은 `number[]` 같은 '단순한' 배열을 `Object[]`보다 훨씬 효율적으로 처리합니다. SoA의 `lives: number[]`는 `Particle[]`의 `p.life`에 접근하는 것보다 빠릅니다.

하지만 JavaScript 객체(`{}`)는 여전히 메모리 오버헤드가 있습니다. 진정한 SoA 성능을 내려면 **타입이 지정된 배열 (Typed Arrays)**을 사용해야 합니다.


#### 13.3.1. 극단적 SoA: `ArrayBuffer`와 `TypedArray`


최고의 성능이 필요한 경우(예: Three.js의 지오메트리, WebGL), 객체를 완전히 제거하고 `ArrayBuffer`라는 거대한 메모리 블록 위에 데이터를 직접 씁니다.

```typescript
// 1000개 파티클을 위한 메모리 할당
const PARTICLE_COUNT = 1000;

// Particle 1개의 데이터 구조 정의 (Struct)
// position (x, y) = 2 * 4바이트 (float32)
// velocity (dx, dy) = 2 * 4바이트 (float32)
// color (r, g, b, a) = 4 * 1바이트 (uint8)
// life = 1 * 4바이트 (float32)
// 총 = 8 + 8 + 4 + 4 = 24바이트

// 1. AoS 방식의 TypedArray (비효율적)
// [P0_pos, P0_vel, P0_col, P0_life] [P1_pos, P1_vel, ...]
const bufferAoS = new ArrayBuffer(PARTICLE_COUNT * 24);

// 2. SoA 방식의 TypedArray (매우 효율적)
// [P0_pos, P1_pos, ...] [P0_vel, P1_vel, ...]
const bufferSoA = {
  positions: new Float32Array(PARTICLE_COUNT * 2), // [x0, y0, x1, y1, ...]
  velocities: new Float32Array(PARTICLE_COUNT * 2), // [dx0, dy0, dx1, dy1, ...]
  colors: new Uint8Array(PARTICLE_COUNT * 4),       // [r0, g0, b0, a0, ...]
  lives: new Float32Array(PARTICLE_COUNT),          // [life0, life1, ...]
};

// SoA 방식의 시스템 (매우 빠름)
function movementSystemSoA_Typed(world: typeof bufferSoA): void {
  const positions = world.positions;
  const velocities = world.velocities;
  const lives = world.lives;
  
  for (let i = 0; i < PARTICLE_COUNT; i++) {
    const i2 = i * 2; // (x, y) 인덱스
    
    // 객체 생성 오버헤드 '제로'
    positions[i2]   += velocities[i2];   // x
    positions[i2+1] += velocities[i2+1]; // y
    
    lives[i] -= 1;
  }
}
```

이 `movementSystemSoA_Typed` 함수는 JavaScript가 낼 수 있는 거의 C에 가까운 성능을 보여줍니다. `colors` 데이터는 전혀 건드리지 않으며, 모든 데이터는 연속된 메모리 블록(TypedArray)에서 직접 처리됩니다.

------


### 13.4. 결론: 언제 무엇을 써야 하는가?


모든 것을 SoA로 바꿀 필요는 없습니다. 패턴에는 트레이드오프가 따릅니다.

- **Array of Structs (AoS)** (예: `User[]`)
  - **장점**:
    - 직관적이고 코드가 단순합니다. (OOP)
    - '하나의 객체'를 통째로 다룰 때(예: `user.name`, `user.email`을 모두 보여주는 `UserProfile` 컴포넌트) 매우 효율적입니다.
  - **단점**:
    - '여러 객체'의 '특정 속성'만 순회할 때(예: `MovementSystem`) 캐시 효율이 나쁩니다.
  - **적합한 곳**: 대부분의 CRUD 애플리케이션, UI 상태, 엔티티 수가 적은 경우.
- **Struct of Arrays (SoA)** (예: `ECS World`)
  - **장점**:
    - '여러 객체'의 '특정 속성'만 순회하는 시스템(로직)에서 캐시 효율이 극대화됩니다.
    - 데이터 추가/제거 시 '하나의 객체'를 다루는 대신 '각 배열'을 수정해야 하므로 코드 복잡성이 증가합니다. (예: `world.positions.push(...)`, `world.velocities.push(...)` 등)
  - **단점**:
    - '하나의 객체'를 통째로 가져오는 작업(예: `Particle 5`의 모든 속성)이 더 번거롭습니다. (`world.positions[5]`, `world.velocities[5]`... 따로 접근)
  - **적합한 곳**: 대규모 데이터 처리, 실시간 시뮬레이션(게임, 물리), 차트/시각화, WebGL, ECS 아키텍처.

데이터 지향 프로그래밍은 개발자에게 "이 로직이 어떤 데이터에 접근하는가?"를 질문하게 만듭니다. 만약 로직이 데이터의 일부(예: `position`, `velocity`)만 반복적으로 순회한다면, AoS는 잘못된 선택일 수 있습니다. 데이터를 로직에 맞게 **SoA**로 재배치하는 것을 고려해야 합니다.

------

네, 알겠습니다. 제4부 '성능 최적화'의 두 번째 장, '데이터 지역성(Data Locality)' 집필을 시작하겠습니다. 이 장에서는 13장에서 배운 SoA/AoS가 왜 성능에 영향을 미치는지, 그 근본 원리인 CPU 캐시와 메모리 모델을 탐구합니다.

------


## 14. 데이터 지역성(Data Locality)


> "가장 빠른 코드는 아무것도 하지 않는 코드이다. 두 번째로 빠른 코드는 메모리에서 데이터를 기다리지 않는 코드이다. 당신의 JavaScript 코드는 CPU를 기다리는 것이 아니라, CPU가 데이터를 기다리고 있다."

제13장 '메모리 효율적인 데이터 구조'에서 우리는 Struct of Arrays (SoA)가 Array of Structs (AoS)보다 특정 순회 작업에서 훨씬 빠를 수 있음을 확인했습니다. 그 이유는 바로 **'데이터 지역성(Data Locality)'** 때문입니다.

데이터 지역성은 "CPU가 데이터에 접근하는 패턴"과 "메모리 시스템이 데이터를 공급하는 방식" 사이의 관계를 설명하는 컴퓨터 과학의 근본 원리입니다. 현대 CPU는 계산 속도(Clock)가 메모리 접근 속도(RAM)보다 수백, 수천 배 빠릅니다. 1초에 수십억 번의 덧셈을 할 수 있는 CPU도, 저 멀리 있는 RAM에서 데이터를 가져오는 데는 수백 번의 덧셈을 할 수 있는 시간을 '대기(Stall)'하며 허비합니다.

이 '대기 시간'을 숨기기 위해 CPU는 **캐시(Cache)**라는 작고 비싸고 극도로 빠른 메모리를 내부에 가지고 있습니다.

데이터 지역성은 이 CPU 캐시를 얼마나 잘 활용하느냐에 대한 척도입니다.

JavaScript는 C++처럼 메모리 주소를 직접 제어할 순 없지만, 우리가 작성하는 코드의 '데이터 접근 패턴'은 V8 엔진과 CPU가 캐시를 효율적으로(또는 비효율적으로) 사용하도록 '유도'합니다.

본 장에서는 이 캐시 시스템이 어떻게 작동하는지, 그리고 '핫 패스'와 '배열 순회 패턴'이 캐시 효율성에(즉, 성능에) 어떻게 치명적인 영향을 미치는지 깊이 있게 탐구합니다.

------


### 14.1. 브라우저 메모리 모델 이해하기


우리가 `let a = { x: 1 }`을 선언할 때, 이 데이터는 브라우저(JavaScript 엔진)에 의해 관리되는 메모리 공간(RAM) 어딘가에 할당됩니다. CPU가 이 `a.x` 값을 읽어야 할 때, 다음과 같은 메모리 계층 구조를 거칩니다.

1. **CPU Registers**: 가장 빠름. (즉시 접근)
2. **L1 Cache (L1 캐시)**: 극도로 빠름, 극도로 작음 (예: 64KB). CPU 코어 바로 옆.
3. **L2 Cache (L2 캐시)**: 매우 빠름, 작음 (예: 256KB).
4. **L3 Cache (L3 캐시)**: 빠름, 중간 크기 (예: 8MB). 여러 코어가 공유.
5. **Main Memory (RAM)**: 느림, 매우 큼 (예: 16GB).
6. **Disk (SSD/HDD)**: 매우 느림.

CPU가 `a.x`를 필요로 할 때, L1 캐시를 먼저 확인합니다. 없으면 L2, L3를 확인하고, 거기에도 없으면(이를 **'캐시 미스(Cache Miss)'**라고 함) RAM까지 가서 데이터를 가져와야 합니다. 이 RAM까지의 여정은 L1 캐시 접근보다 100배 이상 느릴 수 있습니다.


#### 14.1.1. 캐시 라인 (Cache Line)


핵심은, CPU가 RAM에서 데이터를 가져올 때 `a.x`(예: 4바이트) 하나만 가져오지 않는다는 것입니다. CPU는 **'캐시 라인(Cache Line)'**이라는 고정된 크기(예: 64바이트)의 '덩어리' 단위로 데이터를 한꺼번에 가져옵니다.

즉, `a.x`를 요청했더라도, `a.x`를 포함한 64바이트의 연속된 메모리 데이터가 통째로 L1 캐시에 적재됩니다.


#### 14.1.2. 두 가지 지역성 원칙


CPU는 이 캐시 라인 시스템을 기반으로 "앞으로 필요할 데이터"를 '예측(Prefetching)'합니다. 이 예측의 근거가 되는 것이 두 가지 지역성 원칙입니다.

1. **시간적 지역성 (Temporal Locality)**
   - "방금 접근한 데이터는 가까운 미래에 다시 접근될 가능성이 높다."
   - **예시**: 루프 안에서 사용되는 변수 (`for (let i = 0... ) { sum += i; }`의 `sum`과 `i`)
   - 캐시는 방금 사용된 데이터를 버리지 않고 최대한 붙잡아 둡니다.
2. **공간적 지역성 (Spatial Locality)**
   - "방금 접근한 데이터의 '주변'에 있는 데이터는 가까운 미래에 접근될 가능성이 높다."
   - **예시**: 배열 순회 (`array[i]`에 접근한 직후 `array[i+1]`에 접근)
   - 이것이 '캐시 라인'이 존재하는 이유입니다. `array[i]`를 가져올 때, 캐시 라인에 `array[i+1]`, `array[i+2]`...가 함께 딸려오길 기대합니다. `array[i+1]`에 접근할 때는 이미 캐시에 있으므로(**캐시 히트!**) RAM까지 갈 필요가 없어집니다.

제13장의 SoA(`positions[i]`, `positions[i+1]`)는 이 **공간적 지역성**을 극대화하는 패턴입니다. 반면 AoS(`particles[i].pos`, `particles[i+1].pos`)는 `pos`와 `pos` 사이에 관련 없는 `color`, `life` 데이터가 끼어있어(interleaved) 공간적 지역성을 파괴합니다.

------


### 14.2. 핫 패스(hot path) 최적화


**'핫 패스(Hot Path)'**는 애플리케이션의 성능에 가장 큰 영향을 미치는, 즉 **가장 자주 실행되는 코드 경로**를 의미합니다.

- React의 `render` 함수 내부 로직
- 매 프레임 실행되는 애니메이션/물리 루프 (`requestAnimationFrame`)
- 수천 개의 데이터를 순회하는 `for` 루프
- 실시간 이벤트 핸들러 (`onMouseMove`, `onScroll`)

애플리케이션 성능의 90%는 이 10%의 '핫 패스' 코드에서 결정됩니다. 데이터 지역성 최적화는 다른 곳이 아닌 바로 이 '핫 패스'에 집중되어야 합니다.

**핫 패스를 최적화한다는 것은, 핫 패스 내부에서 접근하는 데이터가 CPU 캐시에 '핫(Hot)'하게 유지되도록 데이터 구조를 설계한다는 의미입니다.**


#### 14.2.1. 핫 패스에서의 OOP(다형성)의 함정


객체 지향의 다형성(Polymorphism)은 코드의 유연성을 높이지만, 핫 패스에서는 캐시 성능에 재앙이 될 수 있습니다.

```typescript
// 👎 핫 패스에서 다형성을 사용하는 나쁜 예
interface Shape {
  draw(): void;
  // 각자 다른 데이터를 가짐
}
class Circle implements Shape {
  radius: number;
  position: { x: number; y: number };
  draw() { /* 원을 그리는 로직 (radius, position 접근) */ }
}
class Square implements Shape {
  width: number;
  position: { x: number; y: number };
  draw() { /* 사각형을 그리는 로직 (width, position 접근) */ }
}

const shapes: Shape[] = [new Circle(), new Square(), new Circle(), ...];

// 핫 패스 (매 프레임 렌더링)
function renderLoop(shapes: Shape[]) {
  // 💥 이 루프는 캐시에 최악이다.
  for (const shape of shapes) {
    shape.draw(); 
  }
}
```

이 `renderLoop`가 왜 나쁠까요?

1. **데이터 지역성 파괴**: `shapes` 배열에는 `Circle` 객체(메모리A)와 `Square` 객체(메모리B)가 섞여 있습니다. `Circle`의 데이터(`radius`)와 `Square`의 데이터(`width`)는 메모리상에 흩어져 있습니다.
2. **분기 예측 실패 (Branch Misprediction)**: CPU는 `shape.draw()`를 만날 때마다, 이 `shape`이 `Circle`인지 `Square`인지 확인해야 합니다. 이 'if'문(분기)은 예측이 불가능하므로 CPU 파이프라인이 중단되고 '대기' 상태에 빠집니다.
3. **캐시 오염**: `Circle`을 그리기 위해 `radius`를 캐시에 올렸는데, 다음 루프는 `Square`이므로 `width`를 캐시에 새로 올려야 합니다. 캐시가 계속 '물갈이'됩니다.


#### 14.2.2. 핫 패스 최적화 (데이터 지향적 접근)


이 문제를 해결하려면 제13장의 SoA/ECS 원칙을 적용하여 **데이터를 타입별로 분리**해야 합니다.

```typescript
// 👍 핫 패스를 위한 데이터 지향적 구조 (SoA)
interface RenderWorld {
  circles: {
    positions: { x: number; y: number }[];
    radii: number[];
  };
  squares: {
    positions: { x: number; y: number }[];
    widths: number[];
  };
}

// 핫 패스 (매 프레임 렌더링)
function renderLoopSoA(world: RenderWorld) {
  
  // 1. '원 그리기' 핫 패스
  // 💥 데이터(positions, radii)가 연속적이므로 캐시 히트율 극대화
  // 💥 분기 예측 실패 없음. '원 그리기' 로직만 계속 실행
  const circlePositions = world.circles.positions;
  const radii = world.circles.radii;
  for (let i = 0; i < radii.length; i++) {
    drawCircle(circlePositions[i], radii[i]);
  }

  // 2. '사각형 그리기' 핫 패스
  // 💥 데이터(positions, widths)가 연속적이므로 캐시 히트율 극대화
  const squarePositions = world.squares.positions;
  const widths = world.squares.widths;
  for (let i = 0; i < widths.length; i++) {
    drawSquare(squarePositions[i], widths[i]);
  }
}
```

이 코드는 OOP 방식보다 '못생겨' 보일 수 있지만, `renderLoop` 핫 패스에서 실행될 때 수십 배 더 빠를 수 있습니다. CPU가 좋아하는 **예측 가능하고 선형적인(Linear) 데이터 접근**을 제공하기 때문입니다.

------


### 14.3. 배열 순회 패턴과 성능


핫 패스는 결국 '루프(Loop)'이며, 이 루프를 '어떻게' 도느냐가 캐시 효율을 결정합니다.


#### 14.3.1. 선형 순회 (Linear Traversal) - Good


```typescript
// 👍 공간적 지역성의 왕
const data = [1, 2, 3, ... 1_000_000];
let sum = 0;
for (let i = 0; i < data.length; i++) {
  sum += data[i]; // data[0], data[1], data[2]...
}
```

CPU의 '프리페처(Prefetcher)'가 가장 사랑하는 패턴입니다. `data[i]`를 읽을 때 `data[i+1]`... `data[i+16]`(예시)까지 캐시 라인에 미리 적재합니다. 다음 15번의 루프는 RAM 접근 없이 캐시에서 즉시 데이터를 가져옵니다.


#### 14.3.2. 임의 접근 (Random Access) - Bad


```typescript
// 👎 캐시 미스의 지옥
const data: Record<string, number> = { 'a': 1, 'b': 2, ... }; // 메모리에 흩어짐
const keys = ['z', 'a', 'x', 'c', ...]; // 순서가 무작위
let sum = 0;
for (const key of keys) {
  sum += data[key]; // data['z'] -> data['a'] -> data['x']
}
```

JavaScript의 `Object`나 `Map`의 데이터는 메모리상에 연속적으로 저장된다는 보장이 없습니다. `keys` 배열을 순회하며 `data[key]`에 접근하는 것은 메모리 맵 곳곳을 '점프'하며 다니는 것과 같습니다. 매 접근마다 캐시 미스가 발생할 확률이 높습니다.

> **교훈**: 핫 패스에서는 `Object`나 `Map`을 순회하며 데이터를 읽는 것을 피하고, **데이터를 `Array` 또는 `TypedArray`로 변환**하여 선형 순회해야 합니다. (제13장의 SoA)


#### 14.3.3. JavaScript `forEach` vs. `for`


`Array.prototype.forEach`는 함수형 프로그래밍에서 선호되는 방식이며 가독성이 좋습니다.

```typescript
data.forEach(value => {
  sum += value;
});
```

하지만 `forEach`는 본질적으로 **콜백 함수 호출**입니다. 극도로 민감한 핫 패스(예: 초당 60번 실행되는 루프)에서는 이 함수 호출 오버헤드와 컨텍스트 스위칭이 미미한 성능 저하를 유발할 수 있습니다.

V8 엔진은 최신 버전에서 `forEach`를 `for` 루프 수준으로 최적화하려 노력하지만, 가장 '안전하고' 예측 가능한 성능을 보장하는 것은 여전히 고전적인 `for` 루프입니다.

```typescript
// 핫 패스에서는 이것이 가장 안전하다
for (let i = 0, len = data.length; i < len; i++) {
  sum += data[i];
}
```

(단, 이는 극단적인 최적화이며, 대부분의 UI 로직에서는 `forEach`의 가독성이 주는 이점이 더 큽니다. 벤치마크를 통해 병목 지점을 정확히 식별한 후에만 `for` 루프로 변경하십시오.)

------


### 14.4. 결론: CPU 캐시를 친구로 만들기


데이터 지역성은 "JavaScript 개발자는 메모리 관리를 안 해도 된다"라는 통념에 정면으로 반박합니다. 우리는 메모리 주소를 제어할 순 없지만, V8 엔진과 CPU가 최상의 성능을 내도록 **데이터의 '구조'와 '접근 패턴'을 설계**할 책임이 있습니다.

1. **데이터 구조 (Data Structure)**: 핫 패스에서 순회할 데이터는 AoS(객체 배열)가 아닌 **SoA(데이터 속성별 배열)** 또는 `TypedArray`로 구성하여 **공간적 지역성**을 극대화합니다.
2. **데이터 접근 (Data Access)**: 핫 패스의 루프는 다형성이나 임의 접근을 피하고, 단순하며 **선형적인(Linear) 순회**를 사용해야 합니다.

캐시 미스는 프로그램에서 가장 비싼 작업 중 하나입니다. 데이터 지향 프로그래밍은 이 캐시 미스를 피하기 위해 데이터를 로직에 맞게 '재배치'하는 기술입니다.

------

네, 알겠습니다. 제4부 '성능 최적화'의 세 번째 장, '캐시 친화적인 데이터 레이아웃' 집필을 시작하겠습니다. 이 장은 13장(SoA/AoS)과 14장(데이터 지역성)에서 배운 원칙을 실제 데이터 구조 설계에 적용하는 구체적인 실천 기법들을 다룹니다.

------


## 15. 캐시 친화적인 데이터 레이아웃 설계


> "데이터를 어떻게 '저장'할지 결정하는 것은 데이터를 어떻게 '사용'할지 아는 것에서부터 시작된다. 캐시 친화적인 설계란, 로직(System)이 필요로 하는 데이터를 정확히, 연속적으로, 그리고 잡음 없이 메모리상에 '진열'하는 기술이다."

제13장과 14장에서 우리는 성능의 핵심이 CPU와 메모리 간의 속도 차이를 메우는 '캐시(Cache)'에 있으며, '데이터 지역성'(특히 공간적 지역성)이 캐시 히트율을 높이는 열쇠임을 배웠습니다. SoA(Struct of Arrays)는 AoS(Array of Structs)보다 '핫 패스' 순회에 유리한, 캐시 친화적인 데이터 레이아웃의 한 예시였습니다.

하지만 캐시 친화적인 설계는 단순히 SoA를 적용하는 것에서 그치지 않습니다. 이는 우리의 **'데이터 접근 패턴(Data Access Pattern)'**을 분석하고, 그 패턴에 맞게 데이터 구조를 의도적으로 재배치하는 모든 과정을 포함합니다.

본 장에서는 '핫/콜드 데이터 분리'와 같은 실용적인 레이아웃 설계 기법을 통해, JavaScript라는 추상화된 환경 속에서도 어떻게 하면 V8 엔진과 CPU가 최대의 성능을 내도록 '유도'할 수 있는지 구체적인 전략을 탐구합니다.

------


### 15.1. 캐시 효율을 떨어뜨리는 주범: 관련 없는 데이터의 간섭


제13장의 AoS 예시를 다시 떠올려 봅시다.

```typescript
// 👎 Array of Structs (AoS)
interface Particle {
  position: { x: number; y: number }; // 핫(Hot) 데이터
  velocity: { dx: number; dy: number }; // 핫(Hot) 데이터
  color: { r: number; g: number; b: number; a: number }; // 콜드(Cold) 데이터
  life: number; // 핫(Hot) 데이터
  name: string; // 콜드(Cold) 데이터
  id: string; // 콜드(Cold) 데이터
}
```

`MovementSystem`은 매 프레임(`requestAnimationFrame`) 실행되는 **'핫 패스'**입니다. 이 시스템은 오직 `position`, `velocity`, `life`만 필요로 합니다.

하지만 메모리 레이아웃은 다음과 같습니다.

[P0_pos, P0_vel, P0_col, P0_life, P0_name, P0_id] [P1_pos, P1_vel, P1_col, P1_life, P1_name, P1_id] ...

CPU가 `P0_pos`를 읽기 위해 64바이트 캐시 라인을 가져올 때, `P0_col`, `P0_name` 같은 **관련 없는 '콜드(Cold)' 데이터**가 캐시의 귀중한 공간을 함께 차지합니다. `MovementSystem`은 이 `color` 데이터를 절대 사용하지 않음에도 불구하고, 이 데이터 때문에 정작 필요한 `P1_pos` 데이터가 캐시 라인에 함께 실리지 못할 수 있습니다.

이것이 바로 **'캐시 오염(Cache Pollution)'**입니다. `MovementSystem`의 관점에서 `color`와 `name`은 메모리상의 '잡음(Noise)'입니다.

------


### 15.2. 핵심 전략: 핫/콜드 데이터 분리 (Hot/Cold Data Splitting)


캐시 친화적인 레이아웃의 제1원칙은 **"데이터를 접근 빈도에 따라 분리하는 것"**입니다.

- **핫 데이터 (Hot Data)**: 핫 패스(예: `renderLoop`)에서 *매번*, *자주* 접근하는 데이터.
- **콜드 데이터 (Cold Data)**: 가끔(예: `onClick` 이벤트) 접근하거나, 초기 설정 시에만 접근하는 데이터.

우리는 이 두 데이터를 **서로 다른 배열(SoA)** 또는 **서로 다른 객체(AoS)**로 분리해야 합니다.


#### 15.2.1. SoA를 사용한 핫/콜드 분리 (궁극의 최적화)


이는 제13장에서 배운 SoA 방식 그 자체입니다.

```typescript
// 👍 SoA를 통한 핫/콜드 분리 (ECS 모델)
interface ParticleWorld {
  // --- 핫(Hot) 컴포넌트 저장소 ---
  // (MovementSystem이 함께 순회함)
  positions: { x: number; y: number }[];
  velocities: { dx: number; dy: number }[];
  lives: number[];

  // --- 콜드(Cold) 컴포넌트 저장소 ---
  // (RenderSystem만 가끔 순회함)
  colors: { r: number; g: number; b: number; a: number }[];
  // (InfoSystem만 onClick 시 접근함)
  metadata: { id: string; name: string }[];
  
  count: number;
}
```

`MovementSystem`이 `positions`, `velocities`, `lives` 배열을 순회할 때, 이 세 배열의 데이터는 메모리상에 각각 연속적으로 배치됩니다. `colors`나 `metadata` 배열은 이 시스템의 캐시 라인을 전혀 오염시키지 않습니다.


#### 15.2.2. AoS를 유지하면서 핫/콜드 분리하기 (실용적 절충안)


때로는 SoA로의 전환이 너무 급진적이거나, AoS의 '객체 단위' 접근 방식(`particle[i]`)이 주는 편리함을 포기하기 어려울 수 있습니다. 이 경우, **AoS 객체 자체를 분리**할 수 있습니다.

```typescript
// 👍 AoS를 유지하면서 핫/콜드 객체로 분리
interface ParticleHot {
  position: { x: number; y: number };
  velocity: { dx: number; dy: number };
  life: number;
}
interface ParticleCold {
  color: { r: number; g: number; b: number; a: number };
  name: string;
  id: string;
}

// 💥 데이터가 '핫 배열'과 '콜드 배열'로 분리됨
// (주의: 두 배열의 index 'i'는 동일한 엔티티를 가리켜야 함)
const particlesHot: ParticleHot[] = [
  { pos: ..., vel: ..., life: 100 }, // Particle 0
  { pos: ..., vel: ..., life: 80 },  // Particle 1
  // ...
];
const particlesCold: ParticleCold[] = [
  { col: ..., name: 'p0', id: 'uuid-0' }, // Particle 0
  { col: ..., name: 'p1', id: 'uuid-1' }, // Particle 1
  // ...
];
```

이제 `MovementSystem`을 실행해 봅시다.

```typescript
// '핫 배열'만 순회하는 핫 패스
function movementSystemAoS_Split(hotData: ParticleHot[]): void {
  for (let i = 0; i < hotData.length; i++) {
    const p = hotData[i];
    p.position.x += p.velocity.dx;
    p.position.y += p.velocity.dy;
    p.life -= 1;
  }
}
```

이 `movementSystemAoS_Split` 함수는 `particlesHot` 배열만 순회합니다. 이 배열은 `position`, `velocity`, `life`라는 **핫 데이터만으로 빽빽하게(Dense)** 채워져 있습니다.

`particlesCold` 배열의 `color`, `name` 데이터는 이 루프에서 완전히 배제됩니다. `hotData[i]`를 캐시 라인으로 가져올 때 `hotData[i+1]`이 함께 딸려올 확률이 높아져 **공간적 지역성이 크게 향상**됩니다.

이 방식은 React의 `useState`나 Redux 스토어에서도 실용적으로 적용할 수 있습니다.

```typescript
// 👎 나쁜 예: 핫/콜드 데이터가 섞인 상태
const [user, setUser] = useState({
  id: 'u1',               // 콜드
  name: 'Alice',          // 콜드
  email: 'alice@e.com',   // 콜드
  lastActivity: Date.now() // 핫 (매초 갱신될 수 있음)
});

// 👍 좋은 예: 핫/콜드 상태 분리
const [userProfile, setUserProfile] = useState({ // 콜드
  id: 'u1',
  name: 'Alice',
  email: 'alice@e.com',
});
const [userStatus, setUserStatus] = useState({ // 핫
  lastActivity: Date.now()
});
```

`lastActivity`가 갱신되어도, `userProfile` 객체는 변경되지 않습니다. `userProfile`을 `prop`으로 받는 `ProfileHeader` 컴포넌트는 불필요한 리렌더링을 피할 수 있습니다. (이는 제6장 '파생 상태'의 원리와도 연결됩니다.)

------


### 15.3. 데이터 순서와 메모리 정렬 (Field Ordering)


캐시 친화적인 레이아웃의 두 번째 원칙은 **"함께 사용되는 데이터는 메모리상에서도 가깝게 배치하라"**입니다.

JavaScript는 C/C++처럼 메모리 주소를 직접 제어하거나 구조체 패딩(Padding)을 관리할 수 없습니다. 하지만 V8 엔진은 **객체 속성(Property)의 순서**를 어느 정도 존중합니다.


#### 15.3.1. JavaScript 객체의 메모리 레이아웃 (추상적)


V8 엔진은 '히든 클래스(Hidden Class)' 또는 'Shape'라는 메커니즘을 사용합니다. 동일한 '모양'(동일한 순서로 정의된 동일한 속성)을 가진 객체들은 내부적으로 동일한 메모리 레이아웃을 공유합니다.

```typescript
const obj1 = { a: 1, b: 2 };
const obj2 = { a: 3, b: 4 };
// obj1과 obj2는 동일한 'Shape'을 공유 (최적화됨)

const obj3 = { b: 5, a: 6 };
// obj3는 '속성 순서'가 다르므로 *다른* 'Shape'을 가짐 (비효율적)
```

**규칙: 항상 동일한 순서로 객체를 생성하십시오.** (대부분의 경우 TypeScript 인터페이스와 `prettier`가 이를 강제합니다.)


#### 15.3.2. 접근 패턴에 맞게 속성 순서 정하기


더 나아가, 우리는 '핫 패스'에서 함께 접근되는 데이터들을 객체 정의 시 **물리적으로 가깝게** 배치할 수 있습니다.

```typescript
// (MovementSystem이 pos와 vel만 접근한다고 가정)

// 👎 캐시 비친화적 순서
// (pos와 vel 사이에 관련 없는 데이터가 끼어 있음)
const particleAoS = {
  position: { x: 10, y: 20 },
  color: { r: 255, g: 0, b: 0, a: 1 }, // 콜드
  velocity: { dx: 1, dy: 0 },
  name: 'p0', // 콜드
  life: 100,
};

// 👍 캐시 친화적 순서
// (핫 데이터(pos, vel, life)가 메모리상에 연속적으로 배치될 가능성 ↑)
const particleAoS_Optimized = {
  // --- 핫 데이터 그룹 ---
  position: { x: 10, y: 20 },
  velocity: { dx: 1, dy: 0 },
  life: 100,
  // --- 콜드 데이터 그룹 ---
  color: { r: 255, g: 0, b: 0, a: 1 },
  name: 'p0',
};
```

V8 엔진이 `particleAoS_Optimized.position`을 캐시 라인에 가져올 때, 바로 뒤에 있는 `velocity`와 `life` 데이터가 함께 딸려올 확률이 `particleAoS`보다 높습니다. `MovementSystem`이 `pos`, `vel`, `life`를 연달아 접근할 때 캐시 히트율이 높아질 수 있습니다.

이것은 미세 최적화(Micro-optimization) 영역이지만, 수백만 개의 객체를 핫 패스에서 순회할 때는 측정 가능한 성능 차이를 만들어냅니다.

------


### 15.4. 결론: 로직에 맞게 데이터를 '요리'하라


캐시 친화적인 데이터 레이아웃은 '데이터는 데이터, 로직은 로직'이라는 수동적인 태도를 버리고, **"로직(System)이 데이터를 어떻게 소비하는가?"**에 맞춰 데이터 구조를 능동적으로 '설계'하는 과정입니다.

1. **접근 빈도를 분석하라**: 어떤 데이터가 '핫 패스'에서 순회되고, 어떤 데이터가 '가끔' 접근되는가?
2. **핫/콜드 데이터를 분리하라**: '핫 데이터'는 '핫 데이터'끼리 빽빽하게 모아 캐시 오염을 막아라. (SoA 또는 AoS 분리)
3. **접근 순서를 고려하라**: 핫 패스에서 '함께' 접근되는 데이터는 객체/구조체 내에서도 '가깝게' 배치하라.

AoS는 '개념적(Conceptual)'으로 데이터를 캡슐화한 방식이며, SoA는 '접근 패턴(Access Pattern)'에 맞게 데이터를 재배치한 방식입니다.

데이터 지향 성능 최적화란, AoS라는 '인간 친화적' 레이아웃을 '핫 패스'에 한해 **SoA라는 'CPU 친화적' 레이아웃으로 변환**하는 기술입니다.

------

네, 알겠습니다. 제4부 '성능 최적화'의 네 번째 장, '대용량 리스트 가상화와 데이터 청킹' 집필을 시작하겠습니다. 이 장은 수백만 개의 데이터를 다루는 현대 웹 애플리케이션의 핵심 성능 병목을 해결하는 데이터 지향 기법을 탐구합니다.

------


## 16. 대용량 리스트 가상화와 데이터 청킹


> "가장 빠른 픽셀은 렌더링되지 않은 픽셀이고, 가장 가벼운 데이터는 로드되지 않은 데이터이다. 대용량 데이터를 다룰 때, 우리가 보여주지 '않을' 것을 아는 것이 보여줄 것을 아는 것보다 중요하다."

지금까지 우리는 13~15장을 통해 데이터가 메모리에 '어떻게' 배치되어야 CPU의 캐시 효율을 높일 수 있는지(SoA, 데이터 지역성, 핫/콜드 분리)라는 마이크로 레벨의 성능을 탐구했습니다.

이제 우리는 시야를 넓혀, '얼마나 많은' 데이터를 브라우저에 로드하고 렌더링할 것인가라는 매크로 레벨의 성능 문제를 다룹니다.

트위터 피드, 슬랙 메시지, 거대한 데이터 그리드, 로그 뷰어... 현대 웹 애플리케이션은 수천, 수만, 심지어 수백만 개의 항목을 사용자에게 보여줘야 합니다. 여기에 데이터 지향 원칙을 적용하지 않고 순진하게 접근하면, 즉 `data.map(item => <Item ... />)`을 실행하면, 브라우저는 즉시 멈춰버릴 것입니다.

DOM 노드는 매우 '비싼' 자원입니다. 각 노드는 메모리를 차지할 뿐만 아니라, 브라우저의 레이아웃, 페인트, 합성 과정에서 복잡한 계산을 유발합니다. 10,000개의 `<div>`를 렌더링하는 것은 10,000개의 JavaScript 객체를 만드는 것과는 비교할 수 없는 부하를 유발합니다.

이 문제를 해결하기 위한 두 가지 핵심 데이터 전략이 바로 **'UI 가상화(UI Virtualization)'**와 **'데이터 청킹(Data Chunking)'**입니다.

- **UI 가상화**: DOM 렌더링 병목을 해결합니다. (View 최적화)
- **데이터 청킹**: JavaScript 메모리 및 네트워크 병목을 해결합니다. (Data 최적화)

본 장에서는 이 두 기법이 어떻게 상호작용하여 사실상 무한한 데이터를 매끄럽게 스크롤할 수 있게 하는지 그 원리를 탐구합니다.

------


### 16.1. UI 가상화 (List Virtualization): DOM 속이기


UI 가상화(또는 '윈도윙(Windowing)')의 기본 아이디어는 지극히 데이터 지향적입니다.

"전체 데이터 리스트(예: 100,000개)를 자바스크립트 메모리에는 들고 있되, DOM에는 '현재 눈에 보이는' 몇 개(예: 20개)만 렌더링한다."


#### 16.1.1. 핵심 원리: '창문'과 '가짜 스크롤바'


1. **컨테이너(Container)**: `overflow-y: scroll`이 적용된, 고정된 높이(예: `600px`)의 '창문' 역할을 하는 `<div>`입니다.
2. **전체 스크롤바 생성 (The Spacer Trick)**:
   - 사용자가 100,000개 항목을 스크롤하는 것처럼 느끼게 하려면, 스크롤바의 총 높이가 그만큼 길어야 합니다.
   - 각 항목의 높이를 안다(고 가정)면(예: `itemHeight = 30px`), 총 높이를 계산할 수 있습니다.
   - `totalHeight = items.length * itemHeight` (100,000 * 30 = 3,000,000px)
   - 컨테이너 내부에 이 `totalHeight`를 가진 '스페이서(Spacer)' `<div>`를 둡니다. 이것이 가짜 스크롤바를 만듭니다.
3. **'창문' 계산 (The Windowing)**:
   - 사용자가 컨테이너를 스크롤하면 `onScroll` 이벤트가 발생하고, `scrollTop` 값을 얻을 수 있습니다.
   - 이 `scrollTop`과 `itemHeight`를 사용해 '현재 보여줘야 할' 항목의 인덱스 범위를 계산합니다.
   - `startIndex = Math.floor(scrollTop / itemHeight)`
   - `visibleItemCount = Math.ceil(containerHeight / itemHeight) + buffer` (보통 위아래로 몇 개씩 버퍼를 둠)
   - `endIndex = startIndex + visibleItemCount`
4. **렌더링 및 위치 조정**:
   - 실제 렌더링할 데이터는 `items.slice(startIndex, endIndex)`입니다. (단 20여 개)
   - 이 20개의 항목을 담은 `<div>`를 스페이서 내부에 `position: absolute`로 배치합니다.
   - 이 리스트의 수직 위치는 `transform: translateY(${startIndex * itemHeight}px)`로 조정합니다.


#### 16.1.2. 간단한 고정 높이 가상 리스트 (TypeScript + React)


이 원리를 간단한 React 훅으로 구현해 봅시다.

```typescript
import React, { useState, useMemo, useCallback } from 'react';

// 가상화 로직을 처리하는 '시스템' (Custom Hook)
function useVirtualList<T>(
  items: T[],         // 1. 전체 데이터 (JS 메모리에 있음)
  itemHeight: number, // 2. 각 항목의 '고정' 높이
  containerHeight: number, // 3. '창문'의 높이
  buffer: number = 5 // 4. 위아래 버퍼
) {
  const [scrollTop, setScrollTop] = useState(0);

  // 1. 스크롤 이벤트 핸들러 (부수 효과 영역)
  const handleScroll = (e: React.UIEvent<HTMLDivElement>) => {
    setScrollTop(e.currentTarget.scrollTop);
  };

  // 2. 파생 상태: 전체 높이 계산 (메모이제이션)
  const totalHeight = useMemo(
    () => items.length * itemHeight,
    [items.length, itemHeight]
  );

  // 3. 파생 상태: '창문' 계산 (메모이제이션)
  const { startIndex, endIndex, offsetY } = useMemo(() => {
    const startIndex = Math.max(
      0,
      Math.floor(scrollTop / itemHeight) - buffer
    );
    const endIndex = Math.min(
      items.length - 1,
      Math.floor((scrollTop + containerHeight) / itemHeight) + buffer
    );
    const offsetY = startIndex * itemHeight;
    return { startIndex, endIndex, offsetY };
  }, [scrollTop, itemHeight, containerHeight, items.length, buffer]);

  // 4. 파생 상태: 현재 렌더링할 아이템들
  const visibleItems = useMemo(
    () => items.slice(startIndex, endIndex + 1),
    [items, startIndex, endIndex]
  );

  // 5. 렌더링에 필요한 'props' 반환
  return {
    handleScroll,
    totalHeight,
    offsetY,
    visibleItems,
  };
}

// --- React 컴포넌트 (RenderSystem) ---
// (100,000개 아이템을 가진 'data' 배열이 있다고 가정)
function VirtualizedList() {
  const containerHeight = 600;
  const itemHeight = 30;

  const { handleScroll, totalHeight, offsetY, visibleItems } = useVirtualList(
    data,
    itemHeight,
    containerHeight
  );

  return (
    // 1. '창문' 컨테이너 (스크롤 이벤트 감지)
    <div
      style={{ height: containerHeight, overflowY: 'scroll', border: '1px solid black' }}
      onScroll={handleScroll}
    >
      {/* 2. '가짜 스크롤바'를 위한 스페이서 */}
      <div style={{ height: totalHeight, position: 'relative' }}>
        
        {/* 3. '실제' 렌더링되는 아이템들 (절대 위치로 이동) */}
        <div style={{ transform: `translateY(${offsetY}px)`, position: 'absolute', width: '100%' }}>
          {visibleItems.map((item) => (
            <div key={item.id} style={{ height: itemHeight, borderBottom: '1px solid #eee' }}>
              {item.name} (ID: {item.id})
            </div>
          ))}
        </div>
      </div>
    </div>
  );
}
```


#### 16.1.3. 동적 높이: 진짜 문제


위 예제는 `itemHeight`가 고정되어 있다는 비현실적인 가정에 기반합니다. 실제로는 항목마다 높이가 다릅니다. 이는 `startIndex` 계산을 불가능하게 만듭니다.

- **해결책**:
  1. **측정 및 캐싱**: 렌더링된 항목의 실제 높이(`offsetHeight`)를 `useLayoutEffect`나 `ResizeObserver`로 측정하여 `heightCache: Map<index, number>`에 저장합니다.
  2. **추정**: 아직 렌더링되지 않은 항목의 높이는 `averageItemHeight` 같은 추정치를 사용합니다.
  3. **보정**: 스크롤하면서 실제 측정값으로 `totalHeight`와 `offsetY`를 계속 보정합니다.

이 로직은 매우 복잡하며, **`react-window`**, **`react-virtualized`** 또는 **`@tanstack/react-virtual`** 같은 전문 라이브러리를 사용하는 것이 현명합니다. 이 라이브러리들은 이 '측정'과 '보정'이라는 복잡한 '시스템(Logic)'을 캡슐화해 줍니다.

------


### 16.2. 데이터 청킹 (Data Chunking): JS 메모리 속이기


UI 가상화는 10만 개의 항목이 **이미 JavaScript 메모리에 로드되었다**고 가정합니다. 만약 항목이 천만 개라면 어떨까요? 서버에서 천만 개 데이터를 `fetch`하는 순간, 네트워크 요청도 실패하고 브라우저 메모리도 다운될 것입니다.

**데이터 청킹(Data Chunking)**은 UI 가상화가 DOM에 했던 일을, JS 메모리에 똑같이 적용합니다.

"서버의 전체 데이터(예: 천만 개) 중, '현재 사용자가 볼 가능성이 있는' 데이터(예: 500개)만 JS 메모리로 가져온다."

이 기법은 보통 '무한 스크롤(Infinite Scrolling)'과 결합됩니다.

1. UI 가상화 시스템이 `startIndex = 480`, `endIndex = 500`을 계산했다고 가정합시다.
2. 데이터 청킹 시스템(데이터 캐시)은 "500번 인덱스 항목이 필요한데, 해당 '페이지'가 로드되었는가?"를 확인합니다.
3. 데이터를 100개 단위의 '청크(Chunk)' 또는 '페이지(Page)'로 관리한다고 가정합니다.
   - `pageNeeded = Math.floor(endIndex / 100)` (즉, 5번 페이지)
   - `dataCache: Map<pageNumber, Item[]>` (JS 메모리에 유지하는 캐시)
4. `dataCache.has(5)`를 확인합니다.
   - **Cache Hit**: `dataCache.get(5)`에서 데이터를 가져와 가상 리스트에 제공합니다.
   - **Cache Miss**: `dataCache.set(5, 'LOADING')`으로 표시하고, `api.fetchPage(5)` (100개 항목 요청)를 비동기적으로 호출합니다. 이 동안 UI는 로딩 스피너를 보여줍니다.
5. API 응답이 오면 `dataCache.set(5, response.data)`로 캐시를 업데이트하고, UI를 리렌더링합니다.


#### 16.2.1. 데이터 지향적 캐시 설계


이 `dataCache`는 제5장(SSoT)과 제12장(CQRS)의 관점에서 완벽한 **'읽기 모델(Read Model)'**이자 **'서버 상태의 클라이언트 캐시'**입니다.

- **SSoT**: 서버 데이터베이스 (진실)
- **Write Model (in Client)**: `dataCache: Map<page, Item[]>` (SSoT의 캐시)
- **Query**: `getItem(index)` (UI 가상화 시스템이 호출하는 조회 함수)

```typescript
// (Zustand나 React Query로 관리하면 더 좋음)
const dataCache = new Map<number, { status: 'loading' | 'loaded'; data: Item[] }>();
const CHUNK_SIZE = 100;

// 'Query Handler' 역할 (CQRS)
// UI는 이 함수 하나만 바라봄
function getItemFromCache(index: number): Item | 'loading' | 'idle' {
  const page = Math.floor(index / CHUNK_SIZE);
  const indexInPage = index % CHUNK_SIZE;

  const chunk = dataCache.get(page);

  if (!chunk) {
    // Cache Miss -> 'Command' 트리거
    fetchChunk(page); // (비동기, 중복 방지 로직 필요)
    return 'loading';
  }
  
  if (chunk.status === 'loading') {
    return 'loading';
  }

  // Cache Hit
  return chunk.data[indexInPage] ?? 'idle'; // (데이터가 없을 수도 있음)
}

// 'Command Handler' 역할 (CQRS)
async function fetchChunk(page: number) {
  if (dataCache.get(page)?.status === 'loading') return; // 중복 방지

  dataCache.set(page, { status: 'loading', data: [] });
  // (실제로는 스토어의 'set'을 호출하여 React에 알려야 함)

  try {
    const data = await api.fetchItems(page, CHUNK_SIZE);
    dataCache.set(page, { status: 'loaded', data: data });
    // (스토어 'set' 호출 -> UI 갱신)
  } catch (e) {
    dataCache.delete(page); // 실패 시 캐시 제거
  }
}
```

이제 `VirtualizedList`는 `data` 배열 대신, `itemCount` 숫자와 `getItem(index)` 함수만 `prop`으로 받아 `getItem(index)`의 반환 값('loading' 또는 실제 데이터)에 따라 렌더링을 분기합니다. (이는 `@tanstack/react-virtual`의 접근 방식과 정확히 일치합니다.)

------


### 16.3. 결론: 두 개의 가상화


대용량 데이터 처리는 두 개의 전선(Front)에서 동시에 벌어지는 전투입니다.

1. **DOM 전선**: CPU의 렌더링 부하를 줄여야 합니다.
   - **해결책**: **UI 가상화 (Windowing)**. '눈에 보이는 것'만 렌더링합니다.
2. **메모리 전선**: JavaScript 힙 메모리 부하와 네트워크 부하를 줄여야 합니다.
   - **해결책**: **데이터 청킹 (Pagination/Caching)**. '필요할 것 같은 것'만 로드합니다.

이 두 전략은 **'필요한 데이터만, 필요한 시점에 처리한다'**는 데이터 지향 프로그래밍의 핵심 원칙을 공유합니다. 우리는 '전체'를 다루려는 OOP적 사고(예: `new MassiveList(data).render()`)에서 벗어나, 데이터를 '창문'과 '청크'라는 작은 단위로 분해하고 파이프라이닝함으로써 사실상 무한한 스케일의 성능을 달성합니다.

------

네, 알겠습니다. 제4부 '성능 최적화'를 마치고, 이제 제5부 '실용적인 기법들'의 첫 번째 장을 시작하겠습니다. 이 장은 제2부에서 다루었던 '정규화'의 개념을 더 실용적이고 깊이 있는 전략적 관점에서 다시 탐구합니다.

------


## 17. 데이터 정규화 전략 - Relational 데이터의 프론트엔드 표현


> "데이터베이스 설계자가 수십 년간 고민해온 '관계'의 문제를 프론트엔드라고 피할 수 있을까? 정규화는 선택이 아니라, 복잡한 '관계'를 다루는 애플리케이션의 숙명이다. 어떻게, 그리고 '얼마나' 할 것인가가 문제일 뿐이다."

제2부 '상태 관리의 데이터 중심 접근'의 제4장('정규화된 상태 구조 설계')에서, 우리는 상태 관리의 핵심 원칙으로 '정규화'를 배웠습니다. 중첩된(Nested) API 응답 구조를 그대로 상태에 저장하는 것이 왜 '데이터 중복', '복잡한 업데이트', '성능 저하'라는 재앙을 초래하는지 확인했습니다.

그 해답은 상태 저장소를 '작은 데이터베이스'처럼 설계하는 것이었습니다.

1. **엔티티(Entities) 분리**: `users`, `posts`처럼 데이터 유형별로 '테이블'을 나눕니다.
2. **ID 기반 인덱싱**: `entities.users['u1']`처럼 $O(1)$ 조회를 위해 ID를 키로 하는 맵(Map)을 사용합니다.
3. **ID 참조**: `post.authorId = 'u1'`처럼 엔티티 간의 관계는 ID로 표현합니다.

이것은 백엔드의 **관계형 데이터베이스(Relational Database, RDB)**가 작동하는 방식과 정확히 일치합니다. RDB는 `User` 테이블과 `Post` 테이블을 `author_id`라는 '외래 키(Foreign Key)'로 연결(JOIN)합니다.

본 장에서는 이 '관계형 데이터'를 프론트엔드에서 표현하는 실용적인 전략과, "언제 정규화하고 언제 중첩을 허용할 것인가"라는 핵심적인 트레이드오프, 그리고 이 모든 것을 자동으로 처리해 주는 강력한 도구인 **`Redux Toolkit`의 `createEntityAdapter`**에 대해 깊이 있게 탐구합니다.

------


### 17.1. Relational 데이터의 프론트엔드 표현: Schema


프론트엔드에서 '관계'를 다룬다는 것은 결국 '상태 스키마(State Schema)'를 RDB 스키마처럼 설계한다는 의미입니다.

백엔드 RDB 스키마가 다음과 같다고 가정해 봅시다.

User 테이블

| id (PK) | name |

| :--- | :--- |

| u1 | Alice |

| u2 | Bob |

Post 테이블

| id (PK) | author_id (FK -> User.id) | title |

| :--- | :--- | :--- |

| p1 | u1 | "데이터 지향" |

| p2 | u2 | "프론트엔드" |

| p3 | u1 | "성능 최적화" |

프론트엔드의 정규화된 상태 스키마는 이 구조를 그대로 **'모방(Mimic)'**해야 합니다.

```typescript
// 👍 RDB 스키마를 1:1로 반영한 프론트엔드 스키마
interface User {
  id: string;
  name: string;
}

interface Post {
  id: string;
  authorId: string; // '외래 키' (User.id)
  title: string;
}

interface AppState {
  entities: {
    // 'User 테이블'
    users: Record<string, User>; 
    // 'Post 테이블'
    posts: Record<string, Post>;
  };
  // (참고: UI가 'Alice의 게시물 ID 목록'을 빠르게 찾아야 한다면, 
  // users.postIds: string[] 같은 비정규화된 캐시를 추가할 수도 있음)
}

// 스토어의 실제 데이터
const state: AppState = {
  entities: {
    users: {
      'u1': { id: 'u1', name: 'Alice' },
      'u2': { id: 'u2', name: 'Bob' },
    },
    posts: {
      'p1': { id: 'p1', authorId: 'u1', title: '데이터 지향' },
      'p2': { id: 'p2', authorId: 'u2', title: '프론트엔드' },
      'p3': { id: 'p3', authorId: 'u1', title: '성능 최적화' },
    }
  }
};
```

**이점은 명확합니다.** (제4장 복습)

- **SSoT (단일 진실 공급원)**: 'Alice'의 이름이 바뀌면 `state.entities.users['u1'].name` **단 한 곳**만 수정하면 됩니다. `p1`과 `p3` 게시물은 `authorId`로 'u1'을 참조(조회)할 뿐, 'Alice'라는 데이터를 '복사'하고 있지 않기 때문에 자동으로 갱신된 이름을 보게 됩니다.
- **단순한 업데이트**: `p1` 게시물 제목을 수정하는 것은 `state.entities.posts['p1'].title = 'New'`라는 $O(1)$ 작업입니다. 중첩된 배열을 순회할 필요가 없습니다.

------


### 17.2. 핵심 전략: ID 참조 vs 중첩 객체 (The Trade-off)


정규화가 항상 정답일까요? **아닙니다.** 정규화는 '데이터 일관성'을 얻는 대신 '데이터 조회' 시 '재조합(Join)' 비용을 치릅니다.

제6장 '파생 상태'에서 배운 **셀렉터(Selector)**가 바로 이 '재조합'을 수행합니다.

```typescript
// 'p1' 게시물과 작성자 정보를 '재조합'하는 셀렉터
function selectPostWithAuthor(state: AppState, postId: string): PostWithAuthor | null {
  const post = state.entities.posts[postId];
  if (!post) return null;
  
  // 💥 재조합(Join) 비용 발생: post.authorId를 사용해 users 테이블을 다시 조회
  const author = state.entities.users[post.authorId]; 
  
  return { ...post, author: author };
}
```

만약 `post.author` 정보가 *항상* `post`와 함께 필요하고, `author` 정보가 다른 곳에서는 거의 참조되지 않으며, `author` 정보가 절대 변하지 않는다면 어떨까요?

이 경우, `author`를 중첩시키는 것이 셀렉터를 통한 재조합 비용보다 저렴할 수 있습니다.

**[정규화(ID 참조) vs 중첩(Denormalization) 결정 가이드]**


### 1.. ID 참조 (정규화)를 사용해야 할 때 (언제 분리할 것인가?)


**"데이터가 독립적인 생명주기(Lifecycle)를 가지는가?"**

- **데이터가 공유될 때 (Shared)**:
  - 'User' 데이터는 `PostAuthor`, `Commenter`, `ProfilePage` 등 앱 전역에서 공유됩니다.
  - **결론**: `User`는 반드시 정규화된 `entities.users`에 분리해야 합니다.
- **데이터가 개별적으로 업데이트될 때 (Frequently Updated)**:
  - 사용자가 자신의 '이름'을 수정하는 것은 '게시물'을 수정하는 것과 별개의 작업입니다. 'Alice'라는 이름이 `post.author.name`에 중첩되어 있었다면, 'Alice'가 쓴 모든 게시물을 찾아 `author.name`을 갱신해야 하는 끔찍한 작업이 필요합니다.
  - **결론**: `User`는 분리해야 합니다.
- **데이터가 다른 API 엔드포인트에서 올 때 (Separate Endpoints)**:
  - `GET /api/posts/p1`은 `author`를 중첩해 주지만, `GET /api/users/u1`은 `User` 정보만 반환합니다. 이 두 `User` 정보의 일관성을 어떻게 맞출까요?
  - **결론**: `User` 데이터를 `entities.users`라는 SSoT로 통합(정규화)하고, 두 API 응답 모두 이 SSoT를 갱신하도록 파이프라인(제2장)을 설계해야 합니다.


### 2.. 중첩 객체를 허용할 때 (언제 포함시킬 것인가?)


**"데이터가 부모 엔티티에 1:1로 종속적인가?"**

- **데이터가 공유되지 않을 때 (Owned)**:
  - `post.metadata` 객체 (예: `{ seoTitle: '...', canonicalUrl: '...' }`)
  - 이 `metadata`는 `p1` 게시물 외에 그 어디에서도 참조되지 않습니다. `metadata`만 따로 불러오는 API도 없습니다.
  - **결론**: `metadata`는 `Post` 객체 내에 중첩하는 것이 합리적입니다. `entities.metadatas` 테이블을 만드는 것은 과잉 설계(Over-engineering)입니다.
- **데이터가 원자적(Atomic)으로 취급될 때 (Atomic)**:
  - `user.address` 객체 (예: `{ street: '...', city: '...', zipCode: '...' }`)
  - `address`는 `user`와 항상 함께 로드되고, 함께 수정됩니다. `street`만 따로 수정하는 경우는 거의 없습니다.
  - **결론**: `address`는 `User` 객체 내에 중첩해도 좋습니다.
- **데이터가 불변(Immutable)일 때 (Read-only)**:
  - `product.dimensions` (예: `{ width: 10, height: 20 }`)
  - 제품의 '치수'는 생성된 후 절대 변하지 않는 값입니다. 데이터 중복이나 불일치 문제가 원천적으로 발생하지 않습니다.
  - **결론**: `dimensions`는 `Product` 객체 내에 중첩하는 것이 성능상 이득입니다.

**결론**: 정규화는 만병통치약이 아닙니다. **'공유되고', '자주 변경되며', '독립적인' 엔티티(User, Post, Comment)만 정규화**하고, '종속적이고', '원자적이거나', '불변인' 값(Address, Metadata, Dimensions)은 중첩을 허용하는 것이 실용적인 접근입니다.

------


### 17.3. 실용적인 구현: Redux Toolkit의 `createEntityAdapter`


이 복잡한 정규화 상태를 손으로 직접 관리하는 것은 번거롭습니다.

- `addItem`: `state.entities.items[id] = item`
- `removeItem`: `delete state.entities.items[id]`
- `updateItem`: `state.entities.items[id] = { ...state.entities.items[id], ...updates }`

이 모든 보일러플레이트 로직을 '시스템(System)'으로 캡슐화한 것이 바로 Redux Toolkit(RTK)의 **`createEntityAdapter`**입니다.

`createEntityAdapter`는 정규화된 상태를 관리하기 위한 **'완전한 CRUD 시스템'**을 자동으로 생성해 줍니다.


#### 17.3.1. 스키마 정의 및 어댑터 생성


```typescript
import { createEntityAdapter, createSlice, EntityState } from '@reduxjs/toolkit';

// 1. 엔티티 타입 정의
interface User {
  id: string; // 'id' 필드명을 사용한다고 가정
  name: string;
}

// 2. 어댑터(Adapter) 생성
// 'User' 타입을 관리하는 정규화 시스템을 생성
const usersAdapter = createEntityAdapter<User>({
  // (선택 사항: ID 필드명이 'id'가 아닌 'userId'인 경우)
  // selectId: (user) => user.userId,
  
  // (선택 사항: 정렬 순서 유지)
  // sortComparer: (a, b) => a.name.localeCompare(b.name),
});

// 3. 정규화된 상태(State) 타입 정의
// EntityState<T>는 { ids: string[], entities: Record<string, T> } 타입을 제공
interface UsersState extends EntityState<User> {
  // (추가적인 상태, 예: 로딩 상태)
  status: 'idle' | 'loading';
}

// 4. 초기 상태 생성
const initialState: UsersState = usersAdapter.getInitialState({
  status: 'idle',
});
// 'initialState'는 다음과 같은 형태:
// {
//   ids: [],
//   entities: {},
//   status: 'idle'
// }
```


#### 17.3.2. 자동으로 생성되는 CRUD 시스템 (Reducers)


`createEntityAdapter`의 진정한 힘은 '리듀서(시스템)'를 자동으로 제공하는 것입니다.

```typescript
const usersSlice = createSlice({
  name: 'users',
  initialState,
  reducers: {
    // 💥 어댑터가 제공하는 '명령 핸들러(Reducers)' 사용
    
    // 유저 1명 추가: state.users.addOne
    userAdded: usersAdapter.addOne, 
    
    // 유저 여러 명 추가: state.users.addMany
    usersReceived: usersAdapter.setAll, // (setAll은 기존 것을 지우고 새로 채움)
    
    // 유저 1명 수정: state.users.updateOne
    // { id: 'u1', changes: { name: 'Alice Kim' } } 형태의 페이로드 필요
    userUpdated: usersAdapter.updateOne,
    
    // 유저 1명 삭제: state.users.removeOne
    // 'u1' (id) 페이로드 필요
    userRemoved: usersAdapter.removeOne,
    
    // (직접 리듀서를 작성할 수도 있음)
    setLoading: (state, action) => {
      state.status = action.payload;
    }
  },
});
```

`usersAdapter.addOne` 같은 함수는 `(state, action)`을 인자로 받는 **완벽한 리듀서 함수**입니다. `immer.js`가 내장되어 불변성도 알아서 처리해 줍니다.

우리는 제12장(CQRS)에서 말한 'Command Handler'를 단 한 줄도 작성하지 않고 공짜로 얻었습니다.


#### 17.3.3. 자동으로 생성되는 셀렉터 (Queries)


어댑터는 '읽기'를 위한 메모이제이션된 셀렉터(제6장)도 제공합니다.

```typescript
// 어댑터의 'getSelectors'를 호출하여 셀렉터 그룹 생성
export const {
  selectById: selectUserById,     // ID로 1개 조회
  selectAll: selectAllUsers,    // 전체 목록 조회 (ids 순서대로)
  selectIds: selectUserIds,       // ID 목록 조회
  selectTotal: selectTotalUsers,  // 총 개수 조회
} = usersAdapter.getSelectors((state: RootState) => state.users);

// --- React 컴포넌트에서 사용 ---
function UserProfile({ userId }: { userId: string }) {
  // 👍 메모이제이션된 셀렉터를 사용해 SSoT에서 '조회(Query)'
  const user = useSelector((state) => selectUserById(state, userId));
  
  if (!user) return <div>로딩 중...</div>;
  return <h1>{user.name}</h1>;
}

function UserList() {
  const allUsers = useSelector(selectAllUsers);
  return (
    <ul>
      {allUsers.map(user => <li key={user.id}>{user.name}</li>)}
    </ul>
  );
}
```

`createEntityAdapter`는 제2부~제3부에서 배운 **[정규화된 SSoT] + [파생 상태 셀렉터] + [CQRS의 Command/Query]** 패턴을 구현하는 가장 실용적이고 강력한 '표준' 도구입니다.

------


### 17.4. 결론: 실용적인 정규화


프론트엔드에서의 데이터 정규화는 '데이터베이스 이론'이 아니라, **'복잡성 관리'**의 문제입니다.

- **Relational 데이터**는 프론트엔드에도 존재하며, 이를 정규화된 스키마로 표현하는 것은 SSoT를 지키는 첫걸음입니다.
- **ID 참조 vs 중첩**은 '데이터의 생명주기'와 '공유 여부'를 기준으로 결정하는 실용적인 트레이드오프입니다.
- **`createEntityAdapter`**는 이 모든 정규화 관리 로직(쓰기 시스템)과 조회 로직(읽기 셀렉터)을 캡슐화하여, 개발자가 비즈니스 로직에만 집중할 수 있도록 해주는 최고의 실용적인 기법입니다.

정규화는 비용이 들지만, `createEntityAdapter`는 그 비용을 거의 '0'으로 수렴시켜 줍니다.

------

네, 알겠습니다. 제5부 '실용적인 기법들'의 두 번째 섹션, '반응형 데이터 플로우'의 첫 번째 장을 시작하겠습니다. 이 장에서는 '데이터가 변경되면 UI가 반응한다'는 개념을 'Push'와 'Stream'이라는 관점에서 새롭게 탐구합니다.

------


## 18. 반응형 데이터 플로우 - RxJS, Signals를 통한 데이터 스트림


> "시간은 단지 순간의 연속이 아니다. 그것은 흐름이다. 위대한 아키텍처는 '현재 값'에 반응하는 것이 아니라 '값의 흐름'에 반응한다."

지금까지 우리는 `UI = f(State)`라는 React의 핵심 패러다임을 중심으로 아키텍처를 구축했습니다. 이 모델은 본질적으로 **'Pull' 기반**입니다. 상태(SSoT)가 변경되면, React는 컴포넌트 트리를 리렌더링하고, 컴포넌트(혹은 셀렉터)는 스토어에서 *필요한* 데이터를 **'가져옵니다(Pull)'.**

하지만 이 방식이 유일한 해답은 아닙니다. 만약 데이터가 '가져와지는' 정적인 존재가 아니라, '스스로 흘러가는' 동적인 존재라면 어떨까요?

이것이 **'Push' 기반** 아키텍처, 즉 **반응형 프로그래밍(Reactive Programming)**의 시작입니다. 이 패러다임에서 데이터는 '값'이 아니라 **'시간의 흐름에 따른 값의 스트림(Stream)'**으로 취급됩니다. 애플리케이션은 이 스트림을 '구독(Subscribe)'하고 있다가, 새로운 값이 '밀려오면(Push)' 그에 반응합니다.

이 'Push' 기반 모델을 구현하는 프론트엔드의 두 가지 강력한 기술이 바로 **RxJS**와 **Signals**입니다.

- **RxJS (Reactive Extensions for JavaScript)**: 시간에 따른 비동기 이벤트 스트림을 '파이프라인'으로 처리하는 데 특화된, 강력하고 복잡한 라이브러리입니다.
- **Signals**: 상태 변경을 '구독'하는 모든 곳에 정확하고 세밀하게(Fine-grained) '밀어 넣어' VDOM의 필요성조차 제거하려는, 새롭고 직관적인 반응형 원시 값입니다.

본 장에서는 이 두 가지 'Push' 패러다임이 데이터 지향 프로그래밍과 어떻게 연결되며, 프론트엔드 아키텍처를 어떻게 변화시키는지 탐구합니다.

------


### 18.1. RxJS: 이벤트 스트림을 위한 데이터 파이프라인


RxJS는 '이벤트'를 데이터로 취급하는 궁극의 라이브러리입니다. 마우스 클릭, 키보드 입력, API 응답, WebSocket 메시지 등 시간에 따라 발생하는 모든 것을 **'옵저버블(Observable)'**이라는 스트림으로 만듭니다.

그리고 이 스트림을 제어하기 위해 `map`, `filter`, `reduce`와 같은 '연산자(Operators)'를 제공합니다. 이 연산자들은 제1장에서 배운 **'순수 함수'**의 원칙을 따릅니다. 즉, RxJS는 **비동기 데이터 스트림을 위한 순수 함수형 파이프라인**을 구축하는 도구입니다.


#### 18.1.1. RxJS의 핵심 개념


1. **Observable (관찰대상)**: 이벤트 스트림 그 자체입니다. `[click, click, click, ...]`
2. **Observer (관찰자)**: 스트림을 '구독'하고 `next`, `error`, `complete` 알림을 받아 처리하는 소비자입니다.
3. **Subscription (구독)**: Observable과 Observer를 연결하는 '실행'입니다. `observable.subscribe(observer)`가 호출되기 전까지 Observable은 아무 일도 하지 않습니다(Lazy). **이 구독은 반드시 해제(unsubscribe)되어야 메모리 누수를 막습니다.**
4. **Operators (연산자)**: 스트림을 변환하는 순수 함수입니다. `map(e => e.clientX)`, `filter(x => x > 100)` 등.
5. **Pipe (파이프)**: 연산자들을 조합하여 '데이터 변환 파이프라인'(제2장)을 만드는 메서드입니다.


#### 18.1.2. RxJS의 킬러 유스케이스: 자동 완성 검색


RxJS의 진가는 복잡한 비동기 로직을 선언적으로 처리할 때 드러납니다. '검색어 자동 완성' 기능이 완벽한 예시입니다.

**[요구사항]**: 사용자가 검색창에 입력하면, API를 호출하여 결과를 보여준다. 단, 너무 잦은 API 호출을 막고, 이전 요청보다 나중에 시작된 요청이 먼저 도착하는 '경쟁 상태(Race Condition)'를 막아야 한다.

[전통적인(Naive) 방식의 문제점]

onChange 이벤트마다 fetch를 호출하면 네트워크가 마비됩니다. setTimeout으로 '디바운스'를 구현해도, 네트워크 응답 순서가 꼬이는 경쟁 상태는 해결하기 어렵습니다.

**[RxJS 방식: 선언적 데이터 파이프라인]**

```typescript
import { fromEvent, Observable } from 'rxjs';
import { 
  map, 
  debounceTime,         // 1. 디바운싱
  filter,               // 2. 필터링
  distinctUntilChanged, // 3. 중복 값 방지
  switchMap             // 4. 💥 경쟁 상태 해결 (핵심!)
} from 'rxjs/operators';

// 1. 데이터 소스 (Observable): input 요소의 'keyup' 이벤트 스트림
const inputElement = document.getElementById('search-input')!;
const keyUpStream$: Observable<Event> = fromEvent(inputElement, 'keyup');

// 2. 데이터 변환 파이프라인 (Operators)
const searchResultStream$: Observable<string[]> = keyUpStream$.pipe(
  // (a) 이벤트(Event)를 검색어(string)로 변환
  map(event => (event.target as HTMLInputElement).value),
  
  // (b) 300ms 동안 추가 입력이 없으면 통과 (API 호출 방지)
  debounceTime(300), 
  
  // (c) 빈 문자열이나 2글자 미만은 무시
  filter(query => query.length > 1),
  
  // (d) 이전과 동일한 검색어는 무시
  distinctUntilChanged(),
  
  // (e) 💥 핵심: 새로운 검색어가 들어오면, '진행 중이던' 이전 API 요청(fetch)을
  //      '자동으로 취소'하고, '새로운' API 요청으로 갈아탐(switch)
  switchMap(query => {
    // (이 Observable은 fetch Promise를 래핑)
    return fetch(`/api/search?q=${query}`).then(res => res.json());
  })
);

// 3. 구독 (Observer): 스트림의 결과를 소비
// (React 컴포넌트에서는 이 스트림을 `useEffect`로 구독)
const subscription = searchResultStream$.subscribe(
  results => {
    // 💥 이 'results' 데이터가 UI로 'Push'됨
    renderResults(results); 
  },
  error => {
    console.error('검색 중 에러:', error);
  }
);

// 컴포넌트 언마운트 시...
// subscription.unsubscribe();
```

이 코드는 `onChange` 핸들러 안에 복잡한 `if`문과 `setTimeout` 플래그를 두는 대신, "검색어 이벤트가 이런 파이프라인을 거쳐 결과가 된다"라는 **데이터의 흐름을 선언적**으로 정의합니다. `switchMap` 연산자 하나로 골치 아픈 경쟁 상태를 완벽하게 해결하는 것이 RxJS의 힘입니다.

------


### 18.2. Signals: VDOM을 넘어서는 세밀한 반응성


RxJS가 복잡한 비동기 '스트림' 처리에 중점을 둔다면, **Signals**는 '상태(State)' 그 자체를 반응형으로 만드는 데 중점을 둡니다. SolidJS, Qwik, Preact, Angular에서 채택하며 차세대 반응형 모델로 주목받고 있습니다.

Signals의 핵심 아이디어는 React의 UI = f(State) 모델을 버리는 것입니다.

React는 state가 변하면 f(컴포넌트)를 '통째로' 재실행하고 VDOM을 비교합니다.

Signals는 `state`가 변하면, 그 `state`를 **'직접 구독한'** 부분(예: 특정 `console.log` 또는 특정 DOM 노드)만 **'정확하게'** 다시 실행합니다.


#### 18.2.1. Signals의 핵심 개념


1. **Signal (신호)**: 상태의 '원자(Atom)'. `getter`와 `setter`를 가진 값 래퍼(Wrapper)입니다.
2. **Effect (효과)**: 하나 이상의 Signal을 '읽는' 함수. Signal이 `effect` 내부에서 *한 번이라도 읽히면*, 해당 Signal은 이 `effect`를 '구독자'로 자동 등록합니다. (이를 **자동 의존성 추적**이라 함)
3. **Computed/Memo (파생 상태)**: 하나 이상의 Signal을 읽어 '새로운 값'을 계산하는 Signal. (제6장의 '파생 상태', `reselect`와 동일한 역할)


#### 18.2.2. TypeScript 예제: 프레임워크 없는 반응형 시스템


`@preact/signals-core` 라이브러리를 사용하면 React 없이도 이 원리를 이해할 수 있습니다.

```typescript
import { signal, computed, effect } from '@preact/signals-core';

// 1. Signal 생성 (SSoT 원자)
const firstName = signal('Jane');
const lastName = signal('Doe');
const age = signal(30);

// 2. 파생 상태 (Computed/Memo) 생성
// 'computed' 함수는 'fullName'이라는 새로운 읽기 전용 Signal을 반환
const fullName = computed(() => {
  // 💥 '.value'로 읽는 순간 'firstName'과 'lastName'을 자동 구독
  console.log('Computing fullName...');
  return `${firstName.value} ${lastName.value}`;
});

// 3. Effect 생성 (시스템 / 소비자)
// 'effect' 함수는 내부의 Signal이 변할 때마다 *자동으로* 재실행
const loggerEffect = effect(() => {
  // 💥 '.value'로 읽는 순간 'fullName' Signal을 자동 구독
  console.log('Effect: Full name is', fullName.value);
});

// --- 시스템 실행 ---

// 4. 'lastName' Signal을 변경
// (이 변경은 'fullName' Signal을 'dirty'로 표시)
// (-> 'fullName'은 'loggerEffect'를 'dirty'로 표시)
console.log('Setting lastName to "Smith"');
lastName.value = 'Smith';
// 출력:
// Computing fullName...
// Effect: Full name is Jane Smith

console.log('---');

// 5. 'firstName' Signal을 변경
console.log('Setting firstName to "John"');
firstName.value = 'John';
// 출력:
// Computing fullName...
// Effect: Full name is John Smith

console.log('---');

// 6. 💥 관련 없는 'age' Signal을 변경
console.log('Setting age to 31');
age.value = 31;
// 출력:
// (아무것도 출력되지 않음!)
```

마지막 6번이 핵심입니다. `fullName`과 `loggerEffect`는 `age` Signal을 읽지(구독하지) 않았습니다. 따라서 `age`가 아무리 변경되어도 **파생 상태 계산(`fullName`)이나 이펙트(`loggerEffect`)는 전혀 실행되지 않습니다.**

React였다면, `age`가 `useState`였다면 컴포넌트 전체가 리렌더링되고 `useMemo`로 `fullName`의 재계산을 막아야 했을 것입니다. Signals는 이 의존성 그래프를 자동으로, 그리고 완벽하게 세밀하게(Fine-grained) 관리합니다.

------


### 18.3. RxJS vs Signals: 언제 무엇을 써야 하는가?


두 기술 모두 'Push' 기반의 데이터 지향 패러다임이지만, 목적이 다릅니다.

| **특징**        | **RxJS**                                                     | **Signals**                                                  |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **추상화**      | **스트림 (Stream)**                                          | **값 (Value)**                                               |
| **주요 관심사** | **시간**에 따른 **비동기 이벤트**의 조합                     | **상태** 변경에 따른 **동기적 UI** 업데이트                  |
| **복잡도**      | 매우 높음 (학습 곡선 가파름)                                 | 매우 낮음 (직관적)                                           |
| **핵심 연산자** | `switchMap`, `debounceTime`, `mergeMap`                      | `computed` (Memo), `effect`                                  |
| **주요 사용처** | • 복잡한 비동기 오케스트레이션  • UI 이벤트(드래그앤드롭)  • 네트워크/WebSockets | • UI 상태 관리  • VDOM 없는 빠른 렌더링  • React `useMemo`/`useEffect` 대체 |
| **데이터 지향** | 비동기 파이프라인을 위한 **순수 함수**                       | **데이터 주도** 의존성 그래프                                |

**요약**:

- 복잡한 **비동기 로직**과 **이벤트의 흐름**을 다뤄야 한다면 (예: "유저가 드래그를 '시작'하고, 마우스가 '움직이다가', '놓았을' 때 API를 호출하라") **RxJS**가 강력합니다.
- **상태**와 **파생 상태**를 관리하고, 이 상태 변경이 UI에 **즉각적이고 빠르게** 반영되어야 한다면(예: React의 `useState` + `useMemo` + `useEffect` 조합을 대체) **Signals**가 훌륭한 해답입니다.

------


### 18.4. 결론: 'Push' vs 'Pull'의 선택


제2부~제3부에서 배운 Redux, Zustand, `createEntityAdapter`는 모두 'Pull' 기반입니다. UI가 스토어에서 데이터를 가져옵니다.

이번 장에서 배운 RxJS와 Signals는 'Push' 기반입니다. 데이터(이벤트 또는 상태)가 변경을 UI로 밀어 넣습니다.

데이터 지향 프로그래밍은 이 두 가지 모델을 모두 포괄합니다. 로직을 데이터로부터 분리하고(1~3장), 데이터를 정규화하며(4장), 데이터의 흐름을 파이프라인으로 정의하는(2장) 원칙은 동일합니다.

'Push' 기반의 반응형 데이터 플로우는 '명령'을 내리는 주체를 개발자에서 '데이터' 그 자체로 넘김으로써, 더욱 선언적이고 자동화된 아키텍처를 가능하게 합니다.

------

네, 알겠습니다. 제5부 '실용적인 기법들'의 '반응형 데이터 플로우' 섹션 두 번째 장이자, 앞선 18장의 논의를 아키텍처 레벨에서 종합하는 'Push vs Pull 기반 아키텍처' 집필을 시작하겠습니다.

------


## 19. 반응형 데이터 플로우 - Push vs Pull 기반 아키텍처


> "데이터는 가만히 있는가, 아니면 흐르는가? 이 질문에 대한 당신의 대답이 당신의 아키텍처를 결정한다. Pull 아키텍처는 세상을 스냅샷의 연속으로 보지만, Push 아키텍처는 세상을 이벤트의 강물로 본다."

제18장에서 우리는 RxJS와 Signals라는 'Push' 기반 패러다임을 탐구했습니다. 이들은 데이터가 변경되었을 때, 데이터를 '밀어 넣어(Push)' 소비자에게 알리는 방식을 사용합니다. 이는 우리가 책의 1부부터 4부까지 주로 다뤄온 React/Redux의 'Pull' 기반 방식과 근본적으로 대조됩니다.

`UI = f(State)`라는 공식은 두 가지 방식으로 해석될 수 있습니다.

1. **Pull (끌어오기)**: `State`가 변경되면, `f`(컴포넌트) 전체를 다시 실행하라고 '알린다'. 그러면 `f`가 실행되면서 필요한 `State` 값을 저장소에서 **'끌어온다(Pull)'**. (React/Redux/Zustand)
2. **Push (밀어넣기)**: `State`(Signal)가 변경되면, 그 `State`를 구독하는 `f`의 '일부'(Effect)에게 변경된 값을 **'밀어 넣는다(Push)'**. (Signals/RxJS/SolidJS)

이 '데이터 흐름'의 방향성은 프론트엔드 아키텍처의 성능, 복잡성, 그리고 개발자 경험을 결정하는 가장 중요한 설계적 결정입니다. 본 장에서는 이 두 아키텍처의 핵심 메커니즘과 트레이드오프를 데이터 지향적 관점에서 심층적으로 비교 분석합니다.

------


### 19.1. Pull 기반 아키텍처: React의 세계관


Pull 아키텍처는 React 생태계의 표준 모델입니다. 데이터 흐름은 단방향으로 흐르며, '상태'는 수동적인 존재입니다.


#### 19.1.1. 작동 메커니즘


1. **트리거 (Trigger)**: 사용자가 버튼을 클릭하거나 `useEffect`가 실행되어 `setState` 또는 Redux `dispatch`가 호출됩니다.
2. **'더럽힘' (Marking Dirty)**: `setState`는 컴포넌트를 '더럽다(Dirty)'고 표시합니다. Redux `dispatch`는 스토어의 SSoT 참조를 변경하고, 구독 중인 모든 컴포넌트(예: `useSelector` 사용자)를 '더럽다'고 표시합니다.
3. **재조정 (Reconciliation)**: React 스케줄러가 '더러운' 컴포넌트의 `render` 함수(`f`)를 **재실행(Re-run)**합니다.
4. **데이터 '끌어오기' (Pull)**:
   - 재실행된 컴포넌트는 `useState`에서 최신 값을 읽습니다.
   - `useSelector(state => state.entities.users[id])` 같은 셀렉터(제6장, 제17장)가 실행되어, SSoT에서 **필요한 데이터를 '끌어옵니다'.**
5. **VDOM 비교 (Diffing)**: 반환된 JSX(가상 DOM)와 이전 JSX를 비교합니다.
6. **커밋 (Commit)**: 변경된 부분만 실제 DOM에 적용(패치)합니다.


#### 19.1.2. Pull 아키텍처의 데이터 지향적 분석


- **장점 (Pros)**:
  - **단순한 정신 모델**: 데이터 흐름이 항상 `Top-down`(위에서 아래로)으로 명확합니다.
  - **예측 가능성**: `render` 함수는 SSoT(상태)를 기반으로 '현재' 뷰를 선언하는 순수 함수(제1장)로 취급될 수 있습니다.
  - **강력한 SSoT**: SSoT(제5장)와 '파생 상태(셀렉터)'(제6장)의 구분이 명확합니다. `createEntityAdapter`(제17장) 같은 정규화된 SSoT를 관리하기에 용이합니다.
- **단점 (Cons)**:
  - **과잉 실행 (Over-execution)**: `setState`는 기본적으로 컴포넌트 '전체'를 재실행시킵니다. 부모가 리렌더링되면 자식도 리렌더링됩니다.
  - **VDOM의 오버헤드**: '변경 사항 찾기'라는 비교(Diffing) 작업 자체가 비용입니다. 상태가 변하지 않았어도, VDOM은 일단 생성되고 비교되어야 합니다.
  - **수동 최적화의 필요성**: 이 과잉 실행을 막기 위해 개발자가 `React.memo`, `useMemo`, `useCallback`을 '수동으로' 추가하여 최적화해야 합니다. 이는 번거롭고 실수하기 쉽습니다.
  - **'느슨한' 의존성**: `useEffect`의 의존성 배열(`deps`)은 개발자가 '수동으로' 관리해야 합니다. `useSelector`는 상태의 '어떤 조각'이 변했는지 정확히 알지 못하고, 참조가 변경되면 일단 재실행합니다.

**Pull 아키텍처는 "일단 다시 실행하고(Pull), VDOM으로 차이를 걸러낸다"는 접근 방식입니다.**

------


### 19.2. Push 기반 아키텍처: 반응형의 세계관


Push 아키텍처는 데이터가 능동적인 존재가 됩니다. 데이터가 '자신을 구독하는 소비자'를 정확히 알고 있다가, 변경이 발생하면 '직접' 알립니다.


#### 19.2.1. 작동 메커니즘 (Signals 기준)


1. **구독 (Subscription)**: `effect`나 `computed` 함수가 실행되는 동안, 내부에서 접근(`signal.value`)하는 모든 Signal은 **자동으로 이 함수를 '구독자'로 등록**합니다. (자동 의존성 추적)
   - `effect(() => console.log(firstName.value))`는 `firstName` Signal을 구독합니다.
2. **트리거 (Trigger)**: `firstName.value = 'John'`처럼 Signal의 `setter`가 호출됩니다.
3. **'밀어넣기' (Push)**:
   - `firstName` Signal은 자신의 '구독자 목록'(위의 `effect` 함수)을 순회합니다.
   - "내가 변했으니 너도 다시 실행해야 해"라고 **변경 알림을 '밀어 넣습니다'.**
4. **세밀한 실행 (Fine-grained Execution)**:
   - **오직** `firstName`을 구독한 `effect` 함수만 정확하게 재실행됩니다.
   - `lastName` Signal을 구독한 다른 `effect`는 전혀 실행되지 않습니다.
   - SolidJS 같은 프레임워크에서는, 이 `effect`가 컴포넌트 '전체'가 아니라 `<h1>{firstName()}</h1>`라는 **DOM 노드의 `textContent`를 직접 수정**하는 작업에 바인딩됩니다.


#### 19.2.2. Push 아키텍처의 데이터 지향적 분석


- **장점 (Pros)**:
  - **최고의 성능 (Surgical Precision)**: VDOM이 필요 없습니다. "데이터 → DOM 노드"로의 직접적인 업데이트가 가능합니다. 상태 변경과 무관한 코드는 1바이트도 실행되지 않습니다.
  - **자동 의존성 추적**: `useMemo`나 `useCallback`, `deps` 배열이 필요 없습니다. 시스템이 의존성을 100% 자동으로 완벽하게 추적합니다.
  - **자연스러운 파생 상태**: `computed`는 파생 상태(제6장)를 만드는 가장 자연스럽고 효율적인 방법입니다.
  - **데이터가 '주체'가 됨**: 데이터 자체가 '반응성'을 가지므로, 데이터와 로직의 결합이 더 명확해집니다.
- **단점 (Cons)**:
  - **복잡한 디버깅**: Pull의 'Top-down' 흐름이 사라집니다. 변경은 의존성 그래프를 따라 '어디로든' 전파될 수 있습니다. "이 DOM은 왜 업데이트됐지?"를 추적하기가 더 까다로울 수 있습니다. (RxJS의 'Marble Diagram'이나 SolidJS의 DevTools가 이를 보완)
  - **"Glitch" 문제**: 파생 상태가 여러 단계로 얽혀있을 때(A → B → C), A가 변경되면 B와 C가 *순간적으로* 일관성이 깨지는 시점(Glitch)이 발생할 수 있습니다. (Signals는 이를 내부적으로 잘 처리하지만, RxJS에서는 복잡한 문제가 될 수 있음)
  - **학습 곡선**: RxJS는 매우 복잡합니다. Signals는 간단해 보이지만, '언제' 실행되는지 정확히 예측하는 것은 Pull 모델과 다른 사고방식을 요구합니다.

**Push 아키텍처는 "데이터가 변경되면, 구독자에게만 정확히 Push한다"는 접근 방식입니다.**

------


### 19.3. 비교: Pull vs Push


| **특징**        | **Pull (React)**                          | **Push (Signals / RxJS)**               |
| --------------- | ----------------------------------------- | --------------------------------------- |
| **데이터 흐름** | **Top-Down** (UI가 상태를 `Pull`)         | **Graph-Based** (데이터가 UI로 `Push`)  |
| **변경 감지**   | **VDOM Diffing** (느슨함)                 | **자동 구독** (세밀함)                  |
| **실행 단위**   | 컴포넌트 함수 (`f`)                       | 이펙트 / 구독자 (`effect`)              |
| **성능**        | 기본적으로 느리고, **수동 최적화** 필요   | 기본적으로 빠름 (Surgical Precision)    |
| **의존성 관리** | **수동** (`deps` 배열, `memo`, `useMemo`) | **자동** (실행 시 자동 추적)            |
| **파생 상태**   | **수동** (`useMemo`, `reselect`)          | **자동** (`computed`, `pipe(map(...))`) |
| **디버깅**      | 쉬움 (흐름이 명확)                        | 어려울 수 있음 (흐름이 암묵적)          |

------


### 19.4. 결론: 아키텍처는 '흐름'의 선택이다


데이터 지향 프로그래밍의 관점에서 Pull과 Push는 '데이터와 로직의 분리'라는 목표를 달성하는 두 가지 다른 경로입니다.

- **Pull (React/Redux/Zustand)**:
  - **데이터**: 거대하고 수동적인 SSoT (제4장 정규화 모델에 적합).
  - **로직**: `render` 함수와 `useSelector`라는 '읽기 시스템(Query System)'을 통해 데이터를 소비합니다.
  - **적합한 곳**: 상태가 복잡하게 얽혀있고, 데이터의 '전체적인 스냅샷'을 기반으로 뷰를 그리는 것이 더 쉬운 전통적인 CRUD 애플리케이션.
- **Push (Signals/RxJS/SolidJS)**:
  - **데이터**: 작고 능동적인 데이터 '원자(Atom)' 또는 '스트림'. (제7장 ECS의 개별 컴포넌트 데이터와 유사)
  - **로직**: `effect` 또는 `subscribe`라는 '쓰기 시스템(Subscriber)'을 통해 데이터를 소비합니다.
  - **적합한 곳**: 상태 변경이 매우 빈번하고(실시간 차트, 게임), 각 상태가 비교적 독립적이며, VDOM의 오버헤드조차 제거해야 하는 고성능 애플리케이션.

현대의 아키텍처는 이 둘을 **혼합(Hybrid)**하는 추세입니다. React(Pull)의 거대한 생태계와 컴포넌트 모델을 사용하되, 내부의 상태 관리는 Jotai나 Preact Signals(Push)를 사용하여 성능과 개발자 경험을 모두 잡으려는 시도가 늘고 있습니다.

어떤 아키텍처를 선택하든, 핵심은 **"데이터가 어떻게 흐르고(Flow), 어떻게 변환되며(Transform), 어떻게 소비되는지(Consume)"**를 명확하게 설계하는 것입니다.

------

네, 알겠습니다. 제5부 '실용적인 기법들'의 마지막 장, '변경 감지 최적화' 집필을 시작하겠습니다. 이 장은 18장, 19장에서 다룬 Pull/Push 모델이 '성능'과 만나는 지점, 즉 "프레임워크는 데이터 변경을 어떻게 감지하고, 우리는 그것을 어떻게 최적화하는가"에 대한 핵심입니다.

------


## 20. 반응형 데이터 플로우 - 변경 감지 최적화


> "최적화는 '더 빨리' 일하게 만드는 것이 아니다. '불필요한' 일을 하지 않도록 막는 것이다. 훌륭한 변경 감지 시스템은 데이터가 변경되지 않았다면, 코드의 1바이트도 실행하지 않는다."

제19장에서 우리는 Pull(React)과 Push(Signals)라는 두 가지 상반된 데이터 흐름 아키텍처를 비교 분석했습니다. 두 모델 모두 `UI = f(State)`라는 데이터 지향 공식을 따르지만, 그 '실행' 방식이 다릅니다.

- **Pull (React)**: `State`가 변하면 `f`(컴포넌트)를 다시 실행(Pull)하고, VDOM으로 차이를 걸러냅니다.
- **Push (Signals)**: `State`(Signal)가 변하면 `f`의 일부(Effect)에 변경 사항을 직접 밀어 넣습니다(Push).

이 '실행'의 중심에는 **"변경 감지(Change Detection, CD)"**라는 심장이 있습니다. CD는 데이터(State)의 변경을 감지하여 UI(DOM)에 반영하는 프레임워크의 핵심 메커니즘입니다. 그리고 이 메커니즘이 프론트엔드 성능의 90%를 결정합니다.

순진한(Naive) CD는 "데이터가 하나만 바뀌어도, 앱 전체를 다시 그린다"는 방식입니다. 이는 끔찍하게 비효율적입니다. 데이터 지향적 최적화의 목표는 이 작업량을 **`Work ∝ Change` (일의 양은 변경된 데이터의 양에 비례한다)**라는 이상적인 상태로 수렴시키는 것입니다.

본 장에서는 Pull 모델(React)의 수동 최적화 기법(`memo`, `useMemo`)과 Push 모델(Signals)의 자동 최적화 기법이 '데이터의 불변성' 및 '참조 동일성'과 어떻게 연결되는지 깊이 있게 탐구합니다.

------


### 20.1. Pull 모델의 숙명: 과잉 실행과 VDOM


React의 변경 감지 모델은 기본적으로 **"일단 실행하고, 나중에 비교한다"**는 접근 방식입니다.

1. `setState()`가 호출되면, React는 해당 컴포넌트와 그 *모든* 자식 컴포넌트들을 '더럽다(Dirty)'고 표시합니다.
2. React는 '더러운' 컴포넌트의 `render` 함수를 **모두 재실행(Pull)**합니다.
3. 이 과정에서 새로운 가상 DOM(VDOM) 트리가 생성됩니다.
4. 이전 VDOM 트리와 새로운 VDOM 트리를 **비교(Diffing)**합니다. (이것이 React의 핵심 CD 알고리즘입니다.)
5. 차이가 발견된 부분만 실제 DOM에 적용(Patch)합니다.

데이터 지향적 문제점:

이 모델은 "데이터가 정확히 어떻게 변했는지"는 관심 없고, " 어쨌든 변했으니" 컴포넌트 함수(f)를 다시 실행합니다. props.user.name만 바뀌었음에도, props.user를 받지 않는 자식 컴포N트까지 render 함수가 재실행될 수 있습니다.

이 **'과잉 실행(Over-execution)'**이 React 성능 저하의 주범입니다. VDOM Diffing은 빠르지만, 애초에 `render` 함수를 실행하고 VDOM 객체를 생성하는 것 자체가 비용입니다.

------


### 20.2. Pull 모델 최적화: `React.memo`와 불변성


이 과잉 실행을 막기 위해 React는 `React.memo`라는 '탈출구'를 제공합니다.

`React.memo`는 컴포넌트를 감싸는 HOC(Higher-Order Component)로, 컴포넌트에게 **"props가 변경되지 않았다면, `render` 함수 재실행을 건너뛰어라(Skip)"**라는 지시를 내립니다.

```typescript
function UserProfile({ user }) {
  // ... (이 컴포넌트는 매우 '비싼' 렌더링 로직을 가짐)
}
// 💥 props가 '얕은 비교(shallow equal)'로 동일하다면
// 💥 'UserProfile' 함수의 재실행 자체를 막는다.
const MemoizedUserProfile = React.memo(UserProfile);
```

React.memo는 prevProps.user === nextProps.user처럼 **얕은 비교(Shallow Comparison)**를 수행합니다.

여기서 제1장에서 배운 **'불변성(Immutability)'**이 결정적인 역할을 합니다.

**[나쁜 예: 데이터의 가변성(Mutation)]**

```typescript
// 부모 컴포넌트
function Parent() {
  const [user, setUser] = useState({ id: 1, name: 'Alice' });

  const handleRename = () => {
    // 👎 최악의 실수: 원본 객체를 직접 수정 (Mutation)
    user.name = 'Bob'; 
    setUser(user); // React는 참조(user)가 같아서 변경을 감지 못할 수도 있음 (버그)
                   // (강제로 리렌더링한다 해도...)
  };

  // ... 'user' 객체의 *참조*는 동일
  return <MemoizedUserProfile user={user} />;
}
```

`handleRename`이 실행되어도 `user` 객체의 메모리 주소(참조)는 동일합니다. `React.memo`는 `prevProps.user === nextProps.user`가 `true`라고 판단하여, `UserProfile`의 재실행을 막아버립니다. **UI는 'Alice'에 머물러 있습니다.**

**[좋은 예: 데이터의 불변성(Immutability)]**

```typescript
// 부모 컴포넌트
function Parent() {
  const [user, setUser] = useState({ id: 1, name: 'Alice' });

  const handleRename = () => {
    // 👍 좋은 방식: '새로운' 객체 생성 (Immutability)
    const newUser = { 
      ...user, 
      name: 'Bob' 
    };
    setUser(newUser);
  };

  // ... 'user' prop이 *새로운 참조*로 교체됨
  return <MemoizedUserProfile user={user} />;
}
```

`handleRename`이 실행되면 `newUser`라는 **새로운 객체 참조**가 생성됩니다. `React.memo`는 `prevProps.user === nextProps.user`가 `false`임을 즉시 감지하고, `UserProfile`을 *올바르게* 재실행하여 UI를 'Bob'으로 갱신합니다.

**결론:** 데이터 지향 원칙(불변성) 없이는 `React.memo`라는 변경 감지 최적화가 불가능합니다.

------


### 20.3. Pull 모델 최적화: `useMemo`, `useCallback`과 참조 동일성


`React.memo`는 완벽하지 않습니다. 부모가 리렌더링될 때 `props`가 *항상* 새로운 참조가 된다면 `React.memo`는 무용지물이 됩니다.

**[가장 흔한 '최적화 실패' 시나리오]**

```typescript
function Parent() {
  const [count, setCount] = useState(0); // 'user'와 관련 없는 상태

  // 1. 'user' 객체가 매 렌더링마다 '새로' 생성됨
  const user = { id: 1, name: 'Alice' }; 

  // 2. 'handleClick' 함수가 매 렌더링마다 '새로' 생성됨
  const handleClick = () => {
    console.log('Clicked user', user.id);
  };

  return (
    <div>
      {/* 'count'가 변경되어 Parent가 리렌더링되면, 
          'user'와 'handleClick'이 새 참조가 되어 
          'MemoizedUserProfile'은 '항상' 재실행된다. 👎 */}
      <button onClick={() => setCount(c => c + 1)}>Increment Count</button>
      <MemoizedUserProfile user={user} onClick={handleClick} />
    </div>
  );
}
```

관련 없는 `count`가 변경되었을 뿐인데, `user`와 `handleClick`의 **참조 동일성(Referential Integrity)**이 깨졌기 때문에 `React.memo`가 실패합니다.

데이터 지향적 해결책:

"함수와 객체도 '데이터'로 취급하라. 그리고 이 '파생 데이터'를 **캐싱(메모이제이션)**하라."

이 역할을 하는 것이 useMemo와 useCallback입니다.

**[좋은 예: 참조 동일성 보장]**

```typescript
function Parent() {
  const [count, setCount] = useState(0);

  // 1. 'user' 객체를 'useMemo'로 캐싱
  //    '[]'(의존성 배열)이 비어있으므로, 이 객체는 컴포넌트 생명주기 동안
  //    '단 하나의 참조'만 갖게 된다.
  const user = useMemo(() => ({ id: 1, name: 'Alice' }), []);

  // 2. 'handleClick' 함수를 'useCallback'으로 캐싱
  //    (useCallback은 useMemo(fn, deps)의 단축형)
  const handleClick = useCallback(() => {
    console.log('Clicked user 1'); // (user.id 대신 1을 사용하거나, user를 deps에 추가)
  }, []); // '[]' 의존성 배열

  return (
    <div>
      {/* 'count'가 변경되어 Parent가 리렌더링되어도,
          'user'와 'handleClick'은 *동일한 참조*를 유지한다.
          'MemoizedUserProfile'은 재실행되지 않는다. 👍 */}
      <button onClick={() => setCount(c => c + 1)}>Increment Count</button>
      <MemoizedUserProfile user={user} onClick={handleClick} />
    </div>
  );
}
```

`useMemo`와 `useCallback`은 '비싼 계산'을 피하기 위해서가 아니라 (물론 그것도 맞지만), Pull 기반 CD 시스템에서 **'참조 동일성'을 유지하여 `React.memo`의 얕은 비교를 통과시키기 위한** 핵심적인 데이터 지향 도구입니다.

------


### 20.4. Push 모델의 '자동 최적화'


이제 제18장, 19장에서 배운 **Signals**의 세계로 돌아와 봅시다. Signals에는 `React.memo`, `useMemo`, `useCallback`이 **필요 없습니다.**

왜일까요? Signals의 변경 감지(CD)는 'Pull'이 아닌 'Push'이며, VDOM이 아닌 '데이터'에 바인딩되기 때문입니다.

```typescript
// (SolidJS 또는 @preact/signals-core)

// 1. '데이터(Signal)' 생성
const count = signal(0);
const user = signal({ id: 1, name: 'Alice' });

// 2. '파생 데이터(Computed)' 생성 (useMemo와 동일)
const userName = computed(() => user.value.name);

// 3. '이펙트(Effect)' 생성 (UI 렌더링과 동일)
//    'effect'는 'count'와 'userName'을 *자동으로 구독*
effect(() => {
  console.log(`Count: ${count.value}, Name: ${userName.value}`);
});

// --- 시스템 실행 ---

// 1. count 변경
count.value = 1;
// 출력: "Count: 1, Name: Alice"
// (count를 구독한 effect만 정확히 1번 실행)

// 2. user 객체의 '참조'를 변경
user.value = { id: 1, name: 'Bob' };
// 출력: "Count: 1, Name: Bob"
// (user -> userName -> effect로 Push가 전달되어 1번 실행)

// 3. 💥 아무것도 변경하지 않음 (React의 'setState({})'와 유사)
user.value = user.value;
// 출력: (아무것도 없음!)
// (Signal의 setter가 내부적으로 'prev === next'를 검사하여
//  값이 같으면 Push 자체를 막음. CD가 0초 걸림)
```

Signals의 변경 감지는 **'자동'**이고 **'외과수술처럼 정확(Surgical)'**합니다.

- **'데이터(Signal)'**가 '자신을 구독하는 `effect`'를 정확히 알고 있습니다.
- `count`가 변경되면, `userName`을 계산하는 `computed`는 재실행되지 않습니다.
- `user`가 변경되면, `count`를 로그하는 `effect`는 재실행되지 않습니다.

VDOM 비교라는 '추측성' 작업이 없습니다. 오직 **데이터 의존성 그래프(Data Dependency Graph)**를 따라 필요한 곳에만 `Push`가 발생합니다. 이것이 Push 모델의 '기본값(Default)'이 '최적화된(Optimized)' 상태인 이유입니다.

------


### 20.5. 결론: 최적화는 '데이터'를 이해하는 것


'변경 감지 최적화'는 프레임워크의 마법이 아니라, **'데이터'의 흐름과 '참조'를 통제**하는 데이터 지향 프로그래밍의 실천입니다.

- **Pull 아키텍처 (React)**:
  - **문제**: '과잉 실행'이 기본값.
  - **최적화**: 개발자가 **수동으로** 최적화를 수행해야 함.
  - **핵심 도구**: **불변성**을 통한 SSoT 관리, `React.memo`로 재실행 방지, `useMemo`/`useCallback`으로 **참조 동일성** 보장. 이 모든 것이 **데이터 중심(Data-Oriented)** 사고를 요구합니다.
- **Push 아키텍처 (Signals)**:
  - **문제**: (성능이 아닌) 디버깅 복잡성.
  - **최적화**: **자동으로** 내장되어 있음.
  - **핵심 도구**: 'Signal'이라는 데이터 구조 자체가 '변경 감지' 시스템입니다. **데이터가 곧 CD입니다.**

데이터 지향 개발자는 `useMemo`를 남용하는 사람이 아니라, Pull 기반 시스템에서 왜 `useMemo`가 *필요한지* 그 '데이터'의 근본 원리(참조 동일성)를 이해하고, Push 기반 시스템에서는 왜 그것이 *필요 없는지* 아는 사람입니다.

------

네, 알겠습니다. 드디어 '고급 주제'인 제6부에 오셨군요. 이 책의 대미를 장식할, 데이터 지향 프로그래밍의 최전선에 있는 'CRDTs와 로컬 우선 소프트웨어'의 첫 번째 장을 시작하겠습니다.

------


## 21. CRDTs와 로컬 우선 소프트웨어 - Conflict-free Replicated Data Types 이해


> "진정한 SSoT(Single Source of Truth)가 서버에 있다면, 인터넷이 끊기는 순간 당신의 앱은 진실을 잃는다. '로컬 우선'은 진실의 주권을 사용자에게 돌려주는 것이며, CRDT는 서로 다른 진실들이 만나 평화를 이루는 헌법이다."

이 책의 1부부터 5부까지, 우리는 '하나의' SSoT를 가정했습니다. React의 `useState`든, Redux/Zustand 스토어(제4, 5장)든, 심지어 서버 데이터베이스든, 애플리케이션의 '진실'은 단 한 곳에 존재했습니다.

하지만 현대 애플리케이션은 이 가정을 무너뜨리고 있습니다.

- **실시간 협업 (Figma, Google Docs, Notion)**: User A와 User B가 *동시에* 같은 문서를 편집합니다. A의 SSoT와 B의 SSoT, 두 개의 '진실'이 존재합니다.
- **오프라인 우선 (Offline-First)**: 비행기 모드에서도 작동하는 앱(예: Todoist)은 인터넷 연결 없이도 로컬에서 데이터를 수정합니다. '로컬 SSoT'와 '서버 SSoT'라는 두 개의 '진실'이 존재합니다.

이 '분산된 진실'들이 다시 온라인이 되어 만났을 때, **'충돌(Conflict)'**이 발생합니다. User A는 문단의 1번 줄을 삭제했고, User B는 1번 줄에 오타를 수정했습니다. 둘 다 맞는 작업을 했습니다. **누구의 변경을 '승자'로 할 것인가?**

이 문제를 해결하기 위한 패러다임이 **'로컬 우선 소프트웨어(Local-First Software)'**이며, 이를 구현하는 핵심 '데이터 구조'가 바로 **CRDT (Conflict-free Replicated Data Types)**입니다. 본 장에서는 이 데이터 지향의 최전선에 있는 CRDT의 기본 원리를 탐구합니다.

------


### 21.1. '로컬 우선(Local-First)' 패러다임: 왜 필요한가?


전통적인 웹 앱은 **'서버 우선(Server-First)'**입니다. SSoT는 서버 DB에 있으며, 프론트엔드는 그 데이터를 빌려와(캐시) 보여주는 '멍청한 터미널'에 불과합니다. 인터넷이 끊기면 앱은 멈춥니다.

**로컬 우선(Local-First)**은 이 관계를 뒤집습니다.

1. **SSoT는 로컬(사용자 기기)이다**: 앱의 기본 SSoT는 `IndexedDB`나 `localStorage` 같은 로컬 저장소입니다.
2. **즉각적인 반응성**: 모든 읽기/쓰기 작업이 로컬에서 즉시($O(1)$) 발생합니다. 네트워크 대기 시간(latency)이 '0'입니다. UI는 항상 즉각적으로 반응합니다.
3. **오프라인 완벽 지원**: 인터넷 연결은 '부가 기능'입니다.
4. **동기화**: 인터넷이 연결되면, 로컬 SSoT는 다른 피어(Peer)나 서버와 데이터를 '동기화(Sync)'합니다.

이 모델은 완벽해 보이지만, 4번 '동기화' 단계에서 위에서 언급한 '충돌' 문제가 발생합니다. "어떻게 하면 중앙 서버의 중재 없이도, 두 개의 서로 다른 변경 사항을 *충돌 없이* 병합할 수 있을까?"

------


### 21.2. 충돌의 본질: 왜 `JSON.parse()`는 실패하는가


단순한 상태 병합이 왜 실패하는지, 공유 '할 일 목록' 예제로 살펴봅시다.

```typescript
// 초기 상태 (서버와 로컬 모두 동일)
let state_shared = ['A', 'B'];
```

두 사용자가 오프라인 상태에서 각자 작업합니다.

**User 1 (로컬)**: 'C'를 추가

```typescript
let state_user1 = ['A', 'B', 'C'];
```

**User 2 (로컬)**: 'A'를 삭제

```typescript
let state_user2 = ['B'];
```

이제 두 사용자가 온라인이 되어 동기화합니다.

- `User 1`이 `User 2`의 상태(`['B']`)를 받아서 덮어쓰면? `User 1`의 'C' 추가 작업이 **사라집니다.**
- `User 2`가 `User 1`의 상태(`['A', 'B', 'C']`)를 받아서 덮어쓰면? `User 2`의 'A' 삭제 작업이 **사라집니다.**
- 'Git 3-Way Merge'처럼 복잡한 병합을 시도해도, "C를 추가하고 A를 삭제"하는 것이 올바른지, "A를 삭제하고 C를 추가"하는 것이 올바른지 '의도'를 알 수 없습니다.

이것이 **데이터 충돌**입니다. 전통적인 데이터 구조(Array, Object)는 '상태'만 기록할 뿐, '의도(Operation)'를 기록하지 않기 때문에 충돌을 해결할 수 없습니다.

------


### 21.3. CRDT: 충돌 없는 데이터 구조


CRDT는 이 문제를 '데이터 구조' 레벨에서 해결합니다. "어떤 순서로 병합(merge)하든, 항상 수학적으로 동일한 결과에 도달하는" 데이터 구조를 만드는 것입니다.

CRDT `merge` 함수는 다음 세 가지 수학적 속성을 만족해야 합니다.

1. **교환법칙 (Commutative)**: `merge(A, B) === merge(B, A)`
   - (A가 B를 받든, B가 A를 받든 결과는 같다.)
2. **결합법칙 (Associative)**: `merge(A, merge(B, C)) === merge(merge(A, B), C)`
   - (누가 먼저 병합되든 결과는 같다.)
3. **멱등성 (Idempotent)**: `merge(A, A) === A`
   - (같은 데이터를 여러 번 병합해도 결과는 같다.)

이 세 가지가 보장되면, 네트워크 지연으로 인해 메시지(변경 사항)가 순서 없이, 또는 중복되어 도착하더라도 모든 사본(Replica)은 **결국(Eventually)** 동일한 상태로 **수렴(Converge)**합니다. (이를 **'강력한 최종 일관성(Strong Eventual Consistency)'**이라 합니다.)

------


### 21.4. CRDT의 종류와 TypeScript 예제


CRDT는 크게 두 가지 유형이 있습니다.

1. **State-based (CvRDTs - Convergent Replicated Data Types)**
   - "전체 상태"를 주고받습니다.
   - 병합(Merge) 함수는 두 개의 상태를 받아 새로운 상태를 만듭니다.
   - 구현이 비교적 간단합니다.
2. **Operation-based (CmRDTs - Commutative Replicated Data Types)**
   - "변경 작업(Operation)"만 주고받습니다. (제10장 '이벤트 소싱'과 매우 유사!)
   - "A를 추가하라", "B를 삭제하라"는 '이벤트'를 전송합니다.
   - 네트워크 오버헤드가 적지만, 모든 이벤트가 '정확히 한 번' 전달됨을 보장하는 메시징 시스템이 필요합니다.


#### 21.4.1. 예제 1: G-Counter (Grow-Only Counter) (CvRDT)


'좋아요' 개수처럼 절대 줄어들지 않는 카운터입니다.

- **데이터 구조**: 각 노드(사용자)의 ID를 키로 하는 `Map<NodeID, number>`
- **로직**:
  - **Increment**: 자신의 노드 ID에 해당하는 값만 1 증가시킵니다.
  - **Merge**: 두 맵을 합칠 때, 각 키에 대해 '더 큰(max)' 값을 선택합니다.
  - **Value**: 맵의 모든 값을 합산합니다.

```typescript
// G-Counter (State-based)
type GCounter = Record<string, number>;

// Node A (로컬 SSoT)
let nodeA: GCounter = { 'nodeA': 0, 'nodeB': 0 };
// Node B (로컬 SSoT)
let nodeB: GCounter = { 'nodeA': 0, 'nodeB': 0 };

// --- 로컬 작업 (오프라인) ---
// User A가 '좋아요' 2번 클릭
nodeA['nodeA'] = 2; // { 'nodeA': 2, 'nodeB': 0 }

// User B가 '좋아요' 1번 클릭
nodeB['nodeB'] = 1; // { 'nodeA': 0, 'nodeB': 1 }

// --- 병합 함수 (수학적 보장) ---
function mergeGCounter(a: GCounter, b: GCounter): GCounter {
  const allKeys = new Set([...Object.keys(a), ...Object.keys(b)]);
  const merged: GCounter = {};
  for (const key of allKeys) {
    // 💥 각 키의 '최대값'을 취한다 (핵심)
    merged[key] = Math.max(a[key] || 0, b[key] || 0);
  }
  return merged;
}

// --- 동기화 (순서 무관) ---
// 1. A가 B의 상태를 머지
const mergedA = mergeGCounter(nodeA, nodeB); 
// mergedA = { 'nodeA': 2, 'nodeB': 1 }

// 2. B가 A의 상태를 머지
const mergedB = mergeGCounter(nodeB, nodeA); // 💥 교환법칙 성립!
// mergedB = { 'nodeA': 2, 'nodeB': 1 }

// 3. 최종 값 읽기
const totalValue = (state: GCounter) => Object.values(state).reduce((s, v) => s + v, 0);
console.log(totalValue(mergedA)); // 3
console.log(totalValue(mergedB)); // 3
// (충돌 없이 '3'이라는 동일한 값으로 수렴!)
```


#### 21.4.2. 예제 2: 2P-Set (Two-Phase Set) (CvRDT)


'삭제' 기능을 가진 Set입니다. (21.2의 할 일 목록 문제 해결)

- **데이터 구조**: `additions: Set<T>`와 `tombstones: Set<T>` (묘비)라는 두 개의 G-Set.
- **로직**:
  - **Add**: `additions` Set에만 추가합니다.
  - **Remove**: `tombstones` Set에 추가합니다. (데이터를 실제로 지우지 않음!)
  - **Rule**: `tombstones`에 한 번 추가된 항목은 `additions`에 다시 추가될 수 없습니다.
  - **Merge**: 두 2P-Set의 `additions`를 합집합(Union)하고, `tombstones`를 합집합합니다.
  - **Value**: `additions - tombstones` (차집합)

```typescript
// 2P-Set (State-based)
interface TwoPhaseSet<T> {
  adds: Set<T>;
  tombstones: Set<T>;
}

// 초기 상태
const initialSet = (): TwoPhaseSet<string> => ({ adds: new Set(), tombstones: new Set() });
let state_user1 = initialSet();
state_user1.adds.add('A'); state_user1.adds.add('B'); // ['A', 'B']

let state_user2 = { ...state_user1 }; // 복제

// --- 로컬 작업 (오프라인) ---
// User 1: 'C' 추가
state_user1.adds.add('C'); 
// state_user1.adds = {'A', 'B', 'C'}

// User 2: 'A' 삭제 (묘비 추가)
// (삭제는 'A'가 'adds'에 있는지 확인 후 'tombstones'에 추가)
if (state_user2.adds.has('A')) {
  state_user2.tombstones.add('A');
}
// state_user2.adds = {'A', 'B'}, state_user2.tombstones = {'A'}

// --- 병합 함수 ---
function merge2PSet<T>(a: TwoPhaseSet<T>, b: TwoPhaseSet<T>): TwoPhaseSet<T> {
  return {
    // 💥 양쪽의 '추가'를 모두 합친다
    adds: new Set([...a.adds, ...b.adds]),
    // 💥 양쪽의 '삭제'를 모두 합친다
    tombstones: new Set([...a.tombstones, ...b.tombstones]),
  };
}

// --- 동기화 ---
const mergedState = merge2PSet(state_user1, state_user2);
// mergedState.adds = {'A', 'B', 'C'}
// mergedState.tombstones = {'A'}

// --- 최종 값 읽기 ---
function getValue<T>(state: TwoPhaseSet<T>): Set<T> {
  return new Set([...state.adds].filter(item => !state.tombstones.has(item)));
}

console.log(getValue(mergedState)); // Set { 'B', 'C' }
```

`['B', 'C']`라는 최종 상태는 User 1의 'C 추가' 의도와 User 2의 'A 삭제' 의도를 **둘 다 정확하게 반영**합니다. 충돌이 발생하지 않았습니다.

------


### 21.5. Yjs, Automerge: 실용적인 CRDTs


G-Counter와 2P-Set는 기본 원리입니다. '실시간 텍스트 공동 편집' (User A가 5번 인덱스에 삽입, User B가 3번 인덱스 삭제) 같은 복잡한 문제는 **Yjs**나 **Automerge** 같은 전문 CRDT 라이브러리를 사용합니다.

이 라이브러리들은 텍스트, 배열, 맵(JSON)을 위한 고도로 최적화된 CRDT를 제공합니다. 이들은 '문자' 하나하나에 고유한 ID를 부여하거나, 작업(Operation) 자체를 CRDT로 취급하여 충돌 없이 병합합니다.

```typescript
// (Yjs 예시 - 개념적)
import * as Y from 'yjs';

// 1. Yjs 문서 생성 (CRDT 데이터 구조)
const ydocA = new Y.Doc();
const ydocB = new Y.Doc();

// 2. CRDT '텍스트' 타입 정의
const ytextA = ydocA.getText('shared-text');
const ytextB = ydocB.getText('shared-text');

// 3. 로컬 작업 (오프라인)
ytextA.insert(0, 'Hello'); // User A: "Hello"
ytextB.insert(0, 'World'); // User B: "World"

// 4. 동기화: A와 B는 '상태'가 아닌 '업데이트(Operation)'를 교환
// (이벤트 소싱과 동일!)
const updateA = Y.encodeStateAsUpdate(ydocA);
const updateB = Y.encodeStateAsUpdate(ydocB);

// 5. 병합: A는 B의 업데이트를 적용, B는 A의 업데이트를 적용
Y.applyUpdate(ydocA, updateB);
Y.applyUpdate(ydocB, updateA);

// 6. 결과 확인 (수렴)
console.log(ytextA.toString()); // "WorldHello" (또는 "HelloWorld", 순서는 보장됨)
console.log(ytextB.toString()); // "WorldHello" (A와 B의 결과가 동일!)
```

------


### 21.6. 결론: 데이터 구조가 곧 비즈니스 로직


CRDT는 데이터 지향 프로그래밍의 극단적인 형태입니다.

- '충돌 병합'이라는 복잡한 **비즈니스 로직(Logic)**이
- `merge`라는 순수 함수와 `G-Counter`라는 **데이터 구조(Data)** 안으로
- 완벽하게 **캡슐화**되었습니다.

로컬 우선 소프트웨어와 CRDT를 채택하는 것은, "서버가 모든 것을 안다"는 중앙집권적 사고에서 벗어나, "데이터가 스스로를 설명하고 병합할 수 있다"는 분산되고 민주적인 데이터 지향적 사고로의 전환을 의미합니다. 이는 오프라인 지원과 실시간 협업을 '부가 기능'이 아닌 '기본값'으로 만드는 강력한 아키텍처입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 두 번째 장, '오프라인 지원과 동기화' 집필을 시작하겠습니다. 이 장은 21장에서 배운 CRDT라는 '데이터 구조'가 어떻게 '로컬 우선'이라는 '아키텍처'로 구현되는지, 그 실용적인 설계와 데이터 흐름을 탐구합니다.

------


## 22. CRDTs와 로컬 우선 소프트웨어 - 오프라인 지원과 동기화


> "최고의 네트워크 요청은 아예 발생하지 않는 요청이다. '로컬 우선' 아키텍처는 네트워크를 '필수'가 아닌 '선택'으로 격하하며, 동기화는 '데이터를 가져오는' 작업이 아니라 '데이터를 공유하는' 파티가 된다."

제21장에서 우리는 CRDT(Conflict-free Replicated Data Types)라는 마법 같은 데이터 구조를 배웠습니다. CRDT는 여러 사용자가 동시에 데이터를 수정해도(심지어 오프라인에서!), 수학적 원리(교환, 결합, 멱등성)에 따라 충돌 없이 *항상* 동일한 상태로 수렴합니다.

이제 우리는 이 CRDT라는 '엔진'을 가지고 **'로컬 우선(Local-First)'**이라는 '자동차'를 실제로 조립해 볼 차례입니다.

'오프라인 지원'은 단순히 데이터를 캐싱했다가 나중에 서버에 보내는 '옵티미스틱 UI(Optimistic UI)'의 상위 개념이 아닙니다. 그것은 아키텍처의 근본적인 전환입니다. SSoT(단일 진실 공급원)가 서버에서 클라이언트(로컬)로 이동하고, '네트워크 동기화'는 제3장 '부수 효과 격리'에서 배운 '불순한 쉘(Impure Shell)'로 완벽하게 분리됩니다.

본 장에서는 '즉각적인 반응성'과 '100% 오프라인 작동'을 보장하는 로컬 우선 아키텍처의 4계층 스택과, CRDT를 활용한 '동기화 엔진(Sync Engine)'의 데이터 흐름을 상세하게 설계합니다.

------


### 22.1. 로컬 우선 아키텍처의 4계층


전통적인 서버 우선(Server-First) 앱이 `UI ↔ API Client ↔ Server DB`의 3계층이라면, 로컬 우선 앱은 명확한 4계층 스택을 가집니다.

1. **뷰 계층 (View Layer)**: `React`, `Vue` 등. 사용자에게 UI를 렌더링.
2. **애플리케이션 계층 (App Layer)**:
   - **SSoT(단일 진실 공급원)**: **로컬 데이터베이스** (예: `IndexedDB`, `SQLite`, `Realm`).
   - **데이터 구조**: **CRDTs** (예: `Yjs`, `Automerge` 문서). SSoT는 이 CRDT 데이터를 저장합니다.
   - 뷰 계층은 *오직* 이 SSoT하고만 통신합니다. 서버의 존재를 모릅니다.
3. **동기화 엔진 (Sync Engine)**:
   - '불순한 쉘(Impure Shell)'.
   - '애플리케이션 계층(로컬 SSoT)'과 '네트워크 계층' 사이의 중재자.
   - 백그라운드에서 실행됩니다. (예: Web Worker, Service Worker)
4. **네트워크 계층 (Network Layer)**:
   - `WebSocket`, `WebRTC` 또는 `HTTP`.
   - 다른 피어(Peer) 또는 '동기화 서버'와 CRDT 업데이트(이벤트)를 주고받습니다.

이 구조의 핵심은 **2계층(App)과 3계층(Sync)의 완벽한 분리**입니다. 뷰 계층은 "데이터를 수정해 줘"라고 로컬 SSoT에 명령할 뿐, 이 데이터가 어떻게, 언제 동기화되는지는 전혀 신경 쓰지 않습니다.

------


### 22.2. 데이터 흐름: 즉각적인 로컬 쓰기 (Local Write)


로컬 우선 앱에서 사용자 인터랙션은 '즉각적(Instant)'입니다.

**[데이터 흐름 1: 로컬 사용자 입력]**

1. **사용자 (UI)**: `User A`가 텍스트 에디터에 'A'를 입력합니다.
2. **뷰 계층 (React)**: `onClick` 핸들러가 `useMyDocument()` 훅의 `updateText('A')` 함수를 호출합니다.
3. **애플리케이션 계층 (Local SSoT)**:
   - `updateText('A')` 함수는 `Yjs` 같은 CRDT 문서에 `ytext.insert(0, 'A')` 명령을 실행합니다.
   - 이 변경 사항은 즉시 **로컬 `IndexedDB`에 저장(Persist)**됩니다.
4. **반응성 (Reactivity)**:
   - `useMyDocument()` 훅은 로컬 `Yjs` 문서의 `update` 이벤트를 구독하고 있습니다.
   - 로컬 SSoT가 변경되었으므로, 훅이 리렌더링을 트리거합니다.
   - UI가 'A'라는 텍스트를 즉시(0ms 지연) 렌더링합니다.

이 모든 과정은 **인터넷 연결과 100% 무관하게** 일어납니다. 이것이 '옵티미스틱(Optimistic) UI'가 아니라 **'리얼(Real) UI'**인 이유입니다.

------


### 22.3. 동기화 엔진: 백그라운드의 중재자


이제 '동기화 엔진'이 무대에 오릅니다. 이 엔진은 애플리케이션 계층과 네트워크 계층을 연결하는 '파이프'입니다.

```typescript
// (개념적 TypeScript 예제)

// --- 2. 애플리케이션 계층 (로컬 SSoT) ---
// (Yjs와 IndexedDB 지속성 어댑터 사용 가정)
import * as Y from 'yjs';
import { IndexeddbPersistence } from 'y-indexeddb';

const ydoc = new Y.Doc();
// 'ydoc'의 모든 변경 사항을 'my-doc-id' 키로 IndexedDB에 자동 저장
const persistence = new IndexeddbPersistence('my-doc-id', ydoc);


// --- 3. 동기화 엔진 (Sync Engine) ---
// (WebSocket 동기화 프로바이더 사용 가정)
import { WebsocketProvider } from 'y-websocket';

// 이 'provider'가 바로 동기화 엔진입니다.
// ydoc, WebSocket 서버 주소, 방(room) 이름을 전달
const wsProvider = new WebsocketProvider(
  'wss://my-sync-server.com',
  'my-doc-id',
  ydoc
);

// 💥 동기화 엔진의 두 가지 핵심 임무 💥

// 1. 로컬 SSoT(ydoc)가 변경되면 -> 네트워크(wsProvider)로 '업데이트'를 전송
// (y-websocket이 내부적으로 자동 처리)
// ydoc.on('update', (update: Uint8Array) => {
//   wsProvider.send(update);
// });

// 2. 네트워크(wsProvider)에서 '업데이트'를 받으면 -> 로컬 SSoT(ydoc)에 적용
// (y-websocket이 내부적으로 자동 처리)
// wsProvider.on('message', (remoteUpdate: Uint8Array) => {
//   // 💥 여기가 CRDT의 마법 💥
//   // 충돌 검사? 머지 로직? 필요 없습니다.
//   // 그냥 원격의 변경 사항을 '적용'하면, CRDT가 알아서 병합합니다.
//   Y.applyUpdate(ydoc, remoteUpdate);
// });
```

`y-websocket` 같은 라이브러리는 이 두 가지 임무를 캡슐화하여 제공합니다.

------


### 22.4. 데이터 흐름: 원격 동기화 (Remote Sync)


이제 `User B`가 다른 기기에서 동시에 작업하는 시나리오를 완성해 봅시다.

**[데이터 흐름 2: 원격 사용자 입력]**

1. **User B (다른 기기)**: 'B'를 입력합니다.
2. **User B의 앱**: (흐름 1과 동일) `User B`의 로컬 SSoT(`ydocB`)를 수정합니다.
3. **User B의 동기화 엔진**:
   - `ydocB`의 `update` 이벤트를 감지합니다.
   - 'B'를 추가하는 CRDT `updateB` 메시지를 `Sync Server`로 전송합니다.
4. **네트워크 (Sync Server)**:
   - `Sync Server`는 '방'에 연결된 모든 클라이언트(User A 포함)에게 `updateB` 메시지를 **단순히 중계(Relay)**합니다. (서버는 이 데이터가 'B'인지 알 필요도 없습니다. 제12장 CQRS의 '명령 버스'와 유사합니다.)
5. **User A의 동기화 엔진**:
   - `wsProvider`가 `updateB` 메시지를 수신합니다.
   - `Y.applyUpdate(ydocA, updateB)`를 호출합니다.
6. **User A의 애플리케이션 계층**:
   - `ydocA`의 상태가 변경됩니다. (CRDT가 'A'와 'B'를 충돌 없이 병합)
   - `ydocA`의 `update` 이벤트가 발생합니다.
7. **User A의 뷰 계층**:
   - `useMyDocument()` 훅이 `update` 이벤트를 감지합니다.
   - UI가 리렌더링되어 'AB' (또는 'BA', 순서는 CRDT가 보장)를 표시합니다.

핵심 통찰:

User A의 React 컴포넌트(useMyDocument 훅)는 '자신'이 'A'를 입력했을 때와 'Sync Engine'이 'B'를 입력했을 때를 전혀 구분하지 못합니다. 구분할 필요도 없습니다.

컴포넌트는 오직 **'로컬 SSoT가 변경되었다'**는 단 하나의 이벤트에만 반응합니다.

------


### 22.5. '동기화 서버'의 진정한 역할


이 아키텍처에서 '서버'는 전통적인 `REST API Server`가 아닙니다. SSoT가 아니며, 비즈니스 로직(제3장)도 없습니다.

동기화 서버의 역할은 두 가지뿐입니다.

1. **중계기 (Relay)**: 현재 온라인인 클라이언트 간에 CRDT 업데이트(이벤트)를 중계합니다. (WebSocket)
2. **백업 (Backup / Catch-up)**: 클라이언트가 오랫동안 오프라인이었다가 접속했을 때, 그동안 쌓인 다른 사람들의 변경 사항(`update` 묶음)을 전달해 줍니다. (또는 `ydoc`의 전체 스냅샷을 저장해 둠)

이는 서버의 복잡성을 극도로 낮추며, 서버는 '상태 비저장(Stateless)'이 되어 확장성(Scalability)이 매우 용이해집니다.

------


### 22.6. 결론: 신뢰할 수 있는 UI의 완성


'오프라인 지원'과 '동기화'는 데이터 지향 프로그래밍의 원칙을 통해 완벽하게 분리되고 자동화될 수 있습니다.

- **로컬 SSoT**는 UI에 **즉각적인 반응성**을 보장합니다. (데이터 지역성)
- **동기화 엔진**은 '네트워크'라는 **부수 효과**를 앱의 핵심 로직과 완벽하게 **격리**합니다. (제3장)
- **CRDTs**는 '동기화'라는 복잡한 **병합 로직**을 '데이터 구조' 자체에 **캡슐화**하여, 충돌을 원천적으로 제거합니다.

이로써 개발자는 '로딩 스피너'나 '네트워크 에러 모달'을 처리하는 대신, 사용자가 '지금 당장' 수행하는 작업의 비즈니스 로직에만 집중할 수 있습니다. 이것이 로컬 우선 아키텍처가 제공하는 진정한 가치입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 세 번째 장, 'Yjs, Automerge 활용 사례' 집필을 시작하겠습니다. 이 장에서는 21장, 22장에서 배운 CRDT와 로컬 우선 아키텍처를 구현하는 두 개의 가장 강력하고 대중적인 라이브러리를 실용적인 예제와 함께 비교 분석합니다.

------


## 23. CRDTs와 로컬 우선 소프트웨어 - Yjs, Automerge 활용 사례


> "이론은 구조를 제시하지만, 라이브러리는 전쟁을 치른다. Yjs와 Automerge는 수천 명의 동시 편집자와 불안정한 네트워크라는 실제 전장에서 CRDT 이론을 증명해낸 두 개의 검증된 무기이다."

제21장과 22장에서 우리는 '로컬 우선(Local-First)' 아키텍처의 청사진을 그렸습니다. SSoT를 로컬(`IndexedDB`)에 두고, 네트워크 동기화를 '부수 효과'로 분리하며, 'CRDT'라는 충돌 없는 데이터 구조를 통해 이 모든 것을 가능하게 하는 원리를 배웠습니다.

이제 우리는 이 강력한 이론을 실제 코드로 구현하는 두 개의 핵심 라이브러리, **Yjs**와 **Automerge**를 만나볼 차례입니다.

이 둘은 CRDT를 구현하는 방식과 개발자에게 제공하는 API가 근본적으로 다릅니다.

- **Yjs**: '성능'과 '모듈성'에 초점을 맞춘, 고도로 최적화된 바이너리 기반의 CRDT 구현체입니다.
- **Automerge**: '불변성(Immutability)'과 'JSON과 유사한' 데이터 모델에 초점을 맞춘, 함수형 프로그래밍과 React에 친화적인 구현체입니다.

본 장에서는 이 두 라이브러리의 핵심 철학과 아키텍처를 비교하고, React 애플리케이션에 각각을 통합하는 실용적인 활용 사례를 TypeScript 코드로 탐구합니다.

------


### 23.1. Yjs: 성능 최전선의 CRDT 엔진


Yjs는 실시간 협업 CRDT 라이브러리 생태계에서 사실상의 표준으로 통합니다. Figma, Tiptap, Notion 등 수많은 고성능 애플리케이션이 Yjs를 기반으로 합니다.

핵심 철학:

Yjs는 CRDT '데이터 구조' 자체보다는, CRDT '업데이트(Update)'를 생성하고 병합하는 **'작업(Operation)'**에 집중합니다. (CmRDT와 CvRDT의 하이브리드 접근 방식)

- **바이너리 프로토콜**: 모든 업데이트는 극도로 최적화된 바이너리 형식으로 인코딩됩니다. 이는 JSON 기반의 Automerge보다 네트워크 대역폭과 파싱 속도에서 압도적으로 유리합니다.
- **데이터 타입**: `Y.Doc`라는 '문서'가 SSoT(CRDT)입니다. 이 문서 안에 `Y.Text`, `Y.Array`, `Y.Map` 같은 공유 데이터 타입을 정의합니다.
- **관찰(Observe)**: Yjs 문서는 '가변적(Mutable)'입니다. `ytext.insert(0, 'A')`처럼 직접 수정합니다. 대신, `ydoc.on('update', ...)` 이벤트를 '구독(Subscribe)'하여 변경 사항을 감지합니다. (Push 모델, 제18장)
- **풍부한 생태계 (Providers)**: Yjs의 진정한 강점은 '동기화 엔진(제22장)'을 캡슐화한 '프로바이더(Provider)' 생태계입니다.
  - `y-websocket`: WebSocket 서버와 동기화
  - `y-webrtc`: 서버 없이 P2P로 동기화
  - `y-indexeddb`: 로컬 `IndexedDB`에 SSoT를 영속화 (로컬 우선)


#### 23.1.1. Yjs 활용 사례: React에서 실시간 상태 공유 훅


React(Pull 모델)와 Yjs(Push 모델)를 연결하려면 '브릿지(Bridge)'가 필요합니다. `useEffect`를 사용해 Yjs의 `update` 이벤트를 구독하고, React의 `useState`로 상태를 밀어 넣는 커스텀 훅을 만들 수 있습니다.

```typescript
// (Yjs와 프로바이더 설치 필요: npm install yjs y-websocket y-indexeddb)
import * as Y from 'yjs';
import { WebsocketProvider } from 'y-websocket';
import { IndexeddbPersistence } from 'y-indexeddb';
import { useEffect, useState, useMemo } from 'react';

// 1. Yjs SSoT(ydoc)와 프로바이더를 초기화하는 커스텀 훅
function useYjsDoc(roomId: string) {
  // Y.Doc은 한 번만 생성되어야 함 (useMemo 사용)
  const ydoc = useMemo(() => new Y.Doc(), []);

  useEffect(() => {
    // 2. 동기화 엔진 (Sync Engine) - 네트워크
    const wsProvider = new WebsocketProvider(
      'wss://my-sync-server.com',
      roomId,
      ydoc
    );

    // 3. 지속성 엔진 (Persistence Engine) - 로컬 SSoT
    const persistence = new IndexeddbPersistence(roomId, ydoc);
    
    // 4. 클린업: 컴포넌트 언마운트 시 모든 연결 해제
    return () => {
      wsProvider.disconnect();
      persistence.destroy();
    };
  }, [ydoc, roomId]);

  return ydoc;
}

// 2. Y.Map을 React 상태로 양방향 바인딩하는 훅
function useYjsMap<T>(yMap: Y.Map<T>): [Record<string, T>, (key: string, value: T) => void] {
  
  // Y.Map의 '현재 상태'를 React 'useState'로 복사 (Pull 모델용)
  const [mapState, setMapState] = useState(() => yMap.toJSON() as Record<string, T>);

  useEffect(() => {
    // 3. Yjs(Push) -> React(Pull) 브릿지
    // Y.Map이 '원격' 또는 '로컬'에서 변경될 때마다...
    const observer = () => {
      setMapState(yMap.toJSON() as Record<string, T>);
    };
    yMap.observe(observer);

    // 클린업
    return () => yMap.unobserve(observer);
  }, [yMap]);

  // 4. React(Pull) -> Yjs(Push) 브릿지
  // React UI가 SSoT(Yjs)를 변경하는 '명령(Command)'
  const setYMapEntry = (key: string, value: T) => {
    // 💥 로컬 SSoT(Yjs)에 직접 쓰기 (즉각적 반영)
    yMap.set(key, value);
    // (이 'set'은 위 'observer'를 트리거하여 'setMapState'를 호출,
    //  하지만 y-react 같은 바인딩은 이 로직을 더 최적화함)
  };

  return [mapState, setYMapEntry];
}

// 3. React 컴포넌트에서 사용
function CollaborativeComponent() {
  const doc = useYjsDoc('my-room');
  const sharedMap = doc.getMap<string>('shared-map');
  
  // 'useYjsMap' 훅을 통해 React 컴포넌트는 CRDT의 존재를 모름
  const [data, setData] = useYjsMap(sharedMap);

  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    // 💥 UI는 로컬 상태를 바꾸는 것처럼 '명령'만 내림
    setData('username', e.target.value);
  };

  return (
    <div>
      <p>다른 브라우저와 동기화됩니다:</p>
      <input value={data.username || ''} onChange={handleChange} />
      <pre>{JSON.stringify(data, null, 2)}</pre>
    </div>
  );
}
```

`CollaborativeComponent`는 `useYjsMap` 훅 뒤에 숨겨진 Yjs, WebSocket, IndexedDB의 복잡성을 전혀 알 필요가 없습니다. 이것이 바로 '로컬 우선' 아키텍처의 4계층(뷰/앱/동기화/네트워크)이 실제로 구현된 모습입니다.

------


### 23.2. Automerge: 불변성과 개발자 경험의 CRDT


Automerge는 Yjs와 완전히 다른 철학에서 출발했습니다. "CRDT를 다루는 것이 마치 Redux 스토어나 `immer`를 다루는 것처럼 느껴지게 만들 수는 없을까?"

핵심 철학:

Automerge는 '불변(Immutable)' 데이터 구조를 기반으로 합니다.

- **JSON-like 모델**: 데이터 SSoT는 `Automerge.init<T>()`로 생성된 `Doc<T>`입니다. 이 `Doc`은 일반적인 JavaScript 객체/배열처럼 보입니다.
- **불변성(Immutability)**: `Doc`을 수정하려면 `Automerge.change(doc, draft => { ... })` 함수를 사용해야 합니다. (Redux Toolkit의 `immer`와 API가 거의 동일!)
- **Change 함수**: 이 `change` 함수는 '이전 `doc`'을 기반으로 '새로운 `doc`' 객체를 반환합니다.
- **React 친화성**: 이 '새로운 참조'가 반환되는 모델은 `useState`와 완벽하게 호환됩니다. `setDoc(newDoc)`을 호출하면 React의 Pull 기반 변경 감지가 자동으로 동작합니다.


#### 23.2.1. Automerge 활용 사례: React `useState`와의 자연스러운 통합


```typescript
// (Automerge 설치 필요: npm install @automerge/automerge)
import * as Automerge from '@automerge/automerge';
import React, { useState, useEffect } from 'react';
// (Automerge 동기화를 위한 'Repo' 및 'NetworkAdapter' 필요)
// import { Repo } from '@automerge/automerge-repo';
// import { WebsocketClientAdapter } from '@automerge/automerge-repo-network-websocket';

interface MyDoc {
  text: string;
  tasks: { title: string; done: boolean }[];
}

// (Automerge 동기화/지속성을 위한 'Repo' 설정 - Yjs의 Provider와 유사)
// const repo = new Repo({
//   network: [new WebsocketClientAdapter('wss://my-automerge-server.com')],
//   storage: ... // (IndexedDB 어댑터)
// });

// React 컴포넌트
function AutomergeComponent() {
  // 1. Automerge 문서를 React 'useState'로 관리
  // (실제로는 'Repo'에서 'handle'을 받아 'useDocument' 훅을 사용)
  const [doc, setDoc] = useState(() => Automerge.init<MyDoc>());

  const handleAddTask = () => {
    // 2. 💥 'change' 함수로 SSoT(doc) 변경
    //    'immer'와 동일한 'draft' API 사용
    const newDoc = Automerge.change(doc, draft => {
      if (!draft.tasks) draft.tasks = [];
      draft.tasks.push({ title: 'New task', done: false });
    });
    
    // 3. 💥 React의 'setState'에 '새로운 참조'를 전달
    //    React의 Pull 기반 CD가 자동으로 트리거됨
    setDoc(newDoc);
  };
  
  // (동기화: 실제로는 'Repo'가 이벤트를 발생시키고
  //  'useDocument' 훅이 'setDoc'을 호출해 줌)
  // useEffect(() => {
  //   const handle = repo.find(docUrl);
  //   handle.on('change', (e) => setDoc(e.doc));
  //   ...
  // }, []);

  return (
    <div>
      <button onClick={handleAddTask}>Add Task</button>
      <ul>
        {doc.tasks?.map((task, i) => (
          <li key={i}>{task.title}</li>
        ))}
      </ul>
    </div>
  );
}
```

`Automerge.change` API는 '불변성'과 '데이터 지향' 원칙을 React 개발자에게 매우 친숙한 방식으로 제공합니다. SSoT(doc)를 직접 수정하는 대신, '변경(Change)'이라는 '명령(Command)'을 데이터 구조에 적용하여 '새로운 상태'를 파생시킵니다.

------


### 23.3. Yjs vs Automerge: 전략적 선택


두 라이브러리 모두 로컬 우선과 실시간 협업을 구현할 수 있지만, 트레이드오프가 명확합니다.

| **특징**               | **Yjs**                                                      | **Automerge**                                                |
| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **핵심 패러다임**      | **가변(Mutable)** `Doc` + **이벤트 구독 (Push)**             | **불변(Immutable)** `Doc` + **`change` 함수 (Pull 친화적)**  |
| **데이터 형식**        | 바이너리 (고도로 압축/최적화)                                | JSON-like (가독성 높음, 디버깅 용이)                         |
| **성능 (속도/메모리)** | **매우 빠름**. 대용량 문서, 텍스트 편집에 최적화.            | **느림**. JSON 파싱/직렬화, 불변 객체 생성 오버헤드.         |
| **React 통합**         | `useEffect` + `useState`로 **'브릿지'** 필요. (Push → Pull)  | `useState`와 **자연스럽게** 통합. (불변성 패턴)              |
| **생태계**             | **성숙함**. (Websocket, WebRTC, IndexedDB 프로바이더, Prosemirror/Tiptap 바인딩) | **성장 중**. (`automerge-repo`로 통합 중)                    |
| **추천 사용 사례**     | • **고성능 텍스트 편집기** (Tiptap, Prosemirror)  • **그래픽 편집기** (Figma, tldraw)  • 성능이 최우선일 때 | • **JSON 기반 상태** 관리 (Trello 보드, Todo 리스트)  • React/Redux에 익숙한 팀  • 데이터의 '변경 이력'이 중요할 때 (`getHistory`) |

------


### 23.4. 결론: 데이터 구조가 아키텍처를 결정한다


Yjs와 Automerge는 CRDT가 단순한 이론이 아니라, 복잡한 '로컬 우선' 및 '실시간 협업' 아키텍처를 뒷받침하는 **실용적인 데이터 구조**임을 증명합니다.

- **Yjs**는 **'성능'**을 위해 데이터 레이아웃(바이너리)을 극단적으로 최적화한, 제4부 '성능 최적화'의 연장선에 있습니다.
- **Automerge**는 **'개발자 경험'**과 **'불변성'**을 위해 React의 데이터 흐름(Pull)에 맞춘, 제1부/제5부('불변성', '반응형 플로우')의 연장선에 있습니다.

어떤 것을 선택하든, 우리는 더 이상 '충돌 병합 로직'을 직접 작성하지 않습니다. 복잡한 동기화와 병합 로직은 **데이터 구조(CRDT) 자체에 캡슐화**되었으며, 우리는 그저 '로컬 SSoT'를 읽고 쓰는 애플리케이션 계층에만 집중하면 됩니다. 이것이 데이터 지향 프로그래밍이 제공하는 궁극의 추상화입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 네 번째 장, '데이터 기반 렌더링'의 첫 번째 파트인 'Virtual DOM의 데이터 지향적 이해' 집필을 시작하겠습니다. 이 장은 `UI = f(State)`라는 공식을 데이터 구조의 관점에서 해부합니다.

------


## 24. 데이터 기반 렌더링 - Virtual DOM의 데이터 지향적 이해


> "Virtual DOM은 마법이 아니다. 그것은 DOM이라는 '불순한 세계'를 '순수한 데이터'의 세계로 끌어들인 위대한 추상화이다. 렌더링은 더 이상 '명령'이 아니라 '데이터 변환'이 된다."

이 책의 1부부터 5부까지, 우리는 애플리케이션의 핵심인 **'데이터(Data)'**와 **'로직(Logic)'**을 다루는 데 집중했습니다. 데이터를 어떻게 저장하고(SSoT, 정규화, CRDTs), 어떻게 변환하며(파이프라인, 시스템, CQRS), 어떻게 반응하게 할지(Signals, RxJS) 배웠습니다.

이제 우리는 이 모든 과정의 최종 목적지, 즉 **'렌더링(Rendering)'**에 도달했습니다. 렌더링은 데이터가 사용자에게 보이는 UI로 변환되는 마지막 단계입니다.

```text
UI = f(State)
```

이 유명한 공식에서 `State`는 우리의 SSoT 데이터이고, `UI`는 브라우저의 DOM입니다. 그렇다면 `f`는 무엇일까요? `f`는 **컴포넌트 함수**이며, 이 함수가 UI를 '만들어내는' 행위가 바로 렌더링입니다.

문제는 브라우저의 **'진짜' DOM**이 끔찍하게 다루기 힘든 대상이라는 것입니다. DOM API는 **명령형(Imperative)**이고, **상태 저장형(Stateful)**이며, 접근하고 수정하는 비용이 상상 이상으로 **비쌉니다(Slow)**. `document.getElementById('...').innerHTML = '...'` 같은 코드는 제3장에서 배운 '부수 효과(Side Effect)'의 정점입니다.

이 '비싸고 불순한' DOM의 세계와 '저렴하고 순수한' JavaScript 데이터의 세계를 연결하기 위해 발명된 데이터 지향적 추상화가 바로 **가상 DOM(Virtual DOM, VDOM)**입니다.

본 장에서는 VDOM이 단순한 '성능 트릭'이 아니라, 렌더링 과정을 '명령'에서 '데이터 변환'으로 바꾼 핵심적인 **데이터 구조**임을 탐구합니다.

------


### 24.1. Virtual DOM은 '데이터'다


가장 먼저 깨달아야 할 것은, Virtual DOM은 DOM이 아니라는 사실입니다. DOM을 흉내 낸 **순수한 JavaScript 객체(Plain Old JavaScript Object, POJO)**일 뿐입니다. VDOM은 **'데이터 구조(Data Structure)'**입니다.

브라우저에게 UI를 만들라고 '명령'하는 대신, VDOM은 우리가 원하는 UI가 '어떻게 생겼는지'를 **'설명(Describe)'**하는 데이터입니다.

**[전통적인 명령형(Imperative) DOM 조작]**

```typescript
// 👎 로직과 부수 효과가 결합됨
// '무엇을' 원하는지가 아니라 '어떻게' 할지 명령
function createMyView(data) {
  const div = document.createElement('div');
  div.className = 'container';
  
  const h1 = document.createElement('h1');
  h1.textContent = data.title;
  
  const p = document.createElement('p');
  p.textContent = data.description;
  
  div.appendChild(h1);
  div.appendChild(p);
  
  document.body.appendChild(div); // 💥 부수 효과!
}
```

**[선언적인(Declarative) Virtual DOM 데이터]**

```typescript
// 👍 순수한 '데이터' (JavaScript 객체)
// '어떻게'가 아니라 '무엇을' 원하는지 설명
function describeMyView(data) {
  const vdomTree = {
    type: 'div',
    props: {
      className: 'container',
      children: [
        {
          type: 'h1',
          props: { children: data.title }
        },
        {
          type: 'p',
          props: { children: data.description }
        }
      ]
    }
  };
  return vdomTree; // 💥 부수 효과 없음!
}
```

React에서 우리가 `JSX`를 작성할 때, 우리는 이 '데이터 구조'를 생성하는 것입니다. JSX는 `React.createElement()` 함수의 문법적 설탕(Syntactic Sugar)일 뿐이며, 이 함수가 반환하는 것이 바로 VDOM 객체입니다.

```typescript
// 1. 우리가 작성하는 JSX
<div className="container">
  <h1>{data.title}</h1>
</div>

// 2. Babel이 변환하는 코드 (데이터 생성 함수)
React.createElement('div', { className: 'container' }, 
  React.createElement('h1', null, data.title)
);

// 3. 실제 반환되는 VDOM (순수 데이터)
{
  type: 'div',
  props: {
    className: 'container',
    children: {
      type: 'h1',
      props: { children: data.title }
    }
  }
}
```

이 VDOM 객체는 순수 데이터이므로, 생성하고, 비교하고, 메모리에 저장하는 비용이 '진짜' DOM 노드를 생성하는 것보다 수천 배 저렴합니다.

------


### 24.2. `UI = f(State)`의 진정한 의미: 데이터 변환 파이프라인


이제 `UI = f(State)` 공식을 VDOM의 관점에서 다시 정의할 수 있습니다.

**`VDOM_Tree = ComponentFunction(State, Props)`**

React 컴포넌트(`f`)는 DOM을 반환하는 함수가 아닙니다. `State`와 `Props`라는 **'데이터'를 입력받아** `VDOM_Tree`라는 **'새로운 데이터'를 출력하는 순수 함수**입니다.

이것은 제2장에서 배운 **'데이터 변환 파이프라인'**과 정확히 일치합니다.

- **입력 (Input)**: `State` (SSoT)와 `Props` (부모 데이터)
- **변환 (Transformation)**: `ComponentFunction` (순수 로직)
- **출력 (Output)**: `VDOM_Tree` (새로운 데이터 구조)

렌더링 과정 전체가 '순수의 세계' 안에서 일어납니다. `setState()`가 호출되면 React는 다음과 같은 순수 데이터 변환 작업을 수행합니다.

1. `f(newState)`를 호출하여 `newVdomTree`를 얻습니다.
2. 이전에 기억해둔 `oldVdomTree`를 가져옵니다.
3. `newVdomTree`와 `oldVdomTree`를 비교합니다. (다음 장 'Reconciliation'에서 다룸)

이 모든 과정은 **'데이터'를 '데이터'와 비교**하는 작업일 뿐, '진짜' DOM에 단 한 번도 접근하지 않습니다.

------


### 24.3. Reconciliation: 데이터 트리를 'Diff'하는 시스템


VDOM이 빛을 발하는 순간은 '업데이트'가 발생할 때입니다.

`newVdomTree`와 `oldVdomTree`라는 두 개의 거대한 '데이터 트리'를 비교하는 알고리즘을 **'재조정(Reconciliation)'**이라고 부릅니다. React의 Reconciler(예: Fiber)가 바로 이 작업을 수행하는 **'시스템(System)'**입니다.

이 'Diffing' 알고리즘은 VDOM이 '데이터'이기에 가능한, 지극히 데이터 지향적인 작업입니다.

1. **타입 비교**: `old.type === new.type` (`div`가 `span`으로 바뀌었나?)
   - 데이터가 아니었다면 `oldNode.tagName === newNode.tagName`처럼 비싼 DOM 속성을 읽어야 했을 것입니다.
2. **Props 비교**: `old.props.className === new.props.className`
   - 데이터 객체의 속성을 `===`로 비교합니다. (제20장 '변경 감지 최적화'에서 배운 **'참조 동일성'**이 여기서 중요해집니다.)
3. **자식 비교 (Key의 역할)**: 자식 노드 리스트를 비교합니다.

특히 3번 '자식 비교'에서 VDOM의 데이터 지향적 본질이 드러납니다.

['A', 'B']가 ['B', 'A']로 바뀌었을 때, VDOM은 이것이 'A'와 'B'를 삭제/생성한 것인지, 아니면 '순서만 바꾼' 것인지 어떻게 알 수 있을까요?

바로 **`key` prop**입니다. `key`는 VDOM 노드를 위한 **'데이터베이스의 기본 키(Primary Key)'**입니다.

```typescript
// 👎 'key'가 없는 나쁜 예 (데이터 식별 불가)
// React는 첫 번째 <li>와 두 번째 <li>가
// '같은 것'인지 '다른 것'인지 알 수 없어 비효율적으로 동작
data.map(item => <li>{item.text}</li>)

// 👍 'key'가 있는 좋은 예 (데이터 식별 가능)
// React는 'key-1' 데이터가 'key-2' 데이터와
// *교환*되었음을 'key'라는 데이터를 통해 O(n)만에 파악
data.map(item => <li key={item.id}>{item.text}</li>)
```

`key`는 React에게 "이 VDOM 노드는 `item.id`라는 데이터 엔티티(Entity)에 해당한다"라고 알려주는 **메타데이터(Metadata)**입니다. 이 메타데이터 덕분에 Reconciler는 두 데이터 트리를 비교(Diff)하는 비용을 O(n³)에서 O(n)으로 극적으로 낮출 수 있습니다.

------


### 24.4. 렌더러: 순수한 세계와 불순한 세계의 '브릿지'


Reconciler(Diffing 시스템)의 출력물은 무엇일까요?

바로 **'변경 목록(Mutation List)'**입니다. 이것 역시 **'데이터'**입니다.

```typescript
// Diffing 시스템의 출력물 (순수 데이터)
const mutations = [
  { type: 'UPDATE_ATTRIBUTE', domNodeRef: ..., attr: 'className', value: 'foo' },
  { type: 'UPDATE_TEXT', domNodeRef: ..., text: 'New Title' },
  { type: 'MOVE_NODE', domNodeRef: ..., newIndex: 1 },
];
```

이 '변경 목록' 데이터가 **'렌더러(Renderer)'** (예: `react-dom`)로 전달됩니다.

`react-dom`은 이 책에서 말하는 **'불순한 쉘(Impure Shell)'(제3장)**의 완벽한 예시입니다. 렌더러의 유일한 임무는 이 순수한 '변경 목록' 데이터를 입력받아, 마침내 '진짜' DOM API라는 **부수 효과**를 실행하는 것입니다.

```typescript
mutations.forEach(m => m.domNodeRef.setAttribute(m.attr, m.value))
```

[데이터 지향적 렌더링 파이프라인]

State → (Component f) → VDOM Tree → (Reconciler diff) → Mutation List → (Renderer commit) → DOM (Side Effect)

이 파이프라인을 보십시오. '부수 효과'는 맨 마지막 단계로 완벽하게 격리되었습니다. 애플리케이션 로직의 99%(컴포넌트 실행, VDOM 생성, Diffing)는 **'데이터 변환'**이라는 순수한 세계 안에서 안전하고 빠르게 실행됩니다.

------


### 24.5. VDOM vs Signals (Pull vs Push 재검토)


제19장에서 우리는 Pull(React)과 Push(Signals)를 비교했습니다. VDOM은 Pull 모델의 핵심입니다.

- **VDOM (Pull)**: `setState`가 발생하면, `State`에서 **전체 VDOM 트리를 'Pull'**하여 생성하고 비교합니다. `f`를 다시 실행하는 비용과 VDOM을 비교하는 비용이 듭니다.
- **Signals (Push)**: `signal.value = ...`가 발생하면, VDOM 트리가 없습니다. 변경된 **데이터가 구독 중인 DOM 노드(예: `<span>`)로 직접 'Push'**되어 `textContent`를 갱신합니다.

VDOM은 "어디가 변했는지 모르겠으니, 일단 전체를 *설명*해 주면, 내가 *찾아내서* 고칠게"라는 방식입니다. 이는 `O(n)`의 비교 비용이 들지만, 컴포넌트 함수(`f`)가 상태에 대한 '구독'을 신경 쓰지 않고 그냥 `return <...>`만 하면 되는 **단순한 프로그래밍 모델**을 제공합니다.

반면 Signals는 "어디가 변했는지 *정확히* 아니, 딱 그곳만 고칠게"라는 방식입니다. `O(1)`의 업데이트 비용이 들지만, `effect`와 `computed`라는 명시적인 '구독' 그래프를 관리해야 합니다.

VDOM은 **개발자 경험(DX)을 위해 약간의 런타임 비용(Diffing)을 지불하는 데이터 지향적 '추상화'**인 것입니다.

------


### 24.6. 결론: VDOM은 '선언적 UI'의 데이터 기반


Virtual DOM은 성능 향상 도구가 아니라, **렌더링을 '데이터 변환'의 영역으로 가져온 '데이터 구조'**입니다.

1. VDOM은 `JSX`가 생성하는 **순수 JavaScript 객체(데이터)**입니다.
2. `ComponentFunction`은 `State`(데이터)를 `VDOM`(데이터)으로 변환하는 **순수 함수**입니다.
3. 'Reconciliation'은 `oldVDOM`(데이터)과 `newVDOM`(데이터)을 비교하는 **데이터 'Diff' 시스템**입니다.
4. `key` prop은 이 'Diff' 시스템을 위한 **핵심 메타데이터(데이터)**입니다.
5. `Renderer`는 'Diff' 결과(데이터)를 'DOM'(부수 효과)으로 변환하는 **'불순한 쉘'**입니다.

VDOM을 '데이터'로 이해할 때, 우리는 `key`가 왜 중요한지, 불변성이 왜 중요한지, 그리고 React가 어떻게 `UI = f(State)`라는 선언적 패러다임을 효율적으로 구현했는지 비로소 명확하게 파악할 수 있습니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 다섯 번째 장이자, '데이터 기반 렌더링'의 두 번째 파트인 'Reconciliation 알고리즘' 집필을 시작하겠습니다. 이 장은 24장에서 다룬 'VDOM 데이터 트리'를 '어떻게' 비교하는지에 대한 핵심 엔진을 해부합니다.

------


## 25. 데이터 기반 렌더링 - Reconciliation 알고리즘


> "VDOM이 '설계도'라면, Reconciliation은 두 설계도의 차이점을 1초 안에 찾아내는 '베테랑 감리자'이다. 이 감리자는 '모든 것을 부수고 새로 짓는' 대신, '최소한의 변경' 목록을 만들어내는 영리한 휴리스틱을 사용한다."

제24장에서 우리는 Virtual DOM(VDOM)이 '진짜' DOM이 아닌, UI의 구조를 '설명'하는 순수한 **JavaScript 객체 데이터**임을 배웠습니다. `UI = f(State)`라는 공식은 `VDOM_Tree = ComponentFunction(State)`라는 **데이터 변환 파이프라인**으로 구체화되었습니다.

이제 이 파이프라인의 다음 단계, 즉 React의 '엔진'이라 불리는 **'재조정(Reconciliation)'** 알고리즘을 탐구할 차례입니다.

`setState`가 호출되면, React는 `newVdomTree`를 생성합니다. React의 임무는 이 `newVdomTree`와 이전에 기억해둔 `oldVdomTree`를 비교하여, `oldDOM`을 `newDOM`으로 바꾸는 **'최소한의 DOM 조작(Mutation) 목록'**을 찾아내는 것입니다.

이것은 본질적으로 "한 데이터 트리를 다른 데이터 트리로 변환하는 가장 효율적인 방법을 찾는" 고전적인 컴퓨터 과학의 **'트리 비교(Tree Diffing)'** 문제입니다.

------


### 25.1. 문제는 '비용'이다: O(n³) vs O(n)


이 '최소한의 변경'을 찾는 완벽한 알고리즘은 존재합니다. 하지만 두 개의 임의의 트리를 비교하는 일반적인 트리 비교 알고리즘의 시간 복잡도는 $O(n^3)$ (여기서 $n$은 노드의 수)에 달합니다.

만약 노드가 1000개(결코 많지 않은 수)라면, $1,000^3 = 10억$ 번의 연산이 필요합니다. 이는 16ms(60fps)라는 브라우저의 렌더링 프레임 예산 안에서 절대 불가능한 수치입니다.

**React는 완벽함(최소한의 변경)을 포기하고, '충분히 빠르고' '대부분의 경우 최적인' O(n) 알고리즘을 선택했습니다.**

이 $O(n^3)$을 $O(n)$으로 낮추기 위해, React는 두 가지 강력한 **'휴리스틱(Heuristics)', 즉 경험에 기반한 '가정'**을 세웠습니다. 이 가정이 바로 Reconciliation 알고리즘의 핵심입니다.

------


### 25.2. React의 핵심 휴리스틱(Heuristics)


#### 25.2.1. 휴리스틱 1: 노드 타입이 다르면, 하위 트리도 다르다


> **가정**: "서로 다른 타입의 컴포넌트(예: `<Header>`와 `<Sidebar>`)나 DOM 태그(예: `<div>`와 `<span>`)는, 완전히 다른 UI 구조를 생성할 것이다."

React는 `oldVdomTree`의 루트(Root)와 `newVdomTree`의 루트를 비교할 때, 이 둘의 `type`이 다르면 **더 이상 비교를 시도하지 않습니다.**

- `old.type`이 `div`이고 `new.type`이 `span`인가?
  - **행동**: `diff`를 포기한다. `oldVdomTree` 전체(모든 자식 포함)를 **'언마운트(Unmount)'**하고, `newVdomTree` 전체를 **'마운트(Mount)'**한다.

데이터 지향적 의미:

이 가정은 $O(n^3)$의 복잡도를 $O(n)$으로 줄이는 가장 결정적인 한 수입니다. "두 트리가 혹시 비슷한 구조를 가졌는지"를 탐색하는 복잡한 재귀를 포기하고, 루트의 '데이터(type)'만 비교하여 "전부 교체"라는 단순한 '명령(Mutation)'을 생성합니다.

**주의:** 개발자가 이 가정을 어기면(예: 상태에 따라 `<div>`를 `<span>`으로 바꾸면), React는 `<div>`와 그 안의 모든 자식 DOM을 *파괴*하고 `<span>`과 그 자식 DOM을 *새로* 생성합니다. 이는 매우 비싼 작업입니다.


#### 25.2.2. 휴리스틱 2: `key` Prop을 통해 '데이터'를 식별한다


> **가정**: "개발자가 `key`라는 '고유 식별자(데이터)'를 제공하면, 그 `key`는 여러 렌더링 사이에서 동일한 '데이터 엔티티'를 가리킬 것이다."

이 휴리스틱은 '자식 노드 리스트'를 비교할 때 작동합니다. (25.3.2절에서 상세히 다룸)

------


### 25.3. Reconciliation 알고리즘의 작동 (Diffing)


React의 Reconciler는 이 두 가정을 기반으로 `oldVdomTree`와 `newVdomTree`를 동시에 재귀적으로 순회(Traverse)합니다.


#### 25.3.1. 단일 노드 비교 (루트 또는 재귀 단계)


1. **Case 1: `type`이 다른 경우 (휴리스틱 1)**
   - `old: <div />`, `new: <span />`
   - **명령**: `[UNMOUNT_NODE(old)], [MOUNT_NODE(new)]`
   - (자식은 비교조차 하지 않음)
2. **Case 2: `type`이 같은 DOM 요소인 경우**
   - `old: <div className="foo" />`, `new: <div className="bar" />`
   - **행동**: `type`이 'div'로 동일하므로, **'진짜' DOM 노드를 재사용**합니다.
   - **명령**: `props`만 비교(Diff)합니다.
     - `className`이 'foo'에서 'bar'로 변경됨
     - `[UPDATE_ATTRIBUTE(domNode, 'className', 'bar')]`
   - 이후, 이 노드의 '자식 리스트'에 대해 재귀적으로 Diff를 수행합니다.
3. **Case 3: `type`이 같은 컴포넌트인 경우**
   - `old: <MyComponent count={1} />`, `new: <MyComponent count={2} />`
   - **행동**: 컴포넌트 인스턴스(및 내부 `state`)를 **재사용**합니다.
   - React는 `new.props`(`{count: 2}`)를 컴포넌트 인스턴스에 전달하고, `render()` 함수를 **재실행**시킵니다.
   - **재귀**: Reconciler는 이 `render()`가 반환한 `newVdomTree`와, 이전에 반환했던 `oldVdomTree`를 가지고 **다시 25.3.1 단계(단일 노드 비교)부터 재귀적으로 `diff`를 시작합니다.**


#### 25.3.2. 자식 리스트 비교 (The `key` Prop)


이것이 React 성능의 핵심입니다.

[시나리오 1: key가 없는 최악의 경우]

oldChildren: `[<li>A</li>, <li>B</li>]`

newChildren: `[<li>C</li>, <li>A</li>, <li>B</li>]` (맨 앞에 'C' 삽입)

- `key`가 없으면 React는 **인덱스(Index)**로 비교합니다. (휴리스틱 2 실패)
- **Diff 1 (Index 0)**: `old: <li>A</li>` vs `new: <li>C</li>`
  - `textContent`가 다르므로, DOM 노드를 재사용하되 'A'를 'C'로 **업데이트**합니다. (`[UPDATE_TEXT(domNode, 'C')]`)
- **Diff 2 (Index 1)**: `old: <li>B</li>` vs `new: <li>A</li>`
  - `textContent`가 다르므로, DOM 노드를 재사용하되 'B'를 'A'로 **업데이트**합니다. (`[UPDATE_TEXT(domNode, 'A')]`)
- **Diff 3 (Index 2)**: `old: 없음` vs `new: <li>B</li>`
  - 새로운 노드이므로 **삽입(Insert)**합니다. (`[INSERT_NODE(domNode)]`)

**결과**: 불필요한 DOM 업데이트 2회 + 삽입 1회. (`<li>A</li>`와 `<li>B</li>`는 멀쩡히 있는데도!)

[시나리오 2: key가 있는 데이터 지향적 경우]

oldChildren: `[<li key="A">A</li>, <li key="B">B</li>]`

newChildren: `[<li key="C">C</li>, <li key="A">A</li>, <li key="B">B</li>]`

- React는 `key`를 사용하여 데이터를 식별합니다. (휴리스틱 2 성공)
- **1단계 (Map 생성)**: `newChildren`을 `Map`으로 변환합니다. `{'C': vdomC, 'A': vdomA, 'B': vdomB}`
- **2단계 (`oldChildren` 순회)**:
  - `old: key="A"`
    - `new Map`에 "A"가 있는가? **Yes.**
    - `type`이 `li`로 같은가? **Yes.**
    - `props`가 같은가? **Yes.**
    - 'A'는 `oldIndex 0`에서 `newIndex 1`로 이동했는가? **Yes.**
    - **명령**: `[MOVE_NODE('A')]`
  - `old: key="B"`
    - `new Map`에 "B"가 있는가? **Yes.** (이하 동일)
    - **명령**: `[MOVE_NODE('B')]`
- **3단계 (남은 `newChildren` 처리)**:
  - `new Map`에 "C"가 남아있는가? **Yes.**
  - **명령**: `[INSERT_NODE('C')]`

**결과**: 이동 2회 + 삽입 1회. DOM 업데이트(Mutation)가 전혀 없습니다. `<li>A</li>`와 `<li>B</li>` DOM 노드를 **완벽하게 재사용**했습니다.

------


### 25.4. `key`는 데이터 식별자다


Reconciliation 알고리즘에게 `key`는 **'뷰 데이터(VDOM)'**와 **'상태 데이터(State Entity)'**를 연결하는 **'기본 키(Primary Key)'**입니다.

`key` prop에 `Math.random()`이나 배열의 `index`를 사용하는 것이 왜 최악의 안티패턴인지 이제 명확해집니다.

- `key={Math.random()}`: 매 렌더링마다 `key`가 바뀝니다. React는 모든 노드가 '다른' 엔티티라고 착각하여 **모든 것을 언마운트하고 새로 마운트**합니다.
- `key={index}`: 위 '시나리오 1'과 정확히 동일하게 동작합니다. 리스트 맨 앞에 항목이 삽입되면, 모든 `key`(index)가 밀려나므로 React는 모든 항목이 '변경되었다'고 착각하여 비효율적인 DOM 업데이트를 수행합니다.

**`key`는 반드시 `item.id`처럼 데이터의 고유하고 안정적인 식별자여야 합니다.**

------


### 25.5. 결론: 데이터 구조가 알고리즘을 결정한다


React의 Reconciliation 알고리즘은 '완벽한' 트리 비교를 포기하는 대신, **'데이터'의 특성(타입, 키)**에 대한 두 가지 '휴리스틱'을 기반으로 $O(n)$의 성능을 달성한, 지극히 실용적이고 데이터 지향적인 '시스템'입니다.

1. **VDOM**이라는 **순수 데이터 구조**가 있었기에 'Diff'가 가능했습니다. (제24장)
2. `type`이라는 **데이터**를 비교하여 재귀를 차단했습니다.
3. `key`라는 **메타데이터**를 활용하여 자식 리스트 비교를 $O(n)$으로 최적화했습니다.

이 모든 과정의 최종 출력물은 `[MOVE, INSERT, UPDATE]` 같은 **'명령 데이터 목록(Mutation List)'**이며, 이 목록은 `react-dom`이라는 '불순한 쉘'에 의해 '진짜' DOM으로 커밋(Commit)됩니다.

이것이 `UI = f(State)`라는 선언적 모델이 어떻게 고성능을 유지하는지에 대한 데이터 지향적 해답입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 마지막 장이자, '데이터 기반 렌더링' 섹션을 마무리하는 '선언적 UI = f(state) 패러다임' 집필을 시작하겠습니다. 이 장은 이 책 전체를 관통하는 핵심 사상을 집대성합니다.

------


## 26. 데이터 기반 렌더링 - 선언적 UI = f(state) 패러다임


> "UI = f(state). 이것은 React의 슬로건이 아니다. 이것은 복잡한 UI 엔지니어링의 세계를 '데이터'와 '함수'라는 두 가지 단순한 요소로 환원시킨, 데이터 지향 프로그래밍의 대헌장이다."

이 책의 기나긴 여정은 이 하나의 공식, `UI = f(state)`를 완벽하게 이해하기 위한 과정이었습니다. 우리는 이 공식의 각 구성 요소를 해부하고, 최적화하고, 다양한 아키텍처에 적용해 보았습니다.

- **명령형(Imperative) 프로그래밍 (전통)**: "UI, 너는 `state`를 기반으로 *이렇게 저렇게* 바뀌어야 해." (`button.textContent = state.text`, `div.appendChild(...)`)
- **선언형(Declarative) 프로그래밍 (데이터 지향)**: "UI, 너의 모습은 `state`를 *설명*하는 이 함수(`f`)의 결과물이야." (`return <div>{state.text}</div>`)

명령형 프로그래밍에서 'UI'는 개발자가 직접 조작하고 관리해야 하는 '상태를 가진 객체(Stateful Object)'입니다. 반면 선언형 프로그래밍에서 'UI'는 '상태가 없는(Stateless)' 함수 `f`가 반환하는 **'데이터(VDOM)'의 단순한 반영**일 뿐입니다.

이 패러다임의 전환은 프론트엔드 개발을 'DOM 조작'이라는 복잡한 부수 효과의 영역에서 '데이터 변환'이라는 순수하고 예측 가능한 영역으로 끌어올렸습니다.

본 장에서는 이 공식의 세 가지 구성 요소인 `state`, `f`, `UI`가 우리가 배운 모든 데이터 지향 원칙과 어떻게 연결되는지 최종적으로 정리합니다.

------


### 26.1. `state`: '진실'의 데이터


`UI = f(state)`에서 `state`는 공식의 '입력(Input)' 데이터입니다. 이 입력 데이터가 '좋은' 데이터가 아니라면, '좋은' UI가 나올 수 없습니다. '좋은 state'란 무엇인가?

1. **단일 진실 공급원 (SSoT) (제2부)**
   - `state`는 애플리케이션의 '모든 진실'을 담은 **유일한 원천**이어야 합니다. 중복된 데이터, 분열된 진실은 `f`를 복잡하게 만들고 버그를 유발합니다.
   - `state`가 서버에 있든(서버 상태), 클라이언트에 있든(클라이언트 상태), URL에 있든(라우터 상태) 명확한 '소유자'가 있어야 합니다. (제5장)
2. **불변성 (Immutability) (제1부)**
   - `f`는 `state`를 절대 직접 수정해서는 안 됩니다. `f`는 `state`를 '읽기 전용'으로 취급해야 합니다.
   - `state`가 변경될 때는 항상 **새로운 참조**(`newState`)가 생성되어야 합니다.
   - 이 불변성은 `if (oldState === newState)`라는 $O(1)$ 비교를 가능하게 하여, " `f`를 다시 실행할 필요가 있는지"를 판단하는 **변경 감지 최적화(제5부)**의 핵심 전제가 됩니다.
3. **정규화 (Normalization) (제2부, 제5부)**
   - `state`는 중첩된 API 응답 구조가 아닌, **데이터베이스처럼 정규화**되어야 합니다. (예: `entities.users`, `entities.posts`)
   - 정규화는 데이터 중복을 제거하여 SSoT를 보장하고, `f`(리듀서 또는 컴포넌트)가 상태를 수정하거나 조회하는 로직을 극도로 단순하게 만듭니다. (예: `state.entities.users[id]`)
4. **충돌 없음 (Conflict-free) (제6부)**
   - '로컬 우선'과 '협업'이라는 극한의 환경에서, `state`는 `CRDT`라는 데이터 구조 그 자체가 되어야 합니다.
   - 이때 `state`는 '현재 값'이 아니라 '이벤트 로그' 또는 'CRDT 문서'가 되며, `f`는 이 데이터를 '프로젝션'하는 함수가 됩니다. (제10장, 제21장)

`state`는 단순한 JSON 객체가 아닙니다. 그것은 이 모든 데이터 지향 원칙이 응축된, 견고하게 설계된 **'데이터 구조'**입니다.

------


### 26.2. `f`: '변환'의 순수 함수


`UI = f(state)`에서 `f`는 공식의 '로직(Logic)'입니다. 이 로직은 '데이터'와 완벽하게 분리되어야 합니다.

1. **순수 함수 (Pure Function) (제1부)**
   - `f`는 **부수 효과(Side Effect)가 없어야** 합니다. API 호출, `localStorage` 접근, DOM 직접 조작은 `f`의 외부(예: `useEffect`, 이벤트 핸들러)로 격리되어야 합니다. (제3장)
   - `f`는 **참조 투명성**을 가져야 합니다. 동일한 `state`가 주어지면 *항상* 동일한 `UI`(VDOM)를 반환해야 합니다.
2. **선언적 (Declarative)**
   - `f`는 UI를 '어떻게' 만들지(명령형) 기술하지 않고, '무엇'인지(선언형) 기술합니다.
   - `return <div />`는 "div를 만들라"는 명령이 아니라, "UI는 div다"라는 '선언'입니다.
3. **조합 가능한 파이프라인 (Composable Pipeline) (제2부, 제5부)**
   - `f`는 거대한 단일 함수가 아닙니다. 그것은 **데이터 변환 파이프라인** 전체를 의미합니다.
   - `f = f_reconciler ∘ f_component ∘ f_selector`
   - **1단계: `f_selector` (셀렉터)**
     - `DerivedState = f_selector(SSoT_State)`
     - 정규화된 SSoT에서 UI가 실제로 필요한 '파생 상태'를 계산합니다. `useMemo`나 `reselect`가 이 역할을 합니다. (제6장)
   - **2단계: `f_component` (컴포넌트 함수)**
     - `VDOM_Tree = f_component(DerivedState)`
     - 파생 상태를 입력받아 **VDOM이라는 '데이터'를 반환**합니다. (제24장)
   - **3단계: `f_reconciler` (재조정 알고리즘)**
     - `DOM_Mutations = f_reconciler(Old_VDOM, New_VDOM)`
     - 두 VDOM 데이터 트리를 비교(Diff)하여 '최소한의 변경 목록'이라는 **'데이터'를 반환**합니다. (제25장)

`f`는 `state`라는 데이터를 `VDOM`이라는 데이터로, 다시 `DOM_Mutations`라는 데이터로 변환하는 **'데이터 변환 시스템(Data Transformation System)'** 그 자체입니다.

------


### 26.3. `UI`: '결과'의 반영


`UI = f(state)`에서 `UI`는 공식의 '출력(Output)'입니다.

1. **'진짜'가 아닌 '가상' (Virtual)**
   - `f`가 반환하는 직접적인 결과물은 '진짜' DOM이 아닌 **'가상 DOM(VDOM)'**이라는 데이터입니다. (제24장)
   - `UI`는 `f(state)`의 결과인 `VDOM`을 **'반영(Reflection)'**한 최종 산물입니다.
2. **'불순한 쉘' (Impure Shell) (제3장)**
   - VDOM을 실제 DOM으로 변환하는 `Renderer`(예: `react-dom`)는 `f`의 순수한 세계와 '진짜' DOM이라는 불순한 세계를 연결하는 **유일한 '브릿지'**입니다.
   - 모든 부수 효과는 이 '렌더러'에 의해 맨 마지막 단계에서 '커밋(Commit)'됩니다.
3. **상태가 없는 '멍청한' 존재 (Stateless & Dumb)**
   - 이 패러다임에서 'DOM(UI)'은 스스로 상태를 가지지 않습니다. (혹은 가져서는 안 됩니다. '비제어 컴포넌트'는 예외)
   - DOM은 `state`의 현재 모습을 보여주는 '멍청한 터미널'일 뿐입니다. 진실은 오직 `state`에만 있습니다.

------


### 26.4. `f(state)` 패러다임의 완성


`UI = f(state)`는 단순한 공식을 넘어, 우리가 이 책에서 배운 모든 데이터 지향 원칙을 지탱하는 **아키텍처 그 자체**입니다.

State (정규화된, 불변의, SSoT)

↓

f (순수 함수, 셀렉터, 컴포넌트, Reconciler)

↓

UI (VDOM 데이터, DOM 반영)

이 패러다임을 따름으로써 우리는 다음을 얻습니다.

- **예측 가능성**: `state`만 알면 `UI`가 어떻게 보일지 100% 예측할 수 있습니다.
- **테스트 용이성**: `f`는 순수 함수이므로, `state`를 주입하고 `VDOM` 출력을 검증하는 것으로 UI 로직 테스트가 끝납니다. 브라우저가 필요 없습니다.
- **디버깅 용이성**: `state`가 잘못되었거나, `f`가 잘못되었거나 둘 중 하나입니다. "UI가 이상해요"라는 모호한 문제는 "이 `state`가 주어졌을 때 `f`가 잘못된 `VDOM`을 반환했어요"라는 명확한 데이터의 문제로 바뀝니다.
- **최적화**: `state`가 불변이므로, `oldState === newState` 비교를 통해 `f`의 값비싼 실행을 건너뛸 수 있습니다. (제20장 `React.memo`)
- **이식성**: `f(state)`는 JavaScript일 뿐입니다. `react-dom`(웹) 대신 `react-native`(모바일)를 '렌더러'로 교체하면 동일한 로직이 모바일 앱으로 실행됩니다.

이것이 '데이터'와 '로직'을 분리하고, UI 렌더링을 '데이터 변환'의 문제로 치환한 데이터 지향 프로그래밍의 위대한 승리입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 일곱 번째 장이자, '타입 시스템 활용' 섹션의 첫 번째 파트인 'TypeScript의 고급 타입으로 데이터 모델링' 집필을 시작하겠습니다. 이 장은 우리가 설계한 데이터 구조를 TypeScript의 강력한 타입 시스템으로 어떻게 '정의'하고 '보호'할 수 있는지 탐구합니다. 💻

------


## 27. 타입 시스템 활용 - TypeScript의 고급 타입으로 데이터 모델링


> "타입은 문서가 아니다. 타입은 컴파일러가 당신의 코드를 이해하고, 당신의 실수를 잡아내며, 당신의 의도를 강제하는 '법률'이다. 데이터 지향 프로그래밍에서 데이터는 왕이며, 타입은 그 왕좌를 지키는 가장 강력한 수호자다."

이 책 전반에 걸쳐 우리는 '데이터'를 중심에 두었습니다. 데이터를 어떻게 구조화하고(정규화, SoA/AoS), 어떻게 흐르게 하며(파이프라인, 반응형), 어떻게 보호할지(불변성, CRDT) 논의했습니다. 하지만 이 모든 설계는 '구현' 단계에서 깨지기 쉽습니다. 개발자의 작은 실수가 데이터 구조를 오염시키고, 런타임 에러를 발생시킬 수 있습니다.

JavaScript는 동적 타입 언어이기 때문에 이러한 문제에 특히 취약합니다. `user.naem` 같은 오타나 `calculateTotal(items)`에 숫자 배열 대신 문자열 배열을 넣는 실수는 런타임이 되어서야 발견됩니다.

**TypeScript**는 이 문제를 정면으로 해결합니다. TypeScript는 JavaScript 위에 '정적 타입 시스템'이라는 강력한 보호막을 추가하여, 코드를 실행하기 *전*에 컴파일 단계에서 데이터의 '모양(Shape)'과 '흐름(Flow)'을 검증합니다.

데이터 지향 프로그래밍에서 TypeScript는 단순한 '편의 기능'이 아닙니다. 우리가 설계한 복잡한 데이터 구조(정규화된 상태, 이벤트 유니언, CRDT)를 **정확하게 모델링하고, 그 구조가 깨지지 않도록 강제하는 핵심적인 '안전 장치'**입니다. 🔒

본 장에서는 TypeScript의 **고급 타입**(유니언, 제네릭, 맵드 타입, 조건부 타입 등)을 활용하여, 우리가 논의했던 데이터 지향 구조들을 어떻게 더 명확하고, 안전하며, 유지보수하기 쉽게 모델링할 수 있는지 탐구합니다.

------


### 27.1. 기본을 넘어서: 왜 고급 타입인가?


`string`, `number`, `boolean`, `interface`, `type` 같은 기본 타입만으로는 복잡한 데이터 지향 구조를 충분히 표현하기 어렵습니다.

- `Event`는 `'USER_CREATED'`일 수도 있고 `'ITEM_ADDED'`일 수도 있습니다. (다양한 형태)
- 정규화된 `entities` 객체는 어떤 종류의 엔티티(`User`, `Post`)든 담을 수 있어야 합니다. (일반화)
- `Readonly<T>`처럼 기존 타입을 '변형'하여 불변성을 강제하고 싶습니다. (타입 변환)

이런 요구사항을 만족시키기 위해 TypeScript는 강력한 고급 타입 기능들을 제공합니다.

------


### 27.2. 핵심 도구 1: 식별 가능한 유니언 (Discriminated Unions)


'이벤트(Event)'나 '액션(Action)'을 모델링하는 데 완벽한 패턴입니다. 제10장(이벤트 소싱)과 제11장(Undo/Redo)에서 이미 사용했습니다.

```typescript
// (제10장 CartEvent 예시)
type CartEvent =
  | {
      // 💥 'type' 속성이 '식별자(Discriminant)' 역할
      type: 'CART_CREATED';
      timestamp: number;
      payload: { userId: string };
    }
  | {
      type: 'ITEM_ADDED';
      timestamp: number;
      payload: { itemId: string; name: string; price: number };
    }
  | {
      type: 'ITEM_REMOVED';
      timestamp: number;
      payload: { itemId: string };
    }; // ... 기타 이벤트들 ...

// 프로젝터(리듀서)에서 타입 안전성 확보
function cartStateProjector(state: CartState, event: CartEvent): CartState {
  switch (event.type) {
    case 'CART_CREATED':
      // 👍 'event.payload'는 { userId: string } 타입으로 자동 추론됨
      console.log('Cart created for user:', event.payload.userId);
      return initialState;

    case 'ITEM_ADDED':
      // 👍 'event.payload'는 { itemId, name, price } 타입으로 자동 추론됨
      const { itemId, name, price } = event.payload;
      return produce(state, draft => { /* ... */ });
    
    // 💥 만약 'ITEM_REMOVED' 케이스를 빠뜨리면?
    // TypeScript가 컴파일 에러를 발생시킬 수 있음 ('never' 타입 활용)
    default:
      // 모든 케이스를 처리했는지 확인하는 기법
      const _exhaustiveCheck: never = event;
      return state;
  }
}
```

식별 가능한 유니언은 `switch` 문과 결합될 때 **타입 좁히기(Type Narrowing)**를 통해 강력한 타입 안전성을 제공합니다. `event.type`에 따라 `event.payload`의 타입이 자동으로 결정되므로, 잘못된 속성에 접근하는 실수를 컴파일 단계에서 방지할 수 있습니다. 🛡️

------


### 27.3. 핵심 도구 2: 제네릭 (Generics)


제네릭은 '타입을 위한 변수'입니다. 특정 타입에 의존하지 않고, **재사용 가능한** 데이터 구조나 함수를 만들 때 사용됩니다. 제17장의 `createEntityAdapter`가 완벽한 예시입니다.

```typescript
import { EntityState, EntityAdapter } from '@reduxjs/toolkit';

// 1. EntityState<T> - 제네릭 인터페이스
// 'T'라는 타입 변수를 받아, 정규화된 상태의 '모양'을 정의
// { ids: string[], entities: Record<string, T> }
interface UsersState extends EntityState<User> {}
interface PostsState extends EntityState<Post> {}

// 2. createEntityAdapter<T>() - 제네릭 함수
// 'T' 타입의 엔티티를 관리하는 '어댑터(시스템)'를 생성
const usersAdapter: EntityAdapter<User> = createEntityAdapter<User>();
const postsAdapter: EntityAdapter<Post> = createEntityAdapter<Post>();

// 3. 어댑터 메서드들도 제네릭을 활용
// addOne(state: EntityState<T>, action: PayloadAction<T>): void;
// selectById(state: EntityState<T>, id: string): T | undefined;
```

제네릭 덕분에 Redux Toolkit 팀은 `User`용, `Post`용 어댑터를 각각 만들 필요 없이, **단 하나의 `createEntityAdapter<T>`**만으로 모든 종류의 엔티티에 대한 정규화 관리 시스템을 제공할 수 있었습니다. ✨

로컬 우선 앱(제22장)의 `dataCache: Map<pageNumber, Item[]>`나 CRDT 문서(`Y.Doc`, `Automerge.Doc<T>`) 역시 제네릭을 활용하여 다양한 데이터 타입을 담을 수 있습니다.

------


### 27.4. 핵심 도구 3: 맵드 타입 (Mapped Types)


맵드 타입은 기존 타입을 기반으로 **새로운 타입을 '변형(Transform)'**하여 만드는 강력한 도구입니다. `for...in` 루프처럼 기존 타입의 속성들을 순회하며 새로운 타입 정의를 생성합니다.

TypeScript에 내장된 `Readonly<T>`, `Partial<T>`, `Required<T>`, `Pick<T, K>`, `Record<K, T>` 등이 모두 맵드 타입으로 구현되어 있습니다.

**[예제 1: 모든 속성을 읽기 전용으로 만들기 (`Readonly<T>`)]**

```typescript
type Readonly<T> = {
  // T의 모든 속성 'K'에 대해...
  readonly [P in keyof T]: T[P];
  // 'readonly' 키워드를 추가한다.
};

interface Point { x: number; y: number; }
type ReadonlyPoint = Readonly<Point>; // { readonly x: number; readonly y: number; }
```

이 `Readonly<T>`는 제1장에서 배운 **불변성(Immutability)**을 타입 레벨에서 강제하는 데 핵심적인 역할을 합니다. SSoT 상태나 이벤트 객체를 `Readonly`로 감싸면, 실수로 원본을 수정하려는 시도를 컴파일러가 막아줍니다.

**[예제 2: 상태 업데이트를 위한 `Partial<T>`]**

`Partial<T>`은 타입 `T`의 모든 속성을 '선택적(Optional, `?`)'으로 만듭니다. 이는 엔티티의 일부만 업데이트하는 함수를 모델링할 때 유용합니다.

```typescript
type Partial<T> = {
  [P in keyof T]?: T[P];
};

interface User { id: string; name: string; age: number; }

// 'User'의 일부 속성만 담은 '업데이트 객체'
type UserUpdatePayload = Partial<User> & { id: string }; // id는 필수

function updateUser(payload: UserUpdatePayload) {
  // payload는 { id: 'u1', name: 'Bob' } 이거나
  // { id: 'u2', age: 31 } 일 수 있음
  const user = state.entities.users[payload.id];
  if (user) {
    // 👍 타입 안전하게 속성 업데이트 (id는 제외)
    Object.keys(payload).forEach(key => {
      if (key !== 'id') {
        user[key] = payload[key];
      }
    });
  }
}
```

**[예제 3: `Record<K, T>` - 정규화된 상태 모델링]**

`Record<K, T>`는 키(Key) 타입이 `K`이고 값(Value) 타입이 `T`인 객체 타입을 생성합니다. 이는 제4장, 제17장의 **정규화된 `entities` 객체**를 완벽하게 표현합니다.

```typescript
type Record<K extends keyof any, T> = {
    [P in K]: T;
};

// string 타입의 ID를 키로, User 객체를 값으로 갖는 타입
type UserEntities = Record<string, User>; 
// { [userId: string]: User } 와 동일

const userTable: UserEntities = {
  'u1': { id: 'u1', name: 'Alice', age: 30 },
  'u2': { id: 'u2', name: 'Bob', age: 25 },
};
```

------


### 27.5. 핵심 도구 4: 조건부 타입 (Conditional Types)


조건부 타입은 `타입 ? 참일때_타입 : 거짓일때_타입` 형태를 사용하여, **타입 레벨에서 'if'문**을 구현하는 기능입니다. 이는 매우 복잡한 타입 변환이나 추론을 가능하게 합니다.

**[예제 1: 타입 추출 (`Extract<T, U>`, `Exclude<T, U>`)]**

```typescript
// T가 U에 할당 가능하면 T를, 아니면 never를 반환
type Extract<T, U> = T extends U ? T : never;

// T가 U에 할당 가능하면 never를, 아니면 T를 반환
type Exclude<T, U> = T extends U ? never : T;

type EventType = 'A' | 'B' | 'C';

// EventType에서 'A' 타입만 추출
type EventA = Extract<EventType, 'A'>; // 'A'

// EventType에서 'A' 타입을 제외
type EventBorC = Exclude<EventType, 'A'>; // 'B' | 'C'
```

이는 복잡한 유니언 타입(예: `AllAppEvents`)에서 특정 종류의 이벤트만 필터링하여 새로운 타입(`UserEvents`)을 만드는 데 사용될 수 있습니다.

**[예제 2: 함수의 반환 타입 추론 (`ReturnType<T>`)]**

```typescript
// T가 함수 타입이면 그 반환 타입을, 아니면 any를 반환
type ReturnType<T extends (...args: any) => any> = 
  T extends (...args: any) => infer R ? R : any;
  // 'infer R'은 함수의 반환 타입을 '추론'하여 R 변수에 담음

type Fn = () => string;
type Result = ReturnType<Fn>; // string
```

이는 함수(예: 셀렉터 함수)의 반환 타입을 명시적으로 다시 작성하지 않고, 타입스크립트가 자동으로 추론하게 하여 코드 중복을 줄이는 데 유용합니다.

------


### 27.6. 결론: 타입은 살아있는 설계 문서다 📄


데이터 지향 프로그래밍에서 TypeScript의 고급 타입은 단순한 '주석'이 아닙니다.

- 유니언 타입은 **다양한 데이터 형태(Events, State Variants)**를 명확히 정의합니다.
- 제네릭 타입은 **재사용 가능한 데이터 구조(EntityState, CRDT Doc)**를 가능하게 합니다.
- 맵드 타입은 **데이터 변환 규칙(Readonly, Partial)**을 타입 레벨에서 강제합니다.
- 조건부 타입은 **복잡한 데이터 관계**를 타입 시스템 자체로 추론하고 검증합니다.

잘 설계된 타입 시스템은 그 자체로 **애플리케이션의 데이터 모델과 흐름을 설명하는 가장 정확하고 최신이며 '실행 가능한' 문서**가 됩니다. 컴파일러는 이 문서를 읽고, 우리의 코드가 설계에서 벗어나지 않도록 끊임없이 감시하는 충실한 감시자 역할을 합니다. 🧐

------

네, 알겠습니다. 제6부 '고급 주제'의 여덟 번째 장, '타입 시스템 활용' 섹션의 두 번째 파트인 'Discriminated Unions와 패턴 매칭' 집필을 시작하겠습니다. 이 장은 27장에서 소개한 타입 모델링을 기반으로, '다양한 형태의 데이터'를 소비하는 '로직'을 어떻게 100% 타입 안전하게 작성하는지 탐구합니다.

------


## 28. 타입 시스템 활용 - Discriminated Unions와 패턴 매칭


> "데이터가 자신의 '모양'을 스스로 설명할 수 있다면, 로직은 그 '설명'을 믿고 안전하게 실행될 수 있다. Discriminated Union은 데이터가 스스로를 설명하는 '방식'이며, 패턴 매칭은 로직이 그 설명을 '이해'하는 방식이다."

제27장에서 우리는 TypeScript의 고급 타입이 우리가 설계한 데이터 모델을 컴파일 타임에 '보호'하는 법률과 같다고 정의했습니다. 우리는 제네릭, 맵드 타입 등으로 데이터 구조의 '청사진'을 그렸습니다.

하지만 현실의 데이터는 종종 단 하나의 '청사진'으로 정의되지 않습니다. 데이터는 '여러 가지 유효한 상태(Variants)'를 가질 수 있습니다.

- API 요청의 상태: `Idle` | `Loading` | `Success(data)` | `Error(e)`
- 사용자 인증 상태: `Anonymous` | `Authenticated(user)`
- 이벤트 소싱의 이벤트: `UserCreated` | `ItemAdded` | `ItemRemoved`

이러한 '데이터 변종'을 다룰 때, 개발자는 두 가지 큰 함정에 빠집니다.

1. **불가능한 상태의 허용**: `isLoading: boolean`, `data: User | null`, `error: Error | null`을 모두 '루트'에 두어, `isLoading: true`와 `error: Error`가 동시에 존재하는 '불가능한' 상태를 허용하는 것입니다.
2. **안전하지 않은 로직**: `if (state.data)` { ... } 같은 코드는, `state.data`가 `null`일 가능성을 잊거나 `state.error`가 함께 있을 가능성을 무시하여 런타임 에러를 유발합니다.

데이터 지향 프로그래밍은 **"불가능한 상태는 아예 표현조차 할 수 없도록(Make impossible states unrepresentable)"** 데이터 모델을 설계할 것을 요구합니다.

이 문제를 해결하는 TypeScript의 가장 강력하고 우아한 데이터 모델링 기법이 바로 **'식별 가능한 유니언(Discriminated Unions, DUs)'**이며, 이 데이터를 안전하게 소비하는 로직 기법이 **'패턴 매칭(Pattern Matching)'**입니다. 본 장에서는 이 두 가지 패턴이 어떻게 결합하여 컴파일 타임에 완벽한 데이터-로직 동기화를 구현하는지 탐구합니다.

------


### 28.1. Discriminated Unions (DUs): 스스로를 설명하는 데이터


Discriminated Union은 27.2절에서 간단히 소개했듯이, 여러 타입(보통 객체)을 하나의 `|` (유니언)으로 묶되, 각 타입이 '식별자(Discriminant)' 역할을 하는 **공통된 리터럴 속성**을 갖는 패턴입니다.

- **식별자(Discriminant)**: `type: 'A'`, `status: 'success'`처럼, 모든 유니언 멤버가 공유하지만 값은 고유한 속성.
- **유니언(Union)**: `type Shape = Circle | Square | Triangle`
- **데이터 페이로드**: 각 멤버는 식별자에 따라 *고유한* 데이터 페이로드(속성)를 가집니다.


#### 28.1.1. 최악의 안티패턴: `boolean` 지옥


데이터 변종을 다루는 가장 나쁜 방법은 `boolean` 플래그를 남발하는 것입니다.

```typescript
// 👎 나쁜 예: 불가능한 상태가 표현 가능함
interface UserState {
  isLoading: boolean;
  isError: boolean;
  isSuccess: boolean;
  
  data: User | null;
  error: Error | null;
}

// 💥 이 상태는 논리적으로 '불가능'하지만, 타입 시스템은 '유효'하다고 판단함
const impossibleState: UserState = {
  isLoading: true,
  isError: true,
  isSuccess: false, // 로딩 중인데 에러?
  data: { id: 'u1', name: 'Alice' }, // 로딩 중인데 데이터가 있음?
  error: new Error('Failed to load'), // 로딩 중인데 에러가 있음?
};
```

이 `UserState`는 9개의 서로 다른 boolean 조합을 허용하며, 그 대부분은 논리적 모순입니다. 이 상태를 소비하는 로직(예: React 컴포넌트)은 `if (isLoading) ... else if (isError) ... else if (data)` 같은 복잡하고 오류가 발생하기 쉬운 분기 처리를 강요받습니다.


#### 28.1.2. DU를 통한 데이터 모델링: 불가능한 상태 제거


Discriminated Union은 '상태'를 하나의 거대한 객체가 아닌, '상호 배타적인(Mutually Exclusive)' 타입의 집합으로 모델링합니다.

```typescript
// 👍 좋은 예: Discriminated Union (a.k.a. "Tagged Union")
type RemoteData<T> =
  | { status: 'idle' } // (식별자: status)
  | { status: 'loading' }
  | { status: 'success'; data: T } // 'success' 상태는 *반드시* 'data'를 가짐
  | { status: 'error'; error: Error }; // 'error' 상태는 *반드시* 'error'를 가짐

// 💥 이 타입은 '논리적으로 유효한' 상태만 표현할 수 있음

// 1. 로딩 상태: 'data'나 'error' 속성을 가질 수 *없음*
const loadingState: RemoteData<User> = {
  status: 'loading',
};

// 2. 성공 상태: 'data'가 *반드시* 있어야 함. 'error'는 가질 수 *없음*
const successState: RemoteData<User> = {
  status: 'success',
  data: { id: 'u1', name: 'Alice' },
};

// 3. 💥 컴파일 에러: 불가능한 상태는 타입 에러가 됨
const impossibleState: RemoteData<User> = {
  status: 'loading',
  data: { id: 'u1', name: 'Alice' }, // 🛑 Error: 'loading' 타입에는 'data' 속성이 없음
};
```

데이터 모델이 `status: 'loading'`일 때는 `data` 속성이 존재할 수 없다고 '선언'함으로써, "로딩 중인데 데이터가 있는" 불가능한 상태를 *컴파일 타임*에 원천적으로 차단했습니다. 이것이 **"불가능한 상태를 표현할 수 없게 만드는"** 데이터 지향적 설계의 핵심입니다.

------


### 28.2. 패턴 매칭: 안전하게 데이터 소비하기


데이터 모델을 DU로 완벽하게 설계했다면, 이제 이 데이터를 '소비'할 로직이 필요합니다. **패턴 매칭**은 DU의 '식별자'를 기반으로 데이터의 '모양'을 확인하고, 해당 모양에 맞는 로직을 안전하게 실행하는 제어 구조입니다.

TypeScript에서 기본으로 제공하는 가장 강력한 패턴 매칭 도구는 `switch` 문입니다.


#### 28.2.1. `switch`문과 타입 좁히기 (Type Narrowing)


`switch` 문에 DU의 '식별자(`status`)'를 사용하면, TypeScript는 각 `case` 블록 내부에서 변수의 타입을 **해당 '모양'으로 자동으로 좁혀줍니다(Narrowing).**

```typescript
function renderData(state: RemoteData<User>): string {
  switch (state.status) {
    case 'idle':
      // 👍 state의 타입이 '{ status: "idle" }'로 좁혀짐
      return '아직 요청되지 않음';

    case 'loading':
      // 👍 state의 타입이 '{ status: "loading" }'로 좁혀짐
      return '로딩 중...';
      
    case 'success':
      // 👍 state의 타입이 '{ status: "success"; data: User }'로 좁혀짐
      // 💥 'state.data'에 안전하게 접근 가능
      return `성공: ${state.data.name}`;
      
    case 'error':
      // 👍 state의 타입이 '{ status: "error"; error: Error }'로 좁혀짐
      // 💥 'state.error'에 안전하게 접근 가능
      return `실패: ${state.error.message}`;
      
    // 💥 만약 여기서 'state.data'에 접근하려 하면?
    // case 'loading':
    //   return state.data.name; // 🛑 컴파일 에러: '{ status: "loading" }' 타입에 'data' 속성이 없음
  }
}
```

`switch` 문은 단순히 `if (state.status === '...')`를 나열하는 것보다 강력합니다. TypeScript 컴파일러가 `switch`의 의도를 '패턴 매칭'으로 이해하고, 각 `case` 스코프의 타입 안전성을 보장해 주기 때문입니다.


#### 28.2.2. `never`를 이용한 완전성 검사 (Exhaustiveness Checking)


패턴 매칭의 '꽃'입니다. 만약 우리가 `RemoteData<T>` 타입에 `| { status: 'refreshing' }`이라는 새로운 상태를 추가했다고 가정해 봅시다.

`renderData` 함수는 `case 'refreshing'`을 구현하는 것을 잊었습니다. JavaScript라면 이 코드는 `undefined`를 반환하는 런타임 버그가 될 것입니다.

TypeScript는 `never` 타입을 이용해 이 실수를 **컴파일 타임에** 잡아낼 수 있습니다.

```typescript
function renderData(state: RemoteData<User>): string {
  switch (state.status) {
    // (case 'idle', 'loading', 'success', 'error' ... 생략)

    // 💥 모든 'case'가 끝나고 난 뒤 'default'에 never 검사 로직을 추가
    default:
      // 'state'는 이 시점에서 'never' 타입이어야 함
      // (모든 가능한 케이스가 위에서 처리되었으므로)
      const _exhaustiveCheck: never = state;
      
      // 💥 만약 'refreshing' 케이스를 빼먹었다면?
      // 'state'의 타입은 'never'가 아니라 '{ status: "refreshing" }'이 됨
      // 이 타입은 'never' 타입 변수에 할당될 수 없으므로,
      // TypeScript가 여기서 🛑 컴파일 에러를 발생시킴!
      // "Type '{ status: "refreshing"; }' is not assignable to type 'never'."
      return _exhaustiveCheck;
  }
}
```

이 `default` 블록의 `_exhaustiveCheck: never` 단 두 줄은, 우리의 **'데이터 모델(DU)'**과 **'로직(Pattern Match)'**이 100% 동기화되었음을 컴파일러가 보장해 주는 강력한 안전장치입니다. `state` 타입이 확장되면, `switch` 로직도 *반드시* 확장되어야만 컴파일이 성공합니다.

------


### 28.3. 고급 패턴 매칭: `ts-pattern` 라이브러리


`switch` 문은 강력하지만 두 가지 한계가 있습니다.

1. **문(Statement)**이다: `const result = switch(...)`처럼 표현식으로 사용할 수 없어, `let result;` 같은 임시 변수를 선언해야 합니다.
2. **단순하다**: `status` 같은 단일 식별자만 매칭할 뿐, `{ status: 'success', data: { name: 'Alice' } }` 같은 중첩된 데이터의 '모양'을 직접 매칭할 수는 없습니다.

이 한계를 극복하고 '표현식(Expression)' 기반의 함수형 패턴 매칭을 제공하는 라이브러리가 `ts-pattern`입니다.

```typescript
import { match, P } from 'ts-pattern';

function renderDataWithTsPattern(state: RemoteData<User>): string {
  // 💥 'match'는 'switch'와 달리 '표현식'이므로, 결과를 'view' 변수에 바로 할당
  const view = match(state)
    // 1. 단순 식별자 매칭
    .with({ status: 'idle' }, () => '아직 요청되지 않음')
    .with({ status: 'loading' }, () => '로딩 중...')
    
    // 2. 💥 중첩된 데이터 '모양'으로 매칭
    .with(
      { status: 'success', data: { name: 'Alice' } },
      (payload) => `관리자 ${payload.data.name}님 환영합니다!`
    )
    .with(
      { status: 'success', data: { name: P.string } }, // 'name'이 'string'인 모든 유저
      (payload) => `사용자 ${payload.data.name}님 환영합니다!`
    )
    .with({ status: 'error' }, (payload) => `실패: ${payload.error.message}`)
    
    // 3. 💥 'never' 검사와 동일한 '.exhaustive()'
    //    만약 'refreshing' 케이스가 빠지면 여기서 컴파일 에러 발생
    .exhaustive();
    
  return view;
}
```

`ts-pattern`을 사용하면 `switch`문이 `f(data) = view`라는 **'데이터 변환 파이프라인(제2장)'** 그 자체로 변모합니다. 복잡한 `if/else`나 `switch` 로직이, '데이터 패턴'과 '출력 값'을 1:1로 매핑하는 선언적인 데이터 구조가 됩니다.

------


### 28.4. 결론: 컴파일 타임에 `f(state)`를 완성하라


`UI = f(state)`라는 우리의 핵심 공식은 **Discriminated Unions**와 **Pattern Matching**의 조합을 통해 컴파일 타임 레벨에서 완성됩니다.

- **`state` (데이터)**: **Discriminated Unions**를 사용하여, 논리적으로 유효하고 '스스로를 설명하는' 데이터 모델을 만듭니다. '불가능한 상태'는 타입 시스템이 거부합니다.
- **`f` (로직)**: **Pattern Matching** (`switch` + `never` 또는 `ts-pattern`)을 사용하여, '데이터의 모든 가능한 모양'을 안전하고 '완전하게(Exhaustively)' 처리합니다. '처리되지 않은 상태'는 컴파일러가 거부합니다.

이 패러다임은 런타임에 발생할 수 있는 수많은 `state` 관련 버그(예: `Cannot read properties of null`)를 컴파일 타임으로 끌어내려, 개발자가 데이터 모델의 변경에 즉각적으로 대응하도록 강제합니다. 이것이 바로 TypeScript를 활용한 데이터 지향 프로그래밍의 핵심적인 가치입니다.

------

네, 알겠습니다. 제6부 '고급 주제'의 아홉 번째 장이자, '타입 시스템 활용' 섹션의 마지막 파트인 '컴파일 타임 안정성 극대화' 집필을 시작하겠습니다. 이 장은 우리가 설계한 데이터 모델의 '법률'을 완성하고, 런타임에 발생할 수 있는 데이터 관련 에러를 컴파일 타임에 박멸하는 고급 전략들을 탐구합니다.

------


## 29. 타입 시스템 활용 - 컴파일 타임 안정성 극대화


> "최고의 코드는 버그가 없는 코드가 아니라, 버그가 '존재할 수 없는' 코드이다. 컴파일 타임 안정성은 런타임의 '희망'을 컴파일 타임의 '보증'으로 바꾸는 기술이며, 이는 데이터 지향 설계의 궁극적인 목표다."

제27장과 28장에서 우리는 TypeScript의 고급 타입(제네릭, 맵드 타입)과 식별 가능한 유니언(DU)을 통해 '데이터 모델'을 정교하게 '설계'하고 '소비'하는 방법을 배웠습니다. 우리는 "불가능한 상태는 표현조차 할 수 없게" 만들었고, "데이터의 모든 변종을 안전하게 처리"하도록 컴파일러의 도움을 받았습니다.

하지만 우리의 데이터는 '순수한' TypeScript 세계에만 머무르지 않습니다. 데이터는 '불순한' 외부 세계, 즉 API 응답, `localStorage`, 사용자 입력(`input.value`)으로부터 들어옵니다. 이 데이터는 우리의 '타입 정의'를 존중하지 않습니다.

**컴파일 타임 안정성 극대화**란, 이 '신뢰할 수 없는(Untrusted)' 외부 데이터를 '신뢰할 수 있는(Trusted)' 내부 데이터(`state`)로 변환하는 '국경'을 세우고, 이 국경을 통과한 데이터가 애플리케이션 내부에서 절대 오염되거나 오용되지 않도록 보장하는 모든 기법을 의미합니다.

"컴파일에 성공하면, (적어도 데이터 로직에 관한 한) 올바르게 작동한다." 🚀

본 장에서는 `any`라는 적을 피하고, `unknown`이라는 관문을 세우며, '브랜딩(Branding)', `satisfies`, 그리고 런타임 검증(Zod)을 통해 이 '안전 보증'을 달성하는 최후의 전략들을 탐구합니다.

------


### 29.1. 안정성의 적: `any`와 `unknown`의 올바른 이해


컴파일 타임 안정성을 무너뜨리는 주범은 `any`입니다.


#### 29.1.1. `any`는 '독(Poison)'이다


`any`는 타입 체커를 꺼버리는 '탈출구'입니다. `any` 타입의 변수는 어떤 속성에 접근하든, 어떤 함수에 인자로 전달되든 컴파일러가 '무조건 통과'시킵니다.

```typescript
// 👎 'any'는 타입 시스템을 전염시킨다
function logName(data: any) {
  // data가 { name: 'Alice' } 일지 { user: 'Bob' } 일지 모름
  // 'naem'이라는 오타가 발생해도 컴파일러는 침묵
  console.log(data.naem); // 💥 런타임 에러: Cannot read properties of undefined
}

// 💥 'any'는 전염성이 있다
const myData: any = { id: 1 };
const myName = myData.name; // 'myName'도 'any' 타입이 됨
```

`any`를 사용하는 것은 데이터 지향 프로그래밍의 모든 원칙을 포기하는 행위입니다. `tsconfig.json`에서 `"noImplicitAny": true`와 `"strict": true`를 켜는 것은 안정성 극대화의 첫걸음입니다.


#### 29.1.2. `unknown`은 '관문(Gateway)'이다


외부 세계(API, `JSON.parse`)에서 들어오는 데이터의 타입은 `any`가 아니라 **`unknown`**입니다. `unknown`은 `any`의 '안전한' 버전입니다.

`unknown`은 "나는 이 데이터가 무엇인지 전혀 모른다"라고 선언합니다. 컴파일러는 `unknown` 타입의 데이터에 대해 *어떠한* 작업도 허용하지 않습니다.

```typescript
// 👍 'unknown'은 안전하다
function logNameSafe(data: unknown) {
  // 🛑 컴파일 에러: 'data' is of type 'unknown'.
  // 'data.name'에 접근할 수 없음
  console.log(data.name); 
}
```

`unknown`을 사용하기 위해, 우리는 이 데이터가 '무엇인지' **컴파일러에게 '증명'**해야 합니다. 이 '증명' 과정이 바로 '타입 가드(Type Guards)'입니다.

------


### 29.2. 기법 1: 타입 가드(Type Guards)와 `is` 키워드


타입 가드는 `unknown`이 가득한 런타임 세계와 타입이 명확한 컴파일 타임 세계를 연결하는 '다리'입니다.

```typescript
interface User {
  id: string;
  name: string;
}

// 1. 'is' 키워드를 사용한 타입 가드 함수
// 💥 이 함수는 'boolean'이 아닌 'data is User'를 반환
function isUser(data: unknown): data is User {
  // (typeof data === 'object' && data !== null) 등 더 엄격한 검사 필요
  if (data && typeof data === 'object' && 'id' in data && 'name' in data) {
    return true;
  }
  return false;
}

// 2. 'unknown'을 '증명'하여 사용
async function fetchUser() {
  const response: unknown = await api.fetch('/user/1');
  
  // 3. 💥 'if' 문을 통한 타입 좁히기
  if (isUser(response)) {
    // 👍 이 블록 안에서 'response'는 'User' 타입으로 좁혀짐
    console.log(response.name);
  } else {
    // 👍 이 블록 안에서 'response'는 'unknown' (또는 'User'가 아닌 타입)
    throw new Error('API 응답 형식이 User가 아님');
  }
}
```

`isUser`라는 '국경 검문소'를 통과한 `response` 데이터만이 `User`라는 '시민권'을 얻어 우리 시스템 내부로 들어올 수 있습니다.

------


### 29.3. 기법 2: '브랜딩(Branding)'을 통한 명목적 타이핑


TypeScript는 구조적 타입 시스템(Structural Typing)을 사용합니다. 즉, '모양'이 같으면 같은 타입입니다. 이는 데이터의 '의미(Domain)'를 무시하는 심각한 안정성 문제를 야기합니다.

```typescript
type UserID = string;
type PostID = string;

function deleteUser(id: UserID) { /* ... */ }

const myPostId: PostID = 'post-123';

// 👎 'PostID'와 'UserID'는 '모양'(string)이 같기 때문에,
// 💥 컴파일러가 이 실수를 잡아내지 못함
deleteUser(myPostId); // 런타임에 'user-db'에서 'post-123'을 찾다가 실패
```

데이터 지향 설계는 `UserID`와 `PostID`가 *전혀 다른* 데이터임을 보장해야 합니다. **'브랜딩(Branding)'** 기법(또는 'Opaque Types')은 구조적 타입 시스템에 '명목적(Nominal)' 특성을 부여합니다.

```typescript
// 1. '브랜드'를 정의
type Brand<K, T> = K & { readonly __brand: T };

// 2. 기본 타입을 '브랜딩'
type UserID = Brand<string, 'UserID'>;
type PostID = Brand<string, 'PostID'>;

// 3. 타입을 생성하는 '팩토리 함수' (런타임 오버헤드 없음)
const asUserID = (id: string): UserID => id as UserID;
const asPostID = (id: string): PostID => id as PostID;

function deleteUser(id: UserID) { /* ... */ }

const myPostId: PostID = asPostID('post-123');

// 4. 💥 컴파일 에러 발생!
// 🛑 Error: Argument of type 'PostID' is not assignable to
//           parameter of type 'UserID'.
//           Type 'PostID' is not assignable to type '{ readonly __brand: "UserID"; }'.
deleteUser(myPostId);
```

`__brand`라는 가상의 속성을 타입에 추가함으로써, `UserID`와 `PostID`는 더 이상 호환되지 않습니다. 이로써 `deleteUser` 함수에 `PostID`를 넘기는 데이터 오용(Data Misuse)을 *컴파일 타임*에 방지할 수 있습니다. 이는 제4장, 제17장의 '정규화된 상태'에서 `authorId`가 `CommentID`와 혼동되는 것을 막아주는 강력한 무기입니다. 🛡️

------


### 29.4. 기법 3: `satisfies` 연산자 (타입 추론 유지)


때로는 데이터의 '타입'을 검증하면서도, 데이터의 '구체적인 값'을 잃고 싶지 않을 때가 있습니다. (TS 4.9+)

```typescript
interface Config {
  env: 'dev' | 'prod';
  apiKey: string;
}

// 👎 방법 1: 타입 애너테이션
// 'config.env'의 타입은 'string'이 아닌 'dev' | 'prod'로 잘 검증됨
// 하지만 'config.env'의 *구체적인 값*이 'dev'라는 정보는 잃어버림
const config: Config = {
  env: 'dev',
  apiKey: 'xyz'
};

// 👎 방법 2: as const (불변성)
// 'config.env'의 타입이 'dev' 리터럴 타입으로 잘 보존됨
// 하지만 'Config' 타입(예: 'apiKey'가 빠졌는지)을 *검증*하지 않음
const configConst = {
  env: 'dev',
  // apiKey: 'xyz' // <-- 이 속성을 빼먹어도 컴파일러가 모름
} as const;
```

**`satisfies`** 연산자는 이 두 가지 장점(검증 + 추론)을 모두 취합니다.

```typescript
// 👍 방법 3: 'satisfies' 연산자
const config = {
  env: 'dev',
  apiKey: 'xyz'
  // 💥 만약 'apiKey'를 빼먹으면? 
  // 🛑 컴파일 에러: Property 'apiKey' is missing in type...
  //    (Config 타입에 대한 '검증' 성공)
} satisfies Config;

// 💥 'config.env'의 타입은 'string'이나 'dev' | 'prod'가 아닌,
//    'dev' 리터럴 타입으로 '추론'됨!
// 'config.env'의 타입: "dev"
if (config.env === 'dev') {
  // ...
}
```

`satisfies`는 '데이터의 구체적인 값'을 기반으로 로직을 분기해야 하는 데이터 지향 프로그래밍에서, 타입 검증과 타입 추론을 동시에 달성하게 해주는 강력한 도구입니다.

------


### 29.5. 최종 관문: 런타임 스키마 검증 (Zod)


타입 가드(`isUser`)는 수동이며 실수하기 쉽습니다. API 응답에 `age` 속성이 추가되면, `isUser` 함수를 *수동으로* 업데이트해야 합니다.

안정성을 극대화하는 최종 단계는, 런타임 데이터의 '청사진(Schema)'을 코드(Code)로 정의하고, 이 청사진에서 **'파서(Parser)'**와 **'타입(Type)'**을 *동시에* 파생시키는 것입니다. 이 역할을 하는 라이브러리가 **Zod**입니다.

**Zod는 SSoT(청사진)가 런타임 검증기(Parser)와 컴파일 타임 타입(Type)을 모두 생성하는, 데이터 지향의 완벽한 예시입니다.**

```typescript
import { z } from 'zod';

// 1. SSoT(단일 진실 공급원)로서의 '스키마' 정의
const UserSchema = z.object({
  id: z.string().uuid(), // (타입 + 런타임 검증)
  name: z.string().min(2),
  age: z.number().positive(),
  email: z.string().email(),
});

// 2. 💥 스키마로부터 '컴파일 타임 타입'을 *자동으로* 추론
// (개발자가 'interface User'를 수동으로 작성할 필요 없음)
type User = z.infer<typeof UserSchema>;
/* type User = {
    id: string;
    name: string;
    age: number;
    email: string;
}
*/

// 3. 💥 스키마로부터 '런타임 파서'를 *자동으로* 생성
// 'unknown' -> 'User'로 가는 유일하고 안전한 관문
async function getTrustedUser(): Promise<User> {
  const response: unknown = await api.fetch('/user/1');
  
  try {
    // 4. 'parse'를 통해 런타임 검증
    //    이 코드를 통과하면, 'user'는 'User' 타입임이 100% 보장됨
    const user = UserSchema.parse(response); 
    return user;
  } catch (error) {
    // ZodError가 발생 (예: 'age'가 음수이거나 'name'이 없음)
    console.error('API 응답 데이터가 스키마와 일치하지 않음:', error);
    throw new Error('데이터 검증 실패');
  }
}
```

`UserSchema`라는 단 하나의 '진실'을 정의함으로써, 우리는 `interface User`라는 수동 타입 정의와 `isUser`라는 수동 타입 가드를 모두 제거했습니다. **스키마가 곧 데이터 모델이고, 데이터 모델이 곧 타입이고, 타입이 곧 검증기입니다.**

------


### 29.6. 책을 마치며: 데이터가 중심이 되는 길


우리는 `UI = f(state)`라는 단순한 공식에서 출발하여, 이 공식의 각 요소를 데이터 지향적으로 분해하고, 조립하고, 최적화하는 긴 여정을 거쳤습니다.

`state`를 순수하게 유지하기 위해 **순수 함수**와 **불변성**을 배웠고(1부), 이 `state`를 견고하게 설계하기 위해 **정규화**와 **SSoT**를 도입했습니다(2부). `f`라는 로직을 고도화하기 위해 **ECS**와 **CQRS** 같은 아키텍처 패턴을 탐구했고(3부), 성능을 극대화하기 위해 **SoA**와 **데이터 지역성**을, '무한'을 다루기 위해 **가상화**를 배웠습니다(4부).

우리는 **RxJS**와 **Signals**로 '데이터의 흐름' 자체를 재정의했고(5부), **CRDT**로 '분산된 진실'을 통합했으며(6부 초반), **VDOM**과 **Reconciliation**을 통해 `f(state)`가 어떻게 UI로 변환되는지 그 엔진을 해부했습니다(6부 중반).

그리고 마침내, 이 모든 데이터 모델과 로직을 보호하기 위해 **TypeScript**라는 강력한 '법률 시스템'을 구축했습니다(6부 후반).

'프론트엔드에서의 데이터 지향 프로그래밍'은 특정 프레임워크나 라이브러리를 배우는 것이 아닙니다. 그것은 `data.name`이라는 코드 한 줄을 볼 때, 그 데이터가 어디서 왔고(SSoT), 어떻게 구조화되었으며(Schema), 불변인지(Immutability), 어떻게 변환되고(Pipeline), 어떻게 소비되며(Query/Selector), 어떻게 렌더링되고(VDOM), 어떻게 검증되는지(Type System) 그 **데이터의 '전체 생명주기'**를 생각하는 **'사고방식'**입니다.

데이터는 복잡성의 근원이자, 그 복잡성을 길들이는 열쇠입니다. 이 책에서 탐구한 원칙들이 여러분의 코드에 '예측 가능성'과 '안정성'이라는 질서를 가져다주기를 바랍니다. 🚀

